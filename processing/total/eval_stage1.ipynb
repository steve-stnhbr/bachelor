{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd75e20-cb2a-4d4c-a2d8-8b153aebd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41159c-82b5-46f9-a56d-9bd811efca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_AMOUNT = 2\n",
    "DATASET_DIR = \"_data/plant_pathology\"\n",
    "INT_DIR = \"_intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b632b-b013-41b1-ba62-3b24af56d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(INT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2c724-47cb-48b7-bd21-dcc4dcc37cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATASET_DIR, \"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cf64e-5b47-4d53-8b84-527a7e1723f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = random.sample(list(train_data.index), k=EVAL_AMOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8233ad-0a77-4c1e-ad7e-35c55969c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(masks, image, apply_mask=False, padding=0):\n",
    "    result = []\n",
    "    \n",
    "    for mask in masks:\n",
    "        if apply_mask:\n",
    "            image_tmp = image * (mask[\"segmentation\"][:, :, np.newaxis])\n",
    "        else:\n",
    "            image_tmp = image\n",
    "        \n",
    "        bbox = mask[\"bbox\"]\n",
    "        x0 = bbox[1]-padding\n",
    "        if x0 < 0:\n",
    "            x0 = 0\n",
    "        x1 = bbox[1]+bbox[3]+padding\n",
    "        if x1 >= image.shape[0]:\n",
    "            x1 = image.shape[0] - 1\n",
    "        y0 = bbox[0]-padding\n",
    "        if y0 < 0:\n",
    "            y0 = 0\n",
    "        y1 = bbox[0]+bbox[2]+padding\n",
    "        if y1 >= image.shape[1]:\n",
    "            y1 = image.shape[1] - 1\n",
    "        \n",
    "        patch = image_tmp[x0:x1, y0:y1]\n",
    "        #mask['patch'] = patch\n",
    "        \n",
    "        if 0 in patch.shape:\n",
    "            continue\n",
    "        result.append(patch)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5d090-c53b-4987-8f94-cd6cca19dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed62de-2bf4-4558-93cb-7b1c6df5da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam_generate_mask(image):\n",
    "    import sys\n",
    "    sys.path.append(\"..\")\n",
    "    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "    sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "    model_type = \"vit_h\"\n",
    "\n",
    "\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=device)\n",
    "\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    masks = mask_generator.generate(image)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdf896-ee62-4f44-b5a3-571204f9a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "class BinaryResnetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(BinaryResnetClassifier, self).__init__()\n",
    "        # Load a pre-trained ResNet model\n",
    "        self.resnet = resnet50(ResNet50_Weights.IMAGENET1K_V1)  # You can choose any ResNet variant\n",
    "        # Modify the last fully connected layer\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "        nn.init.xavier_normal_(self.resnet.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the ResNet\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "    \n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "])\n",
    "\n",
    "\n",
    "resnet = torch.load(\"../leaf_segmentation/out/leaf_classifier/resnet/resnet_latest.pth\")\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "def s1_sam_resnet(image):\n",
    "    #masks = execute_in_process(sam_generate_mask, (image,))\n",
    "    masks = sam_generate_mask(image)\n",
    "    patches = get_patches(masks, image)\n",
    "    from PIL import Image\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i, patch in enumerate(patches):\n",
    "            input = tf(Image.fromarray(patch)).unsqueeze(0).to(device)\n",
    "            result = torch.sigmoid(resnet(input)).cpu().item()\n",
    "\n",
    "            results.append(result)\n",
    "            masks[i][\"patch\"] = patch\n",
    "            masks[i][\"leaf_probability\"] = result\n",
    "    PROBABILITY_THRESHOLD = .5\n",
    "    masks_filtered = [mask for mask, result in zip(masks,results) if result > PROBABILITY_THRESHOLD]\n",
    "    return masks_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259a2bf-896f-4787-8f2f-1099d4d3cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"../leaf_segmentation/out/yolo_urban_street/train/weights/best.pt\")\n",
    "def s1_sam_yolo(image):\n",
    "    from ultralytics import YOLO, checks\n",
    "    masks = sam_generate_mask(image)\n",
    "    patches = get_patches(masks, image)\n",
    "    results_yolo = []\n",
    "    for i, patch in enumerate(patches):\n",
    "        result = model.predict(patch)\n",
    "        results_yolo.append(1 if result[0].masks is not None and len(result[0].masks) > 0 else 0)\n",
    "        masks[i][\"patch\"] = patch\n",
    "        # TODO: update probability assignment\n",
    "        masks[i][\"leaf_probability\"] = 1 if result[0].masks is not None and len(result[0].masks) > 0 else 0 \n",
    "    masks_filtered = [mask for mask, result in zip(masks,results_yolo) if result > 0]\n",
    "    return masks_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca455c-920a-4a8b-8b61-3f0d631392e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_dict = {\n",
    "    \"SAM + YOLOv8\": s1_sam_yolo,\n",
    "    \"SAM + ResNet\": s1_sam_resnet,\n",
    "#    \"Mask R-CNN\": s1_mask_rcnn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca72354-fcaf-4bd5-ba49-e6b0f3f8ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_results = {}\n",
    "for stage1_name, stage1_model in stage1_dict.items():\n",
    "    stage1_results[stage1_name] = {}\n",
    "    for index in indices:\n",
    "        gt_healthy = bool(train_data.loc[index][\"healthy\"])\n",
    "        stage1_results[stage1_name][index] = {\n",
    "            'healthy': gt_healthy\n",
    "            'masks': []\n",
    "        }\n",
    "        img = cv2.imread(os.path.join(DATASET_DIR, \"images\", train_data.loc[index][\"image_id\"] + \".jpg\"))\n",
    "        with torch.no_grad():\n",
    "            leaf_masks = stage1_model(img)\n",
    "            stage1_results[stage1_name][index]['masks'] = leaf_masks\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d1dbf-935e-48f2-9d81-d20eddc1357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for stage1_name, stage1_result in stage1_results.items():\n",
    "    with open(os.path.join(INT_DIR, stage1_name, \"data.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(stage1_result, file)\n",
    "\n",
    "with open(os.path.join(INT_DIR, \"total_data.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(stage1_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12117c-d155-4d35-a421-8af546a66751",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage1_name, stage1_result in stage1_results.items():\n",
    "    patches_dir = os.path.join(INT_DIR, stage1_name, \"patches\")\n",
    "    os.makedirs(patches_dir, exist_ok=True)\n",
    "    for index, data in stage1_result.items():\n",
    "        for i, leaf_mask in enumerate(data['masks']):\n",
    "            cv2.imwrite(os.path.join(patches_dir, f\"patch_{index}_{i}.png\"), leaf_mask['patch'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
