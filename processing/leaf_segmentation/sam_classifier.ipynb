{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision.models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "EPOCHS = 32\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "N_CLASSES = 1000\n",
    "LEAF_CLASS = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LeafClassificationDataset(Dataset):\n",
    "    def __init__(self, dir, transforms=None, default_label=1):\n",
    "        self.files = [os.path.join(dir, file) for file in os.listdir(dir) if os.path.isfile(os.path.join(dir, file)) and file.endswith((\"jpg\", \"jpeg\", \"png\"))]\n",
    "        self.transforms = transforms\n",
    "        self.default_label = default_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = read_image(self.files[idx])\n",
    "        label = self.default_label\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf_simple = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Resize((512, 512))\n",
    "])\n",
    "dataset = LeafClassificationDataset(\"_data/urban_street/images\", transforms=tf_simple, default_label=LEAF_CLASS)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    #return torch.stack(xs).to(DEVICE), torch.tensor(ys).to(DEVICE)\n",
    "    return torch.stack(xs), torch.tensor(ys)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=2,\n",
    "                        collate_fn=collate_fn,\n",
    "                        pin_memory=True,\n",
    "                        prefetch_factor=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.convnext_base(weights=\"DEFAULT\", num_classes=N_CLASSES)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_loss = pd.DataFrame({}, columns=[\"step\", \"epoch\", \"loss\", \"probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_net = torch.nn.Sequential(\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(.5),\n",
    "    transforms.RandomPerspective(distortion_scale=0.6)\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_total = torch.nn.Sequential(tf_net, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00025629461742937565, Probabilities: [0.9995408 0.9999212 0.9997693]:  29%|██▉       | 947/3255 [08:26<19:24,  1.98it/s]   "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "step = 0\n",
    "running_loss = .0\n",
    "for epoch in range(EPOCHS):\n",
    "    data_iter = iter(dataloader)\n",
    "\n",
    "    next_batch = next(data_iter) # start loading the first batch\n",
    "    next_batch = [ _.cuda(non_blocking=True) for _ in next_batch ]  # with pin_memory=True and non_blocking=True, this will copy data to GPU non blockingly\n",
    "\n",
    "    p_bar = tqdm.tqdm(range(len(dataloader)))\n",
    "\n",
    "    for i in p_bar:\n",
    "        batch = next_batch \n",
    "        step += len(batch)\n",
    "        if i + 2 != len(dataloader): \n",
    "            # start copying data of next batch\n",
    "            next_batch = next(data_iter)\n",
    "            next_batch = [ _.cuda(non_blocking=True) for _ in next_batch]\n",
    "\n",
    "        # training code\n",
    "        step += len(batch)\n",
    "        inputs, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_total(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)[:, LEAF_CLASS].detach().cpu().numpy()\n",
    "        p_bar.set_description(f\"Loss: {loss.item()}, Probabilities: {probs}\")\n",
    "        df_loss.loc[len(df_loss)] = {\"step\": step, \"epoch\": epoch, \"loss\": loss.item(), \"probability\": probs.mean()}\n",
    "    print(f\"Epoch {epoch} Loss: \", running_loss)\n",
    "    print(\"Saving Model Checkpoint\")\n",
    "    torch.save(model, f\"out/resnet_leaf_classifier/epoch_{epoch}.pt\")\n",
    "    df_loss.to_csv(\"out/resnet_leaf_classifier/loss.csv\")\n",
    "    \n",
    "print(\"Finished Training, Saving Model\")\n",
    "torch.save(model, f\"out/resnet_leaf_classifier/{time.time()}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, f\"out/resnet_leaf_classifier/{time.time()}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROB_THRESHOLD = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=DEVICE)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import cv2\n",
    "image_file = random.sample(os.listdir(\"_data/combined/test\"), 1)[0]\n",
    "image = cv2.imread(os.path.join(\"_data/combined/test\", image_file))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)\n",
    "print(f\"Detected {len(masks)} areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),  \n",
    "])\n",
    "\n",
    "leaf_masks = []\n",
    "\n",
    "for mask in masks:\n",
    "    bbox = mask[\"bbox\"]\n",
    "    if bbox[2] - bbox[0] == 0 or  bbox[3] - bbox[1] == 0:\n",
    "        continue\n",
    "    crop = image[bbox[0]:bbox[2], bbox[1]:bbox[3], :]\n",
    "    if crop.shape[0] == 0 or crop.shape[1] == 0:\n",
    "        continue\n",
    "    crop = tf(crop)\n",
    "    crop = crop.unsqueeze(0)\n",
    "    crop = crop.to(DEVICE)\n",
    "    result = model(crop)\n",
    "    probabilities = torch.nn.functional.softmax(result[0], dim=0)\n",
    "    if probabilities[LEAF_CLASS] > PROB_THRESHOLD:\n",
    "        leaf_masks.append(mask)\n",
    "print(f\"Detected {len(leaf_masks)} leaf areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "show_anns(leaf_masks)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch w/ CUDA 12.4",
   "language": "python",
   "name": "pytorch_cuda_12.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
