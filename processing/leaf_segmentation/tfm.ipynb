{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 12:13:30.517071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-16 12:13:30.541254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-16 12:13:30.541300: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-16 12:13:30.558811: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 12:13:32.963416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial\n",
    "from tfm_configs import *\n",
    "import re\n",
    "import tensorflow_datasets as tfdsw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "#MODEL = \"maskrcnn_mobilenet_fpn\"\n",
    "#MODEL = \"retinanet_resnet_fpn\"\n",
    "MODEL = \"maskrcnn_resnet_fpn\"\n",
    "MODEL_DIR = \"out/\" + MODEL\n",
    "START = time.time()\n",
    "RESTORE_METRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exp_config = maskrcnn_mobilenet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config = retinanet_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "exp_config = maskrcnn_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config.trainer.validation_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution Strategy on Device /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 12:13:39.691555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38484 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vertical integrity not given [512, 9, 9, 9, 9, 9, 9] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([9])), ('groundtruth_is_crowd', TensorShape([9])), ('groundtruth_area', TensorShape([9])), ('groundtruth_boxes', TensorShape([9, 4])), ('groundtruth_instance_masks', TensorShape([9, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([9]))]\n",
      "Val vertical integrity not given [512, 19, 19, 19, 19, 19, 19] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([19])), ('groundtruth_is_crowd', TensorShape([19])), ('groundtruth_area', TensorShape([19])), ('groundtruth_boxes', TensorShape([19, 4])), ('groundtruth_instance_masks', TensorShape([19, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([19]))]\n",
      "Train vertical integrity not given [512, 6, 6, 6, 6, 6, 6] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([6])), ('groundtruth_is_crowd', TensorShape([6])), ('groundtruth_area', TensorShape([6])), ('groundtruth_boxes', TensorShape([6, 4])), ('groundtruth_instance_masks', TensorShape([6, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([6]))]\n",
      "Val vertical integrity not given [512, 4, 4, 4, 4, 4, 4] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([4])), ('groundtruth_is_crowd', TensorShape([4])), ('groundtruth_area', TensorShape([4])), ('groundtruth_boxes', TensorShape([4, 4])), ('groundtruth_instance_masks', TensorShape([4, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([4]))]\n",
      "integrity given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 12:13:41.673748: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 100\n",
    "num_of_examples = 2\n",
    "tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(raw_records)\n",
    "\n",
    "val_tfrecords = tf.io.gfile.glob(exp_config.task.validation_data.input_path)\n",
    "val_raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(val_raw_records)\n",
    "show = True\n",
    "for train, val in zip(raw_records, val_raw_records):\n",
    "    train_decoded = tf_ex_decoder.decode(train)\n",
    "    val_decoded = tf_ex_decoder.decode(val)\n",
    "    \n",
    "    for key in train_decoded.keys():\n",
    "        hor_ok = train_decoded[key].shape[1:] == val_decoded[key].shape[1:]\n",
    "        if not hor_ok:\n",
    "            print(\"Horizontal Integrity not given\", key, train_decoded[key].shape[1:], val_decoded[key].shape[1:])\n",
    "\n",
    "    sizes_train = [train_decoded[key].shape[0] for key in train_decoded.keys() if len(train_decoded[key].shape) > 0]\n",
    "    train_ver_ok = len(set(sizes_train)) == 1\n",
    "    if not train_ver_ok:\n",
    "        print(\"Train vertical integrity not given\", sizes_train,  [(key, value.shape) for key, value in train_decoded.items()])\n",
    "\n",
    "    sizes_val = [val_decoded[key].shape[0] for key in val_decoded.keys() if len(val_decoded[key].shape) > 0]\n",
    "    val_ver_ok = len(set(sizes_val)) == 1\n",
    "    if not val_ver_ok:\n",
    "        print(\"Val vertical integrity not given\", sizes_val, [(key, value.shape) for key, value in val_decoded.items()])\n",
    "print(\"integrity given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_notification(text):\n",
    "    if \"loss\" not in text or 'eval' not in text:\n",
    "        return\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    losses.reverse()\n",
    "    msg = f\"Step #{step}:\" + ' - '.join([f\"{name} Loss: {value}\" for name, value in losses])\n",
    "    send_pushover_notification(msg, title=\"Training Losses\", priority=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "data_val = []\n",
    "os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "\n",
    "if RESTORE_METRICS:\n",
    "    files = os.listdir(f\"metrics/{MODEL}\")\n",
    "    vals = [file for file in files if \"val\" in file]\n",
    "    trains = [file for file in files if \"train\" in file]\n",
    "    vals.sort()\n",
    "    trains.sort()\n",
    "    last_val = vals[-1]\n",
    "    last_train = trains[-1]\n",
    "    data_train = pd.read_csv(os.path.join(f\"metrics/{MODEL}\", last_train)).to_dict('records')\n",
    "    data_val = pd.read_csv(os.path.join(f\"metrics/{MODEL}\", last_val)).to_dict('records')\n",
    "    \n",
    "def log_eval(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    metrics_dict = re.findall(r\"\\s+.'(.*?)':\\s(.*\\d)\", text)\n",
    "    metrics = {name: value for name, value in metrics_dict}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "    \n",
    "    data_val.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_val)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_val_{START}.csv\", index=False)\n",
    "    \n",
    "def log_train(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    metrics = {name: value for name, value in losses}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "\n",
    "    data_train.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_train)\n",
    "    os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_train_{START}.csv\", index=False)\n",
    "    \n",
    "    \n",
    "def tfm_log(text):\n",
    "    if \"output\" not in text:\n",
    "        return\n",
    "    if \"eval\" in text:\n",
    "        log_eval(text)\n",
    "        return\n",
    "    if \"train\" in text:\n",
    "        log_train(text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2024-09-16 12:14:25.792992: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "restoring or initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 12:14:56.132440: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080: FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 77 meaning 'Problem with the SSL CA cert (path? access rights?)', error details: error setting certificate verify locations:  CAfile: /etc/ssl/certs/ca-certificates.crt CApath: none\n\t when reading gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m send_pushover_notification(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow Models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m intercept_stdout(tfm_log):\n\u001b[0;32m----> 4\u001b[0m     model, eval_logs \u001b[38;5;241m=\u001b[39m tfm\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mtrain_lib\u001b[38;5;241m.\u001b[39mrun_experiment(\n\u001b[1;32m      5\u001b[0m         distribution_strategy\u001b[38;5;241m=\u001b[39mdistribution_strategy,\n\u001b[1;32m      6\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m      7\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_and_eval\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         params\u001b[38;5;241m=\u001b[39mexp_config,\n\u001b[1;32m      9\u001b[0m         model_dir\u001b[38;5;241m=\u001b[39mMODEL_DIR,\n\u001b[1;32m     10\u001b[0m         run_post_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:356\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(distribution_strategy, task, mode, params, model_dir, run_post_eval, save_summary, train_actions, eval_actions, trainer, controller_cls, summary_manager, eval_summary_manager, enable_async_checkpointing)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_experiment\u001b[39m(\n\u001b[1;32m    310\u001b[0m     distribution_strategy: tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mStrategy,\n\u001b[1;32m    311\u001b[0m     task: base_task\u001b[38;5;241m.\u001b[39mTask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m     enable_async_checkpointing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[tf_keras\u001b[38;5;241m.\u001b[39mModel, Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Runs train/eval configured by the experiment params.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        otherwise, returns {}.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m   runner \u001b[38;5;241m=\u001b[39m OrbitExperimentRunner(\n\u001b[1;32m    357\u001b[0m       distribution_strategy\u001b[38;5;241m=\u001b[39mdistribution_strategy,\n\u001b[1;32m    358\u001b[0m       task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    359\u001b[0m       mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    360\u001b[0m       params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    361\u001b[0m       model_dir\u001b[38;5;241m=\u001b[39mmodel_dir,\n\u001b[1;32m    362\u001b[0m       run_post_eval\u001b[38;5;241m=\u001b[39mrun_post_eval,\n\u001b[1;32m    363\u001b[0m       save_summary\u001b[38;5;241m=\u001b[39msave_summary,\n\u001b[1;32m    364\u001b[0m       train_actions\u001b[38;5;241m=\u001b[39mtrain_actions,\n\u001b[1;32m    365\u001b[0m       eval_actions\u001b[38;5;241m=\u001b[39meval_actions,\n\u001b[1;32m    366\u001b[0m       trainer\u001b[38;5;241m=\u001b[39mtrainer,\n\u001b[1;32m    367\u001b[0m       controller_cls\u001b[38;5;241m=\u001b[39mcontroller_cls,\n\u001b[1;32m    368\u001b[0m       summary_manager\u001b[38;5;241m=\u001b[39msummary_manager,\n\u001b[1;32m    369\u001b[0m       eval_summary_manager\u001b[38;5;241m=\u001b[39meval_summary_manager,\n\u001b[1;32m    370\u001b[0m       enable_async_checkpointing\u001b[38;5;241m=\u001b[39menable_async_checkpointing,\n\u001b[1;32m    371\u001b[0m   )\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:115\u001b[0m, in \u001b[0;36mOrbitExperimentRunner.__init__\u001b[0;34m(self, distribution_strategy, task, mode, params, model_dir, run_post_eval, save_summary, train_actions, eval_actions, trainer, controller_cls, summary_manager, eval_summary_manager, enable_async_checkpointing)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_manager \u001b[38;5;241m=\u001b[39m summary_manager\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_summary_manager \u001b[38;5;241m=\u001b[39m eval_summary_manager\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_controller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_controller(\n\u001b[1;32m    116\u001b[0m     trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer,\n\u001b[1;32m    118\u001b[0m     save_summary\u001b[38;5;241m=\u001b[39msave_summary,\n\u001b[1;32m    119\u001b[0m     train_actions\u001b[38;5;241m=\u001b[39mtrain_actions,\n\u001b[1;32m    120\u001b[0m     eval_actions\u001b[38;5;241m=\u001b[39meval_actions,\n\u001b[1;32m    121\u001b[0m     controller_cls\u001b[38;5;241m=\u001b[39mcontroller_cls,\n\u001b[1;32m    122\u001b[0m     enable_async_checkpointing\u001b[38;5;241m=\u001b[39menable_async_checkpointing)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:229\u001b[0m, in \u001b[0;36mOrbitExperimentRunner._build_controller\u001b[0;34m(self, trainer, evaluator, save_summary, train_actions, eval_actions, controller_cls, enable_async_checkpointing)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m   eval_summary_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m controller \u001b[38;5;241m=\u001b[39m controller_cls(\n\u001b[1;32m    230\u001b[0m     strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy,\n\u001b[1;32m    231\u001b[0m     trainer\u001b[38;5;241m=\u001b[39mtrainer,\n\u001b[1;32m    232\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m    233\u001b[0m     global_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mglobal_step,\n\u001b[1;32m    234\u001b[0m     steps_per_loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39msteps_per_loop,\n\u001b[1;32m    235\u001b[0m     checkpoint_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_manager,\n\u001b[1;32m    236\u001b[0m     enable_async_checkpointing\u001b[38;5;241m=\u001b[39menable_async_checkpointing,\n\u001b[1;32m    237\u001b[0m     summary_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (save_summary)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    240\u001b[0m     eval_summary_dir\u001b[38;5;241m=\u001b[39meval_summary_dir,\n\u001b[1;32m    241\u001b[0m     summary_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39msummary_interval\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (save_summary)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    244\u001b[0m     train_actions\u001b[38;5;241m=\u001b[39mtrain_actions,\n\u001b[1;32m    245\u001b[0m     eval_actions\u001b[38;5;241m=\u001b[39meval_actions,\n\u001b[1;32m    246\u001b[0m     summary_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_manager\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_summary_manager\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    249\u001b[0m     eval_summary_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_summary_manager\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_summary_manager\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    252\u001b[0m )\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m controller\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/orbit/controller.py:250\u001b[0m, in \u001b[0;36mController.__init__\u001b[0;34m(self, global_step, trainer, evaluator, strategy, train_actions, eval_actions, steps_per_loop, checkpoint_manager, enable_async_checkpointing, summary_interval, summary_dir, eval_summary_dir, summary_manager, eval_summary_manager)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Restores the model if needed.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m   restored_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_checkpoint()\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m restored_path:\n\u001b[1;32m    252\u001b[0m     _log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestored from checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/orbit/controller.py:464\u001b[0m, in \u001b[0;36mController.restore_checkpoint\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     _log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestoring or initializing model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_manager\u001b[38;5;241m.\u001b[39mrestore_or_initialize()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m   _log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestored model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint_management.py:886\u001b[0m, in \u001b[0;36mCheckpointManager.restore_or_initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_latest_checkpoint\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 886\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn()\n\u001b[1;32m    887\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    888\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomized initialization is done through the passed `init_fn`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/base_trainer.py:330\u001b[0m, in \u001b[0;36mTrainer.initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    323\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"A callback function.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m  This function will be called when no checkpoint found for the model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m  pretrained checkpoint, saved under a directory other than the model_dir.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39minitialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/vision/tasks/maskrcnn.py:125\u001b[0m, in \u001b[0;36mMaskRCNNTask.initialize\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    122\u001b[0m     ckpt_items\u001b[38;5;241m.\u001b[39mupdate(decoder\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecoder)\n\u001b[1;32m    124\u001b[0m   ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mckpt_items)\n\u001b[0;32m--> 125\u001b[0m   status \u001b[38;5;241m=\u001b[39m ckpt\u001b[38;5;241m.\u001b[39mread(ckpt_dir_or_file)\n\u001b[1;32m    126\u001b[0m   status\u001b[38;5;241m.\u001b[39mexpect_partial()\u001b[38;5;241m.\u001b[39massert_existing_objects_matched()\n\u001b[1;32m    128\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished loading pretrained checkpoint from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    129\u001b[0m              ckpt_dir_or_file)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py:2595\u001b[0m, in \u001b[0;36mCheckpoint.read\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2593\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(save_path)\n\u001b[1;32m   2594\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[0;32m-> 2595\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saver\u001b[38;5;241m.\u001b[39mrestore(save_path\u001b[38;5;241m=\u001b[39msave_path, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m   2596\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAddCheckpointReadDuration(\n\u001b[1;32m   2597\u001b[0m     api_label\u001b[38;5;241m=\u001b[39m_CHECKPOINT_V2,\n\u001b[1;32m   2598\u001b[0m     microseconds\u001b[38;5;241m=\u001b[39m_get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py:1456\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ASYNC_CHECKPOINT_THREAD \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1455\u001b[0m   _ASYNC_CHECKPOINT_THREAD\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[0;32m-> 1456\u001b[0m reader \u001b[38;5;241m=\u001b[39m py_checkpoint_reader\u001b[38;5;241m.\u001b[39mNewCheckpointReader(save_path)\n\u001b[1;32m   1457\u001b[0m graph_building \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_building:\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:92\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A function that returns a CheckPointReader.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m  A CheckpointReader object.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointReader(compat\u001b[38;5;241m.\u001b[39mas_bytes(filepattern))\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080: FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 77 meaning 'Problem with the SSL CA cert (path? access rights?)', error details: error setting certificate verify locations:  CAfile: /etc/ssl/certs/ca-certificates.crt CApath: none\n\t when reading gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet"
     ]
    }
   ],
   "source": [
    "send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "with intercept_stdout(tfm_log):\n",
    "    model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train_and_eval',\n",
    "        params=exp_config,\n",
    "        model_dir=MODEL_DIR,\n",
    "        run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'{MODEL_DIR}/final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow Models",
   "language": "python",
   "name": "tf_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
