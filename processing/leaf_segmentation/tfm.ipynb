{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:29:10.312231: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-15 12:29:10.326402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-15 12:29:10.341753: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-15 12:29:10.341787: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-15 12:29:10.353931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 12:29:11.515897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial\n",
    "from tfm_configs import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (640, 640)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "MODEL = \"retinanet_resnet_fpn\"\n",
    "MODEL_DIR = \"out/\" + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_config = retinanet_resnet_fpn(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution Strategy on Device /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:29:13.414125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45531 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:29:15.018258: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 100\n",
    "num_of_examples = 3\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "show_batch(raw_records)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_notification(text):\n",
    "    if \"loss\" not in text:\n",
    "        return\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    losses.reverse()\n",
    "    msg = f\"Step #{step}:\" + ' - '.join([f\"{name} Loss: {value}\" for name, value in losses])\n",
    "    send_pushover_notification(msg, title=\"Training Losses\", priority=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring or initializing model...\n",
      "INFO:tensorflow:Customized initialization is done through the passed `init_fn`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Customized initialization is done through the passed `init_fn`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:      0 | training until step 1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:30:07.199456: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:     10 | steps/sec:    0.3 | output: \n",
      "    {'box_loss': 0.014008077,\n",
      "     'cls_loss': 1.0341163,\n",
      "     'learning_rate': 0.008966,\n",
      "     'model_loss': 1.7345202,\n",
      "     'total_loss': 3.1880755,\n",
      "     'training_loss': 3.1880755}\n",
      "saved checkpoint to out/retinanet_resnet_fpn/ckpt-10.\n",
      "train | step:     20 | steps/sec:    2.7 | output: \n",
      "    {'box_loss': 0.014395595,\n",
      "     'cls_loss': 0.90597135,\n",
      "     'learning_rate': 0.011232,\n",
      "     'model_loss': 1.6257509,\n",
      "     'total_loss': 3.0796216,\n",
      "     'training_loss': 3.0796216}\n",
      "train | step:     30 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.013434304,\n",
      "     'cls_loss': 0.7964223,\n",
      "     'learning_rate': 0.013497999,\n",
      "     'model_loss': 1.4681375,\n",
      "     'total_loss': 2.9233592,\n",
      "     'training_loss': 2.9233592}\n",
      "train | step:     40 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.012509008,\n",
      "     'cls_loss': 0.76129615,\n",
      "     'learning_rate': 0.015763998,\n",
      "     'model_loss': 1.3867466,\n",
      "     'total_loss': 2.843331,\n",
      "     'training_loss': 2.843331}\n",
      "train | step:     50 | steps/sec:    3.5 | output: \n",
      "    {'box_loss': 0.012202148,\n",
      "     'cls_loss': 0.7331151,\n",
      "     'learning_rate': 0.018029999,\n",
      "     'model_loss': 1.3432224,\n",
      "     'total_loss': 2.8008633,\n",
      "     'training_loss': 2.8008633}\n",
      "train | step:     60 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.0116725955,\n",
      "     'cls_loss': 0.7164639,\n",
      "     'learning_rate': 0.020296,\n",
      "     'model_loss': 1.3000939,\n",
      "     'total_loss': 2.758438,\n",
      "     'training_loss': 2.758438}\n",
      "train | step:     70 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.011692016,\n",
      "     'cls_loss': 0.8071607,\n",
      "     'learning_rate': 0.022561999,\n",
      "     'model_loss': 1.3917615,\n",
      "     'total_loss': 2.8505638,\n",
      "     'training_loss': 2.8505638}\n",
      "train | step:     80 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.01125156,\n",
      "     'cls_loss': 0.75584227,\n",
      "     'learning_rate': 0.024827998,\n",
      "     'model_loss': 1.3184203,\n",
      "     'total_loss': 2.7776442,\n",
      "     'training_loss': 2.7776442}\n",
      "train | step:     90 | steps/sec:    4.3 | output: \n",
      "    {'box_loss': 0.011751915,\n",
      "     'cls_loss': 1.0440248,\n",
      "     'learning_rate': 0.027094,\n",
      "     'model_loss': 1.6316206,\n",
      "     'total_loss': 3.0909653,\n",
      "     'training_loss': 3.0909653}\n",
      "train | step:    100 | steps/sec:    4.3 | output: \n",
      "    {'box_loss': 0.010613307,\n",
      "     'cls_loss': 1.2447236,\n",
      "     'learning_rate': 0.02936,\n",
      "     'model_loss': 1.7753887,\n",
      "     'total_loss': 3.234995,\n",
      "     'training_loss': 3.234995}\n",
      "train | step:    110 | steps/sec:    3.4 | output: \n",
      "    {'box_loss': 0.0111261355,\n",
      "     'cls_loss': 1.0885319,\n",
      "     'learning_rate': 0.031626,\n",
      "     'model_loss': 1.6448387,\n",
      "     'total_loss': 3.104413,\n",
      "     'training_loss': 3.104413}\n",
      "train | step:    120 | steps/sec:    3.6 | output: \n",
      "    {'box_loss': 0.011850452,\n",
      "     'cls_loss': 1.2058866,\n",
      "     'learning_rate': 0.033892,\n",
      "     'model_loss': 1.7984091,\n",
      "     'total_loss': 3.2596526,\n",
      "     'training_loss': 3.2596526}\n",
      "train | step:    130 | steps/sec:    3.4 | output: \n",
      "    {'box_loss': 0.0112471795,\n",
      "     'cls_loss': 1.008,\n",
      "     'learning_rate': 0.036157995,\n",
      "     'model_loss': 1.570359,\n",
      "     'total_loss': 3.0345135,\n",
      "     'training_loss': 3.0345135}\n",
      "train | step:    140 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.011803778,\n",
      "     'cls_loss': 0.8344078,\n",
      "     'learning_rate': 0.038424,\n",
      "     'model_loss': 1.4245968,\n",
      "     'total_loss': 2.889773,\n",
      "     'training_loss': 2.889773}\n",
      "train | step:    150 | steps/sec:    3.4 | output: \n",
      "    {'box_loss': 0.012069186,\n",
      "     'cls_loss': 0.80224544,\n",
      "     'learning_rate': 0.040689997,\n",
      "     'model_loss': 1.4057049,\n",
      "     'total_loss': 2.8707395,\n",
      "     'training_loss': 2.8707395}\n",
      "train | step:    160 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.011297867,\n",
      "     'cls_loss': 0.75208646,\n",
      "     'learning_rate': 0.042955995,\n",
      "     'model_loss': 1.3169798,\n",
      "     'total_loss': 2.7813268,\n",
      "     'training_loss': 2.7813268}\n",
      "train | step:    170 | steps/sec:    3.7 | output: \n",
      "    {'box_loss': 0.0108119305,\n",
      "     'cls_loss': 0.7341704,\n",
      "     'learning_rate': 0.045222,\n",
      "     'model_loss': 1.2747669,\n",
      "     'total_loss': 2.7381744,\n",
      "     'training_loss': 2.7381744}\n",
      "train | step:    180 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.01091588,\n",
      "     'cls_loss': 0.72019094,\n",
      "     'learning_rate': 0.047487997,\n",
      "     'model_loss': 1.2659851,\n",
      "     'total_loss': 2.7283163,\n",
      "     'training_loss': 2.7283163}\n",
      "train | step:    190 | steps/sec:    3.5 | output: \n",
      "    {'box_loss': 0.010712999,\n",
      "     'cls_loss': 0.7091981,\n",
      "     'learning_rate': 0.049754,\n",
      "     'model_loss': 1.2448481,\n",
      "     'total_loss': 2.7060184,\n",
      "     'training_loss': 2.7060184}\n",
      "train | step:    200 | steps/sec:    3.5 | output: \n",
      "    {'box_loss': 0.010751749,\n",
      "     'cls_loss': 0.68045866,\n",
      "     'learning_rate': 0.05202,\n",
      "     'model_loss': 1.2180461,\n",
      "     'total_loss': 2.677987,\n",
      "     'training_loss': 2.677987}\n",
      "train | step:    210 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.010810264,\n",
      "     'cls_loss': 0.77695966,\n",
      "     'learning_rate': 0.054285996,\n",
      "     'model_loss': 1.317473,\n",
      "     'total_loss': 2.7761688,\n",
      "     'training_loss': 2.7761688}\n",
      "train | step:    220 | steps/sec:    4.3 | output: \n",
      "    {'box_loss': 0.011145539,\n",
      "     'cls_loss': 0.9570178,\n",
      "     'learning_rate': 0.056552,\n",
      "     'model_loss': 1.5142947,\n",
      "     'total_loss': 2.9800544,\n",
      "     'training_loss': 2.9800544}\n",
      "train | step:    230 | steps/sec:    3.4 | output: \n",
      "    {'box_loss': 0.012917218,\n",
      "     'cls_loss': 4.2066565,\n",
      "     'learning_rate': 0.058817998,\n",
      "     'model_loss': 4.852517,\n",
      "     'total_loss': 6.342012,\n",
      "     'training_loss': 6.342012}\n",
      "train | step:    240 | steps/sec:    3.7 | output: \n",
      "    {'box_loss': 0.01659045,\n",
      "     'cls_loss': 2.5018137,\n",
      "     'learning_rate': 0.061083995,\n",
      "     'model_loss': 3.3313363,\n",
      "     'total_loss': 5.831787,\n",
      "     'training_loss': 5.831787}\n",
      "train | step:    250 | steps/sec:    4.3 | output: \n",
      "    {'box_loss': 0.013833789,\n",
      "     'cls_loss': 2.0482833,\n",
      "     'learning_rate': 0.06335,\n",
      "     'model_loss': 2.7399726,\n",
      "     'total_loss': 6.9361496,\n",
      "     'training_loss': 6.9361496}\n",
      "train | step:    260 | steps/sec:    3.6 | output: \n",
      "    {'box_loss': 0.012874188,\n",
      "     'cls_loss': 1.3386972,\n",
      "     'learning_rate': 0.065616,\n",
      "     'model_loss': 1.9824063,\n",
      "     'total_loss': 7.0138063,\n",
      "     'training_loss': 7.0138063}\n",
      "train | step:    270 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.01212434,\n",
      "     'cls_loss': 1.2305111,\n",
      "     'learning_rate': 0.067882,\n",
      "     'model_loss': 1.8367283,\n",
      "     'total_loss': 7.185525,\n",
      "     'training_loss': 7.185525}\n",
      "train | step:    280 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.011461461,\n",
      "     'cls_loss': 0.82010394,\n",
      "     'learning_rate': 0.070148,\n",
      "     'model_loss': 1.393177,\n",
      "     'total_loss': 6.8526278,\n",
      "     'training_loss': 6.8526278}\n",
      "train | step:    290 | steps/sec:    3.4 | output: \n",
      "    {'box_loss': 0.011830721,\n",
      "     'cls_loss': 0.7852022,\n",
      "     'learning_rate': 0.072413996,\n",
      "     'model_loss': 1.3767383,\n",
      "     'total_loss': 6.870786,\n",
      "     'training_loss': 6.870786}\n",
      "train | step:    300 | steps/sec:    4.1 | output: \n",
      "    {'box_loss': 0.011600366,\n",
      "     'cls_loss': 0.8677608,\n",
      "     'learning_rate': 0.07468,\n",
      "     'model_loss': 1.447779,\n",
      "     'total_loss': 6.948912,\n",
      "     'training_loss': 6.948912}\n",
      "train | step:    310 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.011703694,\n",
      "     'cls_loss': 0.9131589,\n",
      "     'learning_rate': 0.076946,\n",
      "     'model_loss': 1.4983435,\n",
      "     'total_loss': 6.996962,\n",
      "     'training_loss': 6.996962}\n",
      "train | step:    320 | steps/sec:    3.5 | output: \n",
      "    {'box_loss': 0.01117106,\n",
      "     'cls_loss': 0.77982515,\n",
      "     'learning_rate': 0.079211995,\n",
      "     'model_loss': 1.3383783,\n",
      "     'total_loss': 6.8320594,\n",
      "     'training_loss': 6.8320594}\n",
      "train | step:    330 | steps/sec:    4.1 | output: \n",
      "    {'box_loss': 0.011346059,\n",
      "     'cls_loss': 0.7467968,\n",
      "     'learning_rate': 0.081478,\n",
      "     'model_loss': 1.3140997,\n",
      "     'total_loss': 6.800992,\n",
      "     'training_loss': 6.800992}\n",
      "train | step:    340 | steps/sec:    3.4 | output: \n",
      "    {'box_loss': 0.011248824,\n",
      "     'cls_loss': 0.76597583,\n",
      "     'learning_rate': 0.083744,\n",
      "     'model_loss': 1.328417,\n",
      "     'total_loss': 6.807284,\n",
      "     'training_loss': 6.807284}\n",
      "train | step:    350 | steps/sec:    3.7 | output: \n",
      "    {'box_loss': 0.011122136,\n",
      "     'cls_loss': 0.7797203,\n",
      "     'learning_rate': 0.086009994,\n",
      "     'model_loss': 1.335827,\n",
      "     'total_loss': 6.8060517,\n",
      "     'training_loss': 6.8060517}\n",
      "train | step:    360 | steps/sec:    3.3 | output: \n",
      "    {'box_loss': 0.011066133,\n",
      "     'cls_loss': 0.7422627,\n",
      "     'learning_rate': 0.088276,\n",
      "     'model_loss': 1.2955694,\n",
      "     'total_loss': 6.756797,\n",
      "     'training_loss': 6.756797}\n",
      "train | step:    370 | steps/sec:    4.2 | output: \n",
      "    {'box_loss': 0.01101597,\n",
      "     'cls_loss': 0.73912543,\n",
      "     'learning_rate': 0.090541996,\n",
      "     'model_loss': 1.2899239,\n",
      "     'total_loss': 6.7418528,\n",
      "     'training_loss': 6.7418528}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m send_pushover_notification(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow Models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m intercept_stdout(send_notification):\n\u001b[0;32m----> 4\u001b[0m     model, eval_logs \u001b[38;5;241m=\u001b[39m tfm\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mtrain_lib\u001b[38;5;241m.\u001b[39mrun_experiment(\n\u001b[1;32m      5\u001b[0m         distribution_strategy\u001b[38;5;241m=\u001b[39mdistribution_strategy,\n\u001b[1;32m      6\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m      7\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_and_eval\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         params\u001b[38;5;241m=\u001b[39mexp_config,\n\u001b[1;32m      9\u001b[0m         model_dir\u001b[38;5;241m=\u001b[39mMODEL_DIR,\n\u001b[1;32m     10\u001b[0m         run_post_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:372\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(distribution_strategy, task, mode, params, model_dir, run_post_eval, save_summary, train_actions, eval_actions, trainer, controller_cls, summary_manager, eval_summary_manager, enable_async_checkpointing)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs train/eval configured by the experiment params.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m      otherwise, returns {}.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m runner \u001b[38;5;241m=\u001b[39m OrbitExperimentRunner(\n\u001b[1;32m    357\u001b[0m     distribution_strategy\u001b[38;5;241m=\u001b[39mdistribution_strategy,\n\u001b[1;32m    358\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m     enable_async_checkpointing\u001b[38;5;241m=\u001b[39menable_async_checkpointing,\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:271\u001b[0m, in \u001b[0;36mOrbitExperimentRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller\u001b[38;5;241m.\u001b[39mtrain(steps\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain_steps)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_and_eval\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller\u001b[38;5;241m.\u001b[39mtrain_and_evaluate(\n\u001b[1;32m    272\u001b[0m       train_steps\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain_steps,\n\u001b[1;32m    273\u001b[0m       eval_steps\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidation_steps,\n\u001b[1;32m    274\u001b[0m       eval_interval\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidation_interval)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    276\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller\u001b[38;5;241m.\u001b[39mevaluate(steps\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidation_steps)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/orbit/controller.py:393\u001b[0m, in \u001b[0;36mController.train_and_evaluate\u001b[0;34m(self, train_steps, eval_steps, eval_interval)\u001b[0m\n\u001b[1;32m    391\u001b[0m interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(train_steps \u001b[38;5;241m-\u001b[39m current_step, eval_interval)\n\u001b[1;32m    392\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m current_step \u001b[38;5;241m+\u001b[39m interval\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(steps\u001b[38;5;241m=\u001b[39mnum_steps, checkpoint_at_completion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    394\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(steps\u001b[38;5;241m=\u001b[39meval_steps)\n\u001b[1;32m    395\u001b[0m current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/orbit/controller.py:282\u001b[0m, in \u001b[0;36mController.train\u001b[0;34m(self, steps, checkpoint_at_completion)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_step \u001b[38;5;241m<\u001b[39m steps:\n\u001b[1;32m    280\u001b[0m   \u001b[38;5;66;03m# Calculates steps to run for the next train loop.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m   num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(steps \u001b[38;5;241m-\u001b[39m current_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_loop)\n\u001b[0;32m--> 282\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_n_steps(num_steps)\n\u001b[1;32m    283\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_save_checkpoint()\n\u001b[1;32m    284\u001b[0m   current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/orbit/controller.py:517\u001b[0m, in \u001b[0;36mController._train_n_steps\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m    515\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mrecord_if(should_record):\n\u001b[1;32m    516\u001b[0m     num_steps_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(num_steps, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m--> 517\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain(num_steps_tensor)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# Verify that global_step was updated properly, then update current_step.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m expected_step \u001b[38;5;241m=\u001b[39m current_step \u001b[38;5;241m+\u001b[39m num_steps\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/orbit/standard_runner.py:146\u001b[0m, in \u001b[0;36mStandardTrainer.train\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_iter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28miter\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_loop_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_iter, num_steps)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loop_end()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    870\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    871\u001b[0m   )\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "with intercept_stdout(send_notification):\n",
    "    model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train_and_eval',\n",
    "        params=exp_config,\n",
    "        model_dir=MODEL_DIR,\n",
    "        run_post_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'{MODEL_DIR}/final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow Models",
   "language": "python",
   "name": "tf_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
