{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (640, 640)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "MODEL = \"retina_net\"\n",
    "MODEL_DIR = \"out/\" + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_experiment_config():\n",
    "    # Create a base experiment config\n",
    "    exp_config = exp_factory.get_exp_config('retinanet_resnetfpn_coco')\n",
    "\n",
    "    exp_config.task.model.input_size = [IMAGE_SIZE[1], IMAGE_SIZE[0], 3]\n",
    "\n",
    "    # Modify the config as needed\n",
    "    exp_config.task.model.num_classes = 2  # Adjust based on your number of classes\n",
    "    \n",
    "    # Configure for custom dataset\n",
    "    exp_config.task.train_data.input_path = INPUT_PATH + \"*train*\"\n",
    "    exp_config.task.validation_data.input_path = INPUT_PATH + \"*val*\"\n",
    "    exp_config.task.train_data.global_batch_size = BATCH_SIZE\n",
    "    exp_config.task.validation_data.global_batch_size = BATCH_SIZE\n",
    "\n",
    "    # Disable COCO-specific configurations\n",
    "    exp_config.task.annotation_file = INPUT_PATH + \"instances.json\"\n",
    "    exp_config.task.use_coco_metrics = False\n",
    "\n",
    "    # Configure data parsers\n",
    "    exp_config.task.train_data.parser = exp_cfg.Parser()\n",
    "    exp_config.task.validation_data.parser = exp_cfg.Parser()\n",
    "\n",
    "    # Training parameters\n",
    "    train_steps = 224_000\n",
    "    exp_config.trainer.steps_per_loop = 200\n",
    "    exp_config.trainer.summary_interval = 200\n",
    "    exp_config.trainer.checkpoint_interval = 200\n",
    "    exp_config.trainer.validation_interval = 200\n",
    "    exp_config.trainer.validation_steps = 200\n",
    "    exp_config.trainer.train_steps = train_steps\n",
    "    exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 200\n",
    "    exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "    exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "    exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.07\n",
    "    exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05\n",
    "\n",
    "    return exp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_config = build_experiment_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    #plt.show()\n",
    "    plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buffer_size = 100\n",
    "num_of_examples = 3\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "show_batch(raw_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "with intercept_stdout(partial(send_pushover_notification, title=\"Tensorflow Models Training\", priority=-1)):\n",
    "    model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train',\n",
    "        params=exp_config,\n",
    "        MODEL_DIR=MODEL_DIR,\n",
    "        run_post_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'out/mask_rcnn_{time.time()}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
