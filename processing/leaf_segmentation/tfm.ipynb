{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial\n",
    "from tfm_configs import *\n",
    "import re\n",
    "import tensorflow_datasets as tfdsw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "#MODEL = \"maskrcnn_mobilenet_fpn\"\n",
    "#MODEL = \"retinanet_resnet_fpn\"\n",
    "MODEL = \"maskrcnn_resnet_fpn\"\n",
    "MODEL_DIR = \"out/\" + MODEL\n",
    "START = time.time()\n",
    "RESTORE_METRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exp_config = maskrcnn_mobilenet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config = retinanet_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "exp_config = maskrcnn_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config.trainer.validation_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution Strategy on Device /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:12:25.770952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79198 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:06:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vertical integrity not given [512, 12, 12, 12, 12, 12, 12] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([12])), ('groundtruth_is_crowd', TensorShape([12])), ('groundtruth_area', TensorShape([12])), ('groundtruth_boxes', TensorShape([12, 4])), ('groundtruth_instance_masks', TensorShape([12, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([12]))]\n",
      "Val vertical integrity not given [512, 3, 3, 3, 3, 3, 3] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([3])), ('groundtruth_is_crowd', TensorShape([3])), ('groundtruth_area', TensorShape([3])), ('groundtruth_boxes', TensorShape([3, 4])), ('groundtruth_instance_masks', TensorShape([3, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([3]))]\n",
      "Train vertical integrity not given [512, 8, 8, 8, 8, 8, 8] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([8])), ('groundtruth_is_crowd', TensorShape([8])), ('groundtruth_area', TensorShape([8])), ('groundtruth_boxes', TensorShape([8, 4])), ('groundtruth_instance_masks', TensorShape([8, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([8]))]\n",
      "Val vertical integrity not given [512, 5, 5, 5, 5, 5, 5] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([5])), ('groundtruth_is_crowd', TensorShape([5])), ('groundtruth_area', TensorShape([5])), ('groundtruth_boxes', TensorShape([5, 4])), ('groundtruth_instance_masks', TensorShape([5, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([5]))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:12:28.038654: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrity given\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 100\n",
    "num_of_examples = 2\n",
    "tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(raw_records)\n",
    "\n",
    "val_tfrecords = tf.io.gfile.glob(exp_config.task.validation_data.input_path)\n",
    "val_raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(val_raw_records)\n",
    "show = True\n",
    "for train, val in zip(raw_records, val_raw_records):\n",
    "    train_decoded = tf_ex_decoder.decode(train)\n",
    "    val_decoded = tf_ex_decoder.decode(val)\n",
    "    \n",
    "    for key in train_decoded.keys():\n",
    "        hor_ok = train_decoded[key].shape[1:] == val_decoded[key].shape[1:]\n",
    "        if not hor_ok:\n",
    "            print(\"Horizontal Integrity not given\", key, train_decoded[key].shape[1:], val_decoded[key].shape[1:])\n",
    "\n",
    "    sizes_train = [train_decoded[key].shape[0] for key in train_decoded.keys() if len(train_decoded[key].shape) > 0]\n",
    "    train_ver_ok = len(set(sizes_train)) == 1\n",
    "    if not train_ver_ok:\n",
    "        print(\"Train vertical integrity not given\", sizes_train,  [(key, value.shape) for key, value in train_decoded.items()])\n",
    "\n",
    "    sizes_val = [val_decoded[key].shape[0] for key in val_decoded.keys() if len(val_decoded[key].shape) > 0]\n",
    "    val_ver_ok = len(set(sizes_val)) == 1\n",
    "    if not val_ver_ok:\n",
    "        print(\"Val vertical integrity not given\", sizes_val, [(key, value.shape) for key, value in val_decoded.items()])\n",
    "print(\"integrity given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_notification(text):\n",
    "    if \"loss\" not in text or 'eval' not in text:\n",
    "        return\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    losses.reverse()\n",
    "    msg = f\"Step #{step}:\" + ' - '.join([f\"{name} Loss: {value}\" for name, value in losses])\n",
    "    send_pushover_notification(msg, title=\"Training Losses\", priority=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "data_val = []\n",
    "os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "\n",
    "if RESTORE_METRICS:\n",
    "    files = os.listdir(f\"metrics/{MODEL}\")\n",
    "    vals = [file for file in files if \"val\" in file]\n",
    "    trains = [file for file in files if \"train\" in file]\n",
    "    vals.sort()\n",
    "    trains.sort()\n",
    "    last_val = vals[-1]\n",
    "    last_train = trains[-1]\n",
    "    data_train = pd.read_csv(os.path.join(f\"metrics/{MODEL}\", last_train)).to_dict('records')\n",
    "    data_val = pd.read_csv(os.path.join(f\"metrics/{MODEL}\", last_val)).to_dict('records')\n",
    "    \n",
    "def log_eval(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    metrics_dict = re.findall(r\"\\s+.'(.*?)':\\s(.*\\d)\", text)\n",
    "    metrics = {name: value for name, value in metrics_dict}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "    \n",
    "    data_val.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_val)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_val_{START}.csv\", index=False)\n",
    "    \n",
    "def log_train(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    metrics = {name: value for name, value in losses}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "\n",
    "    data_train.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_train)\n",
    "    os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_train_{START}.csv\", index=False)\n",
    "    \n",
    "    \n",
    "def tfm_log(text):\n",
    "    if \"output\" not in text:\n",
    "        return\n",
    "    if \"eval\" in text:\n",
    "        log_eval(text)\n",
    "        return\n",
    "    if \"train\" in text:\n",
    "        log_train(text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "restoring or initializing model...\n",
      "restored model from out/maskrcnn_resnet_fpn/ckpt-270000.\n",
      "restored from checkpoint: out/maskrcnn_resnet_fpn/ckpt-270000\n",
      "train | step:  270000 | training until step 275000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1722863577.180679  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -59 } dim { size: -44 } dim { size: -45 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 15:13:35.781040: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:  271000 | steps/sec:    2.7 | output: \n",
      "    {'frcnn_box_loss': 0.05139713,\n",
      "     'frcnn_cls_loss': 0.050842848,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06875492,\n",
      "     'model_loss': 0.1891505,\n",
      "     'rpn_box_loss': 0.015411905,\n",
      "     'rpn_score_loss': 0.0027436644,\n",
      "     'total_loss': 0.31159836,\n",
      "     'training_loss': 0.31159836}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-271000.\n",
      "train | step:  272000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.051524423,\n",
      "     'frcnn_cls_loss': 0.05096751,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.07042903,\n",
      "     'model_loss': 0.1905939,\n",
      "     'rpn_box_loss': 0.014957339,\n",
      "     'rpn_score_loss': 0.0027156558,\n",
      "     'total_loss': 0.31274584,\n",
      "     'training_loss': 0.31274584}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-272000.\n",
      "train | step:  273000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04997954,\n",
      "     'frcnn_cls_loss': 0.049678482,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06671983,\n",
      "     'model_loss': 0.18361267,\n",
      "     'rpn_box_loss': 0.01453308,\n",
      "     'rpn_score_loss': 0.0027017437,\n",
      "     'total_loss': 0.30545485,\n",
      "     'training_loss': 0.30545485}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-273000.\n",
      "train | step:  274000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.049955074,\n",
      "     'frcnn_cls_loss': 0.049649816,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.065327905,\n",
      "     'model_loss': 0.18271534,\n",
      "     'rpn_box_loss': 0.015013081,\n",
      "     'rpn_score_loss': 0.002769457,\n",
      "     'total_loss': 0.30425695,\n",
      "     'training_loss': 0.30425695}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-274000.\n",
      "train | step:  275000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.05051561,\n",
      "     'frcnn_cls_loss': 0.050074786,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06698735,\n",
      "     'model_loss': 0.18504906,\n",
      "     'rpn_box_loss': 0.014776782,\n",
      "     'rpn_score_loss': 0.0026946517,\n",
      "     'total_loss': 0.30627096,\n",
      "     'training_loss': 0.30627096}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-275000.\n",
      " eval | step:  275000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722865209.506579  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 15:40:36.517115: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 15:40:36.517285: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 15:40:37.392824: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.865\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.807\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.759\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.767\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.390\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  275000 | steps/sec:    6.2 | eval time:   82.2 sec | output: \n",
      "    {'AP': 0.7397154,\n",
      "     'AP50': 0.8649204,\n",
      "     'AP75': 0.8069141,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.75907123,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17800036,\n",
      "     'ARmax10': 0.76746076,\n",
      "     'ARmax100': 0.77024,\n",
      "     'ARs': 0.77024,\n",
      "     'mask_AP': 0.26228377,\n",
      "     'mask_AP50': 0.390014,\n",
      "     'mask_AP75': 0.26284164,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.33670288,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.10537809,\n",
      "     'mask_ARmax10': 0.4435842,\n",
      "     'mask_ARmax100': 0.44463092,\n",
      "     'mask_ARs': 0.44463092,\n",
      "     'steps_per_second': 6.22637420343337,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  275000 | training until step 280000...\n",
      "train | step:  276000 | steps/sec:    2.5 | output: \n",
      "    {'frcnn_box_loss': 0.050333116,\n",
      "     'frcnn_cls_loss': 0.049814057,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06956375,\n",
      "     'model_loss': 0.18739313,\n",
      "     'rpn_box_loss': 0.014959747,\n",
      "     'rpn_score_loss': 0.0027226014,\n",
      "     'total_loss': 0.30831388,\n",
      "     'training_loss': 0.30831388}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-276000.\n",
      "train | step:  277000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.050907448,\n",
      "     'frcnn_cls_loss': 0.049752902,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.068043716,\n",
      "     'model_loss': 0.18625864,\n",
      "     'rpn_box_loss': 0.014817546,\n",
      "     'rpn_score_loss': 0.002737079,\n",
      "     'total_loss': 0.30689165,\n",
      "     'training_loss': 0.30689165}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-277000.\n",
      "train | step:  278000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.05139464,\n",
      "     'frcnn_cls_loss': 0.049939822,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.067343004,\n",
      "     'model_loss': 0.1858761,\n",
      "     'rpn_box_loss': 0.014560391,\n",
      "     'rpn_score_loss': 0.0026381954,\n",
      "     'total_loss': 0.30621096,\n",
      "     'training_loss': 0.30621096}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-278000.\n",
      "train | step:  279000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.050732553,\n",
      "     'frcnn_cls_loss': 0.04923348,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06881878,\n",
      "     'model_loss': 0.18651801,\n",
      "     'rpn_box_loss': 0.014945005,\n",
      "     'rpn_score_loss': 0.0027882175,\n",
      "     'total_loss': 0.30655518,\n",
      "     'training_loss': 0.30655518}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-279000.\n",
      "train | step:  280000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.05130959,\n",
      "     'frcnn_cls_loss': 0.049592994,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.069565274,\n",
      "     'model_loss': 0.18859391,\n",
      "     'rpn_box_loss': 0.01537442,\n",
      "     'rpn_score_loss': 0.00275171,\n",
      "     'total_loss': 0.30837032,\n",
      "     'training_loss': 0.30837032}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-280000.\n",
      " eval | step:  280000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722866876.223516  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 16:08:13.646536: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 16:08:13.646643: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 16:08:13.681333: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.60s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.856\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.795\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.740\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.761\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.761\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  280000 | steps/sec:    7.1 | eval time:   71.9 sec | output: \n",
      "    {'AP': 0.730646,\n",
      "     'AP50': 0.85578907,\n",
      "     'AP75': 0.7946529,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.7396496,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17785598,\n",
      "     'ARmax10': 0.75957406,\n",
      "     'ARmax100': 0.76132464,\n",
      "     'ARs': 0.76132464,\n",
      "     'mask_AP': 0.032425698,\n",
      "     'mask_AP50': 0.058299705,\n",
      "     'mask_AP75': 0.030538691,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.0453911,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.04085905,\n",
      "     'mask_ARmax10': 0.15257174,\n",
      "     'mask_ARmax100': 0.15257174,\n",
      "     'mask_ARs': 0.15257174,\n",
      "     'steps_per_second': 7.120533236009243,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  280000 | training until step 285000...\n",
      "train | step:  281000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.05141763,\n",
      "     'frcnn_cls_loss': 0.05056659,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.07010833,\n",
      "     'model_loss': 0.18996966,\n",
      "     'rpn_box_loss': 0.01511285,\n",
      "     'rpn_score_loss': 0.0027642513,\n",
      "     'total_loss': 0.30949634,\n",
      "     'training_loss': 0.30949634}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-281000.\n",
      "train | step:  282000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.0507017,\n",
      "     'frcnn_cls_loss': 0.049381617,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.067005835,\n",
      "     'model_loss': 0.18485798,\n",
      "     'rpn_box_loss': 0.015042949,\n",
      "     'rpn_score_loss': 0.0027260098,\n",
      "     'total_loss': 0.30411643,\n",
      "     'training_loss': 0.30411643}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-282000.\n",
      "train | step:  283000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.050689545,\n",
      "     'frcnn_cls_loss': 0.049169872,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06651513,\n",
      "     'model_loss': 0.18465182,\n",
      "     'rpn_box_loss': 0.015537116,\n",
      "     'rpn_score_loss': 0.00274008,\n",
      "     'total_loss': 0.30360812,\n",
      "     'training_loss': 0.30360812}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-283000.\n",
      "train | step:  284000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.049706202,\n",
      "     'frcnn_cls_loss': 0.04840481,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06589464,\n",
      "     'model_loss': 0.18126534,\n",
      "     'rpn_box_loss': 0.01473625,\n",
      "     'rpn_score_loss': 0.0025234835,\n",
      "     'total_loss': 0.29992005,\n",
      "     'training_loss': 0.29992005}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-284000.\n",
      "train | step:  285000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.049894348,\n",
      "     'frcnn_cls_loss': 0.048494447,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.066529736,\n",
      "     'model_loss': 0.18245576,\n",
      "     'rpn_box_loss': 0.014878001,\n",
      "     'rpn_score_loss': 0.002659252,\n",
      "     'total_loss': 0.30081308,\n",
      "     'training_loss': 0.30081308}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-285000.\n",
      " eval | step:  285000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722868526.282383  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 16:35:43.756276: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 16:35:43.756417: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 16:35:43.791568: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.48s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.854\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.793\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.732\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  285000 | steps/sec:    7.2 | eval time:   70.8 sec | output: \n",
      "    {'AP': 0.7233456,\n",
      "     'AP50': 0.8537694,\n",
      "     'AP75': 0.7929168,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.73158413,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17632197,\n",
      "     'ARmax10': 0.755351,\n",
      "     'ARmax100': 0.75787765,\n",
      "     'ARs': 0.75787765,\n",
      "     'mask_AP': 0.01700585,\n",
      "     'mask_AP50': 0.031871155,\n",
      "     'mask_AP75': 0.0156011665,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.023521455,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.028298141,\n",
      "     'mask_ARmax10': 0.107922755,\n",
      "     'mask_ARmax100': 0.107994944,\n",
      "     'mask_ARs': 0.107994944,\n",
      "     'steps_per_second': 7.231371578107855,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  285000 | training until step 290000...\n",
      "train | step:  286000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.04928767,\n",
      "     'frcnn_cls_loss': 0.04830147,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06588361,\n",
      "     'model_loss': 0.18004511,\n",
      "     'rpn_box_loss': 0.01403002,\n",
      "     'rpn_score_loss': 0.0025424017,\n",
      "     'total_loss': 0.2981094,\n",
      "     'training_loss': 0.2981094}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-286000.\n",
      "train | step:  287000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.05047389,\n",
      "     'frcnn_cls_loss': 0.049663533,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06545757,\n",
      "     'model_loss': 0.18347725,\n",
      "     'rpn_box_loss': 0.015138556,\n",
      "     'rpn_score_loss': 0.0027438207,\n",
      "     'total_loss': 0.30125538,\n",
      "     'training_loss': 0.30125538}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-287000.\n",
      "train | step:  288000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04975453,\n",
      "     'frcnn_cls_loss': 0.04940835,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06850941,\n",
      "     'model_loss': 0.1858662,\n",
      "     'rpn_box_loss': 0.015568734,\n",
      "     'rpn_score_loss': 0.0026252035,\n",
      "     'total_loss': 0.30336398,\n",
      "     'training_loss': 0.30336398}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-288000.\n",
      "train | step:  289000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.050157223,\n",
      "     'frcnn_cls_loss': 0.05020259,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06600734,\n",
      "     'model_loss': 0.18438986,\n",
      "     'rpn_box_loss': 0.015283713,\n",
      "     'rpn_score_loss': 0.0027389536,\n",
      "     'total_loss': 0.30163965,\n",
      "     'training_loss': 0.30163965}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-289000.\n",
      "train | step:  290000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.049228054,\n",
      "     'frcnn_cls_loss': 0.04884257,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06574743,\n",
      "     'model_loss': 0.18065673,\n",
      "     'rpn_box_loss': 0.014237059,\n",
      "     'rpn_score_loss': 0.002601588,\n",
      "     'total_loss': 0.29763386,\n",
      "     'training_loss': 0.29763386}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-290000.\n",
      " eval | step:  290000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722870174.299493  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 17:03:11.705198: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 17:03:11.705574: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 17:03:11.740568: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.804\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.747\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.769\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  290000 | steps/sec:    7.2 | eval time:   70.9 sec | output: \n",
      "    {'AP': 0.7403438,\n",
      "     'AP50': 0.8567705,\n",
      "     'AP75': 0.80424523,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.7470905,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.1791554,\n",
      "     'ARmax10': 0.76863384,\n",
      "     'ARmax100': 0.7703122,\n",
      "     'ARs': 0.7703122,\n",
      "     'mask_AP': 0.008344075,\n",
      "     'mask_AP50': 0.01732233,\n",
      "     'mask_AP75': 0.0068691885,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.011240846,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.01959935,\n",
      "     'mask_ARmax10': 0.075924926,\n",
      "     'mask_ARmax100': 0.075924926,\n",
      "     'mask_ARs': 0.075924926,\n",
      "     'steps_per_second': 7.221361657275137,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  290000 | training until step 295000...\n",
      "train | step:  291000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.050450437,\n",
      "     'frcnn_cls_loss': 0.05010034,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06628544,\n",
      "     'model_loss': 0.18448883,\n",
      "     'rpn_box_loss': 0.014968279,\n",
      "     'rpn_score_loss': 0.0026844607,\n",
      "     'total_loss': 0.30118185,\n",
      "     'training_loss': 0.30118185}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-291000.\n",
      "train | step:  292000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04873123,\n",
      "     'frcnn_cls_loss': 0.04794478,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.066040784,\n",
      "     'model_loss': 0.17932478,\n",
      "     'rpn_box_loss': 0.014017455,\n",
      "     'rpn_score_loss': 0.0025906158,\n",
      "     'total_loss': 0.29574594,\n",
      "     'training_loss': 0.29574594}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-292000.\n",
      "train | step:  293000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04972917,\n",
      "     'frcnn_cls_loss': 0.048854552,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06636109,\n",
      "     'model_loss': 0.18263812,\n",
      "     'rpn_box_loss': 0.015075983,\n",
      "     'rpn_score_loss': 0.0026172206,\n",
      "     'total_loss': 0.29878142,\n",
      "     'training_loss': 0.29878142}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-293000.\n",
      "train | step:  294000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.048701532,\n",
      "     'frcnn_cls_loss': 0.047976904,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06615641,\n",
      "     'model_loss': 0.18092722,\n",
      "     'rpn_box_loss': 0.015484541,\n",
      "     'rpn_score_loss': 0.0026077025,\n",
      "     'total_loss': 0.2967973,\n",
      "     'training_loss': 0.2967973}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-294000.\n",
      "train | step:  295000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.048281934,\n",
      "     'frcnn_cls_loss': 0.047780074,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.064615175,\n",
      "     'model_loss': 0.1773454,\n",
      "     'rpn_box_loss': 0.014046106,\n",
      "     'rpn_score_loss': 0.00262206,\n",
      "     'total_loss': 0.29293334,\n",
      "     'training_loss': 0.29293334}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-295000.\n",
      " eval | step:  295000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722871816.888597  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 17:30:34.406552: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 17:30:34.407115: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 17:30:34.441537: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.852\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.798\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.738\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.766\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.75s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  295000 | steps/sec:    7.2 | eval time:   70.7 sec | output: \n",
      "    {'AP': 0.73177344,\n",
      "     'AP50': 0.85157055,\n",
      "     'AP75': 0.79797494,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.73800105,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.1773687,\n",
      "     'ARmax10': 0.7664501,\n",
      "     'ARmax100': 0.7696084,\n",
      "     'ARs': 0.7696084,\n",
      "     'mask_AP': 0.005423238,\n",
      "     'mask_AP50': 0.011866057,\n",
      "     'mask_AP75': 0.0040096617,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.00697964,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.016711785,\n",
      "     'mask_ARmax10': 0.05807616,\n",
      "     'mask_ARmax100': 0.058328822,\n",
      "     'mask_ARs': 0.058328822,\n",
      "     'steps_per_second': 7.2410814865318756,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  295000 | training until step 300000...\n",
      "train | step:  296000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.04849937,\n",
      "     'frcnn_cls_loss': 0.047707096,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06396207,\n",
      "     'model_loss': 0.17757185,\n",
      "     'rpn_box_loss': 0.01483293,\n",
      "     'rpn_score_loss': 0.0025703826,\n",
      "     'total_loss': 0.29288074,\n",
      "     'training_loss': 0.29288074}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-296000.\n",
      "train | step:  297000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04914861,\n",
      "     'frcnn_cls_loss': 0.04818347,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06775462,\n",
      "     'model_loss': 0.18266156,\n",
      "     'rpn_box_loss': 0.014998839,\n",
      "     'rpn_score_loss': 0.0025760378,\n",
      "     'total_loss': 0.2977039,\n",
      "     'training_loss': 0.2977039}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-297000.\n",
      "train | step:  298000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04914999,\n",
      "     'frcnn_cls_loss': 0.047680926,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06593906,\n",
      "     'model_loss': 0.17974925,\n",
      "     'rpn_box_loss': 0.014416828,\n",
      "     'rpn_score_loss': 0.0025624908,\n",
      "     'total_loss': 0.29453444,\n",
      "     'training_loss': 0.29453444}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-298000.\n",
      "train | step:  299000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04799182,\n",
      "     'frcnn_cls_loss': 0.04720881,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06438705,\n",
      "     'model_loss': 0.17732103,\n",
      "     'rpn_box_loss': 0.015174559,\n",
      "     'rpn_score_loss': 0.0025586467,\n",
      "     'total_loss': 0.29183927,\n",
      "     'training_loss': 0.29183927}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-299000.\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.53s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.804\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.748\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.773\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.773\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.82s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  300000 | steps/sec:    7.2 | eval time:   70.9 sec | output: \n",
      "    {'AP': 0.74085724,\n",
      "     'AP50': 0.86426425,\n",
      "     'AP75': 0.8040977,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.7481944,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17789207,\n",
      "     'ARmax10': 0.77033025,\n",
      "     'ARmax100': 0.7729832,\n",
      "     'ARs': 0.7729832,\n",
      "     'mask_AP': 0.006389861,\n",
      "     'mask_AP50': 0.014543108,\n",
      "     'mask_AP75': 0.0049224366,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.00857727,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.017217109,\n",
      "     'mask_ARmax10': 0.06691933,\n",
      "     'mask_ARmax100': 0.067226134,\n",
      "     'mask_ARs': 0.067226134,\n",
      "     'steps_per_second': 7.218391813149932,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  300000 | training until step 305000...\n",
      "train | step:  301000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.048799235,\n",
      "     'frcnn_cls_loss': 0.047288127,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.066815205,\n",
      "     'model_loss': 0.18041176,\n",
      "     'rpn_box_loss': 0.014955396,\n",
      "     'rpn_score_loss': 0.0025538467,\n",
      "     'total_loss': 0.29438335,\n",
      "     'training_loss': 0.29438335}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-301000.\n",
      "train | step:  302000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04895506,\n",
      "     'frcnn_cls_loss': 0.04853454,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06719706,\n",
      "     'model_loss': 0.18236315,\n",
      "     'rpn_box_loss': 0.014998152,\n",
      "     'rpn_score_loss': 0.0026782088,\n",
      "     'total_loss': 0.29608646,\n",
      "     'training_loss': 0.29608646}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-302000.\n",
      "train | step:  303000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.049111776,\n",
      "     'frcnn_cls_loss': 0.047932755,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06512184,\n",
      "     'model_loss': 0.17872508,\n",
      "     'rpn_box_loss': 0.014065772,\n",
      "     'rpn_score_loss': 0.002492944,\n",
      "     'total_loss': 0.29220805,\n",
      "     'training_loss': 0.29220805}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-303000.\n",
      "train | step:  304000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04705523,\n",
      "     'frcnn_cls_loss': 0.04616676,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06439169,\n",
      "     'model_loss': 0.17531492,\n",
      "     'rpn_box_loss': 0.015185995,\n",
      "     'rpn_score_loss': 0.0025152313,\n",
      "     'total_loss': 0.28852662,\n",
      "     'training_loss': 0.28852662}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-304000.\n",
      "train | step:  305000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.046874266,\n",
      "     'frcnn_cls_loss': 0.045736846,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06463488,\n",
      "     'model_loss': 0.1736306,\n",
      "     'rpn_box_loss': 0.01389605,\n",
      "     'rpn_score_loss': 0.0024886092,\n",
      "     'total_loss': 0.28656965,\n",
      "     'training_loss': 0.28656965}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-305000.\n",
      " eval | step:  305000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722875103.005925  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 18:25:20.400688: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 18:25:20.400778: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 18:25:20.435655: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.806\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.756\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.772\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.772\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  305000 | steps/sec:    7.3 | eval time:   70.4 sec | output: \n",
      "    {'AP': 0.7396049,\n",
      "     'AP50': 0.8569156,\n",
      "     'AP75': 0.80623716,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.75573087,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.1780906,\n",
      "     'ARmax10': 0.76996934,\n",
      "     'ARmax100': 0.772135,\n",
      "     'ARs': 0.772135,\n",
      "     'mask_AP': 0.097301036,\n",
      "     'mask_AP50': 0.17524216,\n",
      "     'mask_AP75': 0.09193175,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.14304464,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.06293088,\n",
      "     'mask_ARmax10': 0.27020395,\n",
      "     'mask_ARmax100': 0.2707634,\n",
      "     'mask_ARs': 0.2707634,\n",
      "     'steps_per_second': 7.272756203262089,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  305000 | training until step 310000...\n",
      "train | step:  306000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.048516057,\n",
      "     'frcnn_cls_loss': 0.046920385,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.0653251,\n",
      "     'model_loss': 0.17798199,\n",
      "     'rpn_box_loss': 0.0145441685,\n",
      "     'rpn_score_loss': 0.0026762763,\n",
      "     'total_loss': 0.2906514,\n",
      "     'training_loss': 0.2906514}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-306000.\n",
      "train | step:  307000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.048773628,\n",
      "     'frcnn_cls_loss': 0.04718015,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06819292,\n",
      "     'model_loss': 0.1818209,\n",
      "     'rpn_box_loss': 0.015056239,\n",
      "     'rpn_score_loss': 0.0026179964,\n",
      "     'total_loss': 0.29425043,\n",
      "     'training_loss': 0.29425043}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-307000.\n",
      "train | step:  308000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.0480186,\n",
      "     'frcnn_cls_loss': 0.047122847,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06654696,\n",
      "     'model_loss': 0.1783759,\n",
      "     'rpn_box_loss': 0.014254605,\n",
      "     'rpn_score_loss': 0.00243297,\n",
      "     'total_loss': 0.29055637,\n",
      "     'training_loss': 0.29055637}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-308000.\n",
      "train | step:  309000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.047853634,\n",
      "     'frcnn_cls_loss': 0.04731268,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06484291,\n",
      "     'model_loss': 0.17735553,\n",
      "     'rpn_box_loss': 0.01479037,\n",
      "     'rpn_score_loss': 0.0025559184,\n",
      "     'total_loss': 0.289304,\n",
      "     'training_loss': 0.289304}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-309000.\n",
      "train | step:  310000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04670806,\n",
      "     'frcnn_cls_loss': 0.046377175,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06504374,\n",
      "     'model_loss': 0.1744004,\n",
      "     'rpn_box_loss': 0.013812978,\n",
      "     'rpn_score_loss': 0.0024584623,\n",
      "     'total_loss': 0.2860893,\n",
      "     'training_loss': 0.2860893}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-310000.\n",
      " eval | step:  310000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722876759.158220  377156 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-05 18:52:56.695833: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-05 18:52:56.695940: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-05 18:52:56.731468: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.806\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.751\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.767\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.769\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.769\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  310000 | steps/sec:    6.2 | eval time:   82.2 sec | output: \n",
      "    {'AP': 0.73925483,\n",
      "     'AP50': 0.85674554,\n",
      "     'AP75': 0.80551094,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.7512233,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17722432,\n",
      "     'ARmax10': 0.7674427,\n",
      "     'ARmax100': 0.769085,\n",
      "     'ARs': 0.769085,\n",
      "     'mask_AP': 0.06332359,\n",
      "     'mask_AP50': 0.11293314,\n",
      "     'mask_AP75': 0.057801574,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.09007445,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.056722615,\n",
      "     'mask_ARmax10': 0.208392,\n",
      "     'mask_ARmax100': 0.20846418,\n",
      "     'mask_ARs': 0.20846418,\n",
      "     'steps_per_second': 6.232104178521419,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  310000 | training until step 315000...\n",
      "train | step:  311000 | steps/sec:    2.5 | output: \n",
      "    {'frcnn_box_loss': 0.04789157,\n",
      "     'frcnn_cls_loss': 0.045697477,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.064463556,\n",
      "     'model_loss': 0.17525,\n",
      "     'rpn_box_loss': 0.014720754,\n",
      "     'rpn_score_loss': 0.0024767441,\n",
      "     'total_loss': 0.28668725,\n",
      "     'training_loss': 0.28668725}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-311000.\n",
      "train | step:  312000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.047308315,\n",
      "     'frcnn_cls_loss': 0.046606746,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06568137,\n",
      "     'model_loss': 0.17707822,\n",
      "     'rpn_box_loss': 0.01496571,\n",
      "     'rpn_score_loss': 0.0025159095,\n",
      "     'total_loss': 0.28827173,\n",
      "     'training_loss': 0.28827173}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-312000.\n",
      "train | step:  313000 | steps/sec:    3.2 | output: \n",
      "    {'frcnn_box_loss': 0.04938364,\n",
      "     'frcnn_cls_loss': 0.04705968,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.06632872,\n",
      "     'model_loss': 0.18047048,\n",
      "     'rpn_box_loss': 0.015095457,\n",
      "     'rpn_score_loss': 0.0026030787,\n",
      "     'total_loss': 0.2914345,\n",
      "     'training_loss': 0.2914345}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-313000.\n"
     ]
    }
   ],
   "source": [
    "send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "with intercept_stdout(tfm_log):\n",
    "    model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train_and_eval',\n",
    "        params=exp_config,\n",
    "        model_dir=MODEL_DIR,\n",
    "        run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'{MODEL_DIR}/final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow Models",
   "language": "python",
   "name": "tf_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
