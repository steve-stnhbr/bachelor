{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 14:56:27.440056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-10 14:56:27.467223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-10 14:56:27.467281: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 14:56:27.484534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 14:56:28.437260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial\n",
    "from tfm_configs import *\n",
    "import re\n",
    "import tensorflow_datasets as tfdsw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "#MODEL = \"maskrcnn_mobilenet_fpn\"\n",
    "#MODEL = \"retinanet_resnet_fpn\"\n",
    "#MODEL = \"maskrcnn_resnet_fpn_coco\"\n",
    "MODEL = \"maskrcnn_resnet_fpn\"\n",
    "MODEL_DIR = \"out/\" + MODEL\n",
    "START = time.time()\n",
    "RESTORE_METRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exp_config = maskrcnn_mobilenet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config = retinanet_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config = custom_or_maskrcnn_resnetfpn_coco(\"_data/coco_synthetic_total.json\", \"_data/synthetic_leaf_instances/train/images/*\",    \"_data/synthetic_leaf_instances/val/images/*\",image_size=IMAGE_SIZE,pretrained=False)\n",
    "exp_config = maskrcnn_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config.trainer.validation_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(task=MaskRCNNTask(init_checkpoint='gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080', model=MaskRCNN(num_classes=2, input_size=[512, 512, 3], min_level=2, max_level=6, anchor=Anchor(num_scales=1, aspect_ratios=[0.5, 1.0, 2.0], anchor_size=8.0), include_mask=True, outer_boxes_scale=1.0, backbone=Backbone(type='resnet', resnet=ResNet(model_id=50, depth_multiplier=1.0, stem_type='v0', se_ratio=0.0, stochastic_depth_drop_rate=0.0, scale_stem=True, resnetd_shortcut=False, replace_stem_max_pool=False, bn_trainable=True), dilated_resnet=DilatedResNet(model_id=50, output_stride=16, multigrid=None, stem_type='v0', last_stage_repeats=1, se_ratio=0.0, stochastic_depth_drop_rate=0.0, resnetd_shortcut=False, replace_stem_max_pool=False), revnet=RevNet(model_id=56), efficientnet=EfficientNet(model_id='b0', se_ratio=0.0, stochastic_depth_drop_rate=0.0), spinenet=SpineNet(model_id='49', stochastic_depth_drop_rate=0.0, min_level=3, max_level=7), spinenet_mobile=SpineNetMobile(model_id='49', stochastic_depth_drop_rate=0.0, se_ratio=0.2, expand_ratio=6, min_level=3, max_level=7, use_keras_upsampling_2d=False), mobilenet=MobileNet(model_id='MobileNetV2', filter_size_scale=1.0, stochastic_depth_drop_rate=0.0, output_stride=None, output_intermediate_endpoints=False), mobiledet=MobileDet(model_id='MobileDetCPU', filter_size_scale=1.0), vit=VisionTransformer(model_name='vit-b16', pooler='token', representation_size=0, hidden_size=1, patch_size=16, transformer=Transformer(mlp_dim=1, num_heads=1, num_layers=1, attention_dropout_rate=0.0, dropout_rate=0.0), init_stochastic_depth_rate=0.0, original_init=True, pos_embed_shape=None, output_encoded_tokens=True, output_2d_feature_maps=False, layer_scale_init_value=0.0, transformer_partition_dims=None)), decoder=Decoder(type='fpn', fpn=FPN(num_filters=256, fusion_type='sum', use_separable_conv=False, use_keras_layer=False), nasfpn=NASFPN(num_filters=256, num_repeats=5, use_separable_conv=False), identity=Identity(), aspp=ASPP(level=4, dilation_rates=[], dropout_rate=0.0, num_filters=256, use_depthwise_convolution=False, pool_kernel_size=None, spp_layer_version='v1', output_tensor=False)), rpn_head=RPNHead(num_convs=1, num_filters=256, use_separable_conv=False), detection_head=DetectionHead(num_convs=4, num_filters=256, use_separable_conv=False, num_fcs=1, fc_dims=1024, class_agnostic_bbox_pred=False, cascade_class_ensemble=False), roi_generator=ROIGenerator(pre_nms_top_k=2000, pre_nms_score_threshold=0.0, pre_nms_min_size_threshold=0.0, nms_iou_threshold=0.7, num_proposals=1000, test_pre_nms_top_k=1000, test_pre_nms_score_threshold=0.0, test_pre_nms_min_size_threshold=0.0, test_nms_iou_threshold=0.7, test_num_proposals=1000, use_batched_nms=False), roi_sampler=ROISampler(mix_gt_boxes=True, num_sampled_rois=512, foreground_fraction=0.25, foreground_iou_threshold=0.5, background_iou_high_threshold=0.5, background_iou_low_threshold=0.0, cascade_iou_thresholds=None), roi_aligner=ROIAligner(crop_size=7, sample_offset=0.5), detection_generator=DetectionGenerator(apply_nms=True, pre_nms_top_k=5000, pre_nms_score_threshold=0.05, nms_iou_threshold=0.5, max_num_detections=100, nms_version='v2', use_cpu_nms=False, soft_nms_sigma=None, use_sigmoid_probability=False), mask_head=MaskHead(upsample_factor=2, num_convs=4, num_filters=256, use_separable_conv=False, class_agnostic=False), mask_sampler=MaskSampler(num_sampled_masks=128), mask_roi_aligner=MaskROIAligner(crop_size=14, sample_offset=0.5), norm_activation=NormActivation(activation='relu', use_sync_bn=True, norm_momentum=0.997, norm_epsilon=0.0001)), train_data=DataConfig(input_path='/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/*train*', tfds_name='', tfds_split='', global_batch_size=8, is_training=True, drop_remainder=True, shuffle_buffer_size=10000, cache=False, cycle_length=None, block_length=1, ram_budget=None, deterministic=None, sharding=True, enable_tf_data_service=False, tf_data_service_address=None, tf_data_service_job_name=None, tfds_data_dir='', tfds_as_supervised=False, tfds_skip_decoding_feature='', enable_shared_tf_data_service_between_parallel_trainers=False, apply_tf_data_service_before_batching=False, trainer_id=None, seed=None, prefetch_buffer_size=None, autotune_algorithm=None, weights=None, dtype='bfloat16', decoder=DataDecoder(type='simple_decoder', simple_decoder=TfExampleDecoder(regenerate_source_id=False, mask_binarize_threshold=None, attribute_names=[]), label_map_decoder=TfExampleDecoderLabelMap(regenerate_source_id=False, mask_binarize_threshold=None, label_map='')), parser=Parser(num_channels=3, match_threshold=0.5, unmatched_threshold=0.5, aug_rand_hflip=True, aug_rand_vflip=False, aug_scale_min=0.8, aug_scale_max=1.25, aug_type=None, skip_crowd_during_training=True, max_num_instances=100, rpn_match_threshold=0.7, rpn_unmatched_threshold=0.3, rpn_batch_size_per_im=256, rpn_fg_fraction=0.5, mask_crop_size=112, pad=True, keep_aspect_ratio=True), file_type='tfrecord', num_examples=-1), validation_data=DataConfig(input_path='/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/*val*', tfds_name='', tfds_split='', global_batch_size=8, is_training=False, drop_remainder=False, shuffle_buffer_size=10000, cache=False, cycle_length=None, block_length=1, ram_budget=None, deterministic=None, sharding=True, enable_tf_data_service=False, tf_data_service_address=None, tf_data_service_job_name=None, tfds_data_dir='', tfds_as_supervised=False, tfds_skip_decoding_feature='', enable_shared_tf_data_service_between_parallel_trainers=False, apply_tf_data_service_before_batching=False, trainer_id=None, seed=None, prefetch_buffer_size=None, autotune_algorithm=None, weights=None, dtype='bfloat16', decoder=DataDecoder(type='simple_decoder', simple_decoder=TfExampleDecoder(regenerate_source_id=False, mask_binarize_threshold=None, attribute_names=[]), label_map_decoder=TfExampleDecoderLabelMap(regenerate_source_id=False, mask_binarize_threshold=None, label_map='')), parser=Parser(num_channels=3, match_threshold=0.5, unmatched_threshold=0.5, aug_rand_hflip=False, aug_rand_vflip=False, aug_scale_min=1.0, aug_scale_max=1.0, aug_type=None, skip_crowd_during_training=True, max_num_instances=100, rpn_match_threshold=0.7, rpn_unmatched_threshold=0.3, rpn_batch_size_per_im=256, rpn_fg_fraction=0.5, mask_crop_size=112, pad=True, keep_aspect_ratio=True), file_type='tfrecord', num_examples=-1), name=None, differential_privacy_config=None, allow_image_summary=False, losses=Losses(loss_weight=1.0, rpn_huber_loss_delta=0.1111111111111111, frcnn_huber_loss_delta=1.0, frcnn_class_use_binary_cross_entropy=True, frcnn_class_loss_top_k_percent=1.0, l2_weight_decay=4e-05, rpn_score_weight=1.0, rpn_box_weight=1.0, frcnn_class_weight=1.0, frcnn_box_weight=1.0, mask_weight=1.0, class_weights=None), init_checkpoint_modules='backbone', annotation_file='coco/instances_val2017.json', per_category_metrics=False, allowed_mask_class_ids=None, use_coco_metrics=True, use_wod_metrics=False, use_approx_instance_metrics=False, freeze_backbone=False), trainer=TrainerConfig(optimizer_config=OptimizationConfig(optimizer=OptimizerConfig(type='sgd', sgd=SGDConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='SGD', decay=0.0, nesterov=False, momentum=0.9), sgd_experimental=SGDExperimentalConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='SGD', nesterov=False, momentum=0.0, jit_compile=False), adam=AdamConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='Adam', beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False), adam_experimental=AdamExperimentalConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='Adam', beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, jit_compile=False), adamw=AdamWeightDecayConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='AdamWeightDecay', beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, weight_decay_rate=0.0, include_in_weight_decay=None, exclude_from_weight_decay=None, gradient_clip_norm=1.0), adamw_experimental=AdamWeightDecayExperimentalConfig(clipnorm=None, clipvalue=None, global_clipnorm=1.0, name='AdamWeightDecayExperimental', beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, weight_decay=0.0, jit_compile=False), lamb=LAMBConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='LAMB', beta_1=0.9, beta_2=0.999, epsilon=1e-06, weight_decay_rate=0.0, exclude_from_weight_decay=None, exclude_from_layer_adaptation=None), rmsprop=RMSPropConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='RMSprop', rho=0.9, momentum=0.0, epsilon=1e-07, centered=False), lars=LARSConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='LARS', momentum=0.9, eeta=0.001, weight_decay_rate=0.0, nesterov=False, classic_momentum=True, exclude_from_weight_decay=None, exclude_from_layer_adaptation=None), adagrad=AdagradConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='Adagrad', initial_accumulator_value=0.1, epsilon=1e-07), slide=SLIDEConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='SLIDE', beta_1=0.9, beta_2=0.999, epsilon=1e-06, weight_decay_rate=0.0, weight_decay_type='inner', exclude_from_weight_decay=None, exclude_from_layer_adaptation=None, include_in_sparse_layer_adaptation=None, sparse_layer_learning_rate=0.1, do_gradient_rescaling=True, norm_type='layer', ratio_clip_norm=100000.0), adafactor=AdafactorConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='Adafactor', factored=True, multiply_by_parameter_scale=True, beta1=None, decay_rate=0.8, step_offset=0, clipping_threshold=1.0, min_dim_size_to_factor=128, epsilon1=1e-30, epsilon2=0.001, weight_decay=None, include_in_weight_decay=None), adafactor_keras=AdafactorKerasConfig(clipnorm=None, clipvalue=None, global_clipnorm=None, name='Adafactor', learning_rate=0.001, beta_2_decay=-0.8, epsilon_1=1e-30, epsilon_2=0.001, clip_threshold=1.0, relative_step=True)), ema=None, learning_rate=LrConfig(type='stepwise', constant=ConstantLrConfig(name='Constant', learning_rate=0.1), stepwise=StepwiseLrConfig(name='PiecewiseConstantDecay', boundaries=[15000, 20000], values=[0.12, 0.012, 0.0054], offset=0), exponential=ExponentialLrConfig(name='ExponentialDecay', initial_learning_rate=None, decay_steps=None, decay_rate=None, staircase=None, offset=0), polynomial=PolynomialLrConfig(name='PolynomialDecay', initial_learning_rate=None, decay_steps=None, end_learning_rate=0.0001, power=1.0, cycle=False, offset=0), cosine=CosineLrConfig(name='CosineDecay', initial_learning_rate=None, decay_steps=None, alpha=0.0, offset=0), power=DirectPowerLrConfig(name='DirectPowerDecay', initial_learning_rate=None, power=-0.5), power_linear=PowerAndLinearDecayLrConfig(name='PowerAndLinearDecay', initial_learning_rate=None, total_decay_steps=None, power=-0.5, linear_decay_fraction=0.1, offset=0), power_with_offset=PowerDecayWithOffsetLrConfig(name='PowerDecayWithOffset', initial_learning_rate=None, power=-0.5, offset=0, pre_offset_learning_rate=1000000.0), step_cosine_with_offset=StepCosineLrConfig(name='StepCosineDecayWithOffset', boundaries=None, values=None, offset=0)), warmup=WarmupConfig(type='linear', linear=LinearWarmupConfig(name='linear', warmup_learning_rate=0.0067, warmup_steps=500), polynomial=PolynomialWarmupConfig(name='polynomial', power=1, warmup_steps=None))), train_tf_while_loop=True, train_tf_function=True, eval_tf_function=True, eval_tf_while_loop=False, allow_tpu_summary=False, steps_per_loop=1000, summary_interval=1000, checkpoint_interval=1000, max_to_keep=3, continuous_eval_timeout=3600, train_steps=750000, validation_steps=512, validation_interval=5000, best_checkpoint_export_subdir='', best_checkpoint_eval_metric='', best_checkpoint_metric_comp='higher', loss_upper_bound=1000000.0, recovery_begin_steps=0, recovery_max_trials=0, validation_summary_subdir='validation', preemption_on_demand_checkpoint=True), runtime=RuntimeConfig(distribution_strategy='mirrored', enable_xla=False, gpu_thread_mode=None, dataset_num_private_threads=None, per_gpu_thread_count=0, tpu=None, num_gpus=0, worker_hosts=None, task_index=-1, all_reduce_alg=None, num_packs=1, mixed_precision_dtype=None, loss_scale=None, run_eagerly=False, batchnorm_spatial_persistent=False, tpu_enable_xla_dynamic_padder=None, num_cores_per_replica=1, default_shard_dim=-1, use_tpu_mp_strategy=False))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution Strategy on Device /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 14:56:31.602618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38484 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buffer_size = 100\n",
    "num_of_examples = 2\n",
    "tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(raw_records)\n",
    "\n",
    "val_tfrecords = tf.io.gfile.glob(exp_config.task.validation_data.input_path)\n",
    "val_raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(val_raw_records)\n",
    "show = True\n",
    "for train, val in zip(raw_records, val_raw_records):\n",
    "    train_decoded = tf_ex_decoder.decode(train)\n",
    "    val_decoded = tf_ex_decoder.decode(val)\n",
    "    \n",
    "    for key in train_decoded.keys():\n",
    "        hor_ok = train_decoded[key].shape[1:] == val_decoded[key].shape[1:]\n",
    "        if not hor_ok:\n",
    "            print(\"Horizontal Integrity not given\", key, train_decoded[key].shape[1:], val_decoded[key].shape[1:])\n",
    "\n",
    "    sizes_train = [train_decoded[key].shape[0] for key in train_decoded.keys() if len(train_decoded[key].shape) > 0]\n",
    "    train_ver_ok = len(set(sizes_train)) == 1\n",
    "    if not train_ver_ok:\n",
    "        print(\"Train vertical integrity not given\", sizes_train,  [(key, value.shape) for key, value in train_decoded.items()])\n",
    "\n",
    "    sizes_val = [val_decoded[key].shape[0] for key in val_decoded.keys() if len(val_decoded[key].shape) > 0]\n",
    "    val_ver_ok = len(set(sizes_val)) == 1\n",
    "    if not val_ver_ok:\n",
    "        print(\"Val vertical integrity not given\", sizes_val, [(key, value.shape) for key, value in val_decoded.items()])\n",
    "print(\"integrity given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_notification(text):\n",
    "    if \"loss\" not in text or 'eval' not in text:\n",
    "        return\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    losses.reverse()\n",
    "    msg = f\"Step #{step}:\" + ' - '.join([f\"{name} Loss: {value}\" for name, value in losses])\n",
    "    send_pushover_notification(msg, title=\"Training Losses\", priority=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'coco/instances_val2017.json'\n  In call to configurable 'Trainer' (<class 'official.core.base_trainer.Trainer'>)\n  In call to configurable 'create_trainer' (<function create_trainer at 0x14fa47c8f1a0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#with intercept_stdout(tfm_log):\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model, eval_logs \u001b[38;5;241m=\u001b[39m tfm\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mtrain_lib\u001b[38;5;241m.\u001b[39mrun_experiment(\n\u001b[1;32m      5\u001b[0m         distribution_strategy\u001b[38;5;241m=\u001b[39mdistribution_strategy,\n\u001b[1;32m      6\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m      7\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_and_eval\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         params\u001b[38;5;241m=\u001b[39mexp_config,\n\u001b[1;32m      9\u001b[0m         model_dir\u001b[38;5;241m=\u001b[39mMODEL_DIR,\n\u001b[1;32m     10\u001b[0m         run_post_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:356\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(distribution_strategy, task, mode, params, model_dir, run_post_eval, save_summary, train_actions, eval_actions, trainer, controller_cls, summary_manager, eval_summary_manager, enable_async_checkpointing)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_experiment\u001b[39m(\n\u001b[1;32m    310\u001b[0m     distribution_strategy: tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mStrategy,\n\u001b[1;32m    311\u001b[0m     task: base_task\u001b[38;5;241m.\u001b[39mTask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m     enable_async_checkpointing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[tf_keras\u001b[38;5;241m.\u001b[39mModel, Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Runs train/eval configured by the experiment params.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        otherwise, returns {}.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m   runner \u001b[38;5;241m=\u001b[39m OrbitExperimentRunner(\n\u001b[1;32m    357\u001b[0m       distribution_strategy\u001b[38;5;241m=\u001b[39mdistribution_strategy,\n\u001b[1;32m    358\u001b[0m       task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    359\u001b[0m       mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    360\u001b[0m       params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    361\u001b[0m       model_dir\u001b[38;5;241m=\u001b[39mmodel_dir,\n\u001b[1;32m    362\u001b[0m       run_post_eval\u001b[38;5;241m=\u001b[39mrun_post_eval,\n\u001b[1;32m    363\u001b[0m       save_summary\u001b[38;5;241m=\u001b[39msave_summary,\n\u001b[1;32m    364\u001b[0m       train_actions\u001b[38;5;241m=\u001b[39mtrain_actions,\n\u001b[1;32m    365\u001b[0m       eval_actions\u001b[38;5;241m=\u001b[39meval_actions,\n\u001b[1;32m    366\u001b[0m       trainer\u001b[38;5;241m=\u001b[39mtrainer,\n\u001b[1;32m    367\u001b[0m       controller_cls\u001b[38;5;241m=\u001b[39mcontroller_cls,\n\u001b[1;32m    368\u001b[0m       summary_manager\u001b[38;5;241m=\u001b[39msummary_manager,\n\u001b[1;32m    369\u001b[0m       eval_summary_manager\u001b[38;5;241m=\u001b[39meval_summary_manager,\n\u001b[1;32m    370\u001b[0m       enable_async_checkpointing\u001b[38;5;241m=\u001b[39menable_async_checkpointing,\n\u001b[1;32m    371\u001b[0m   )\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:107\u001b[0m, in \u001b[0;36mOrbitExperimentRunner.__init__\u001b[0;34m(self, distribution_strategy, task, mode, params, model_dir, run_post_eval, save_summary, train_actions, eval_actions, trainer, controller_cls, summary_manager, eval_summary_manager, enable_async_checkpointing)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_post_eval \u001b[38;5;241m=\u001b[39m run_post_eval\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer \u001b[38;5;241m=\u001b[39m trainer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_trainer(\n\u001b[1;32m    108\u001b[0m     task,\n\u001b[1;32m    109\u001b[0m     train\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode,\n\u001b[1;32m    110\u001b[0m     evaluate\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode) \u001b[38;5;129;01mor\u001b[39;00m run_post_eval)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build_checkpoint_manager()\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_lib.py:153\u001b[0m, in \u001b[0;36mOrbitExperimentRunner._build_trainer\u001b[0;34m(self, task, train, evaluate)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create trainer.\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m--> 153\u001b[0m   trainer \u001b[38;5;241m=\u001b[39m train_utils\u001b[38;5;241m.\u001b[39mcreate_trainer(\n\u001b[1;32m    154\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    155\u001b[0m       task,\n\u001b[1;32m    156\u001b[0m       train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    157\u001b[0m       evaluate\u001b[38;5;241m=\u001b[39mevaluate,\n\u001b[1;32m    158\u001b[0m       checkpoint_exporter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_best_checkpoint_exporter())\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in scope \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scope_str) \u001b[38;5;28;01mif\u001b[39;00m scope_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[38;5;241m=\u001b[39m err_str\u001b[38;5;241m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m utils\u001b[38;5;241m.\u001b[39maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[38;5;241m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(exception)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mwith_traceback(exception\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/train_utils.py:277\u001b[0m, in \u001b[0;36mcreate_trainer\u001b[0;34m(params, task, train, evaluate, checkpoint_exporter, trainer_cls)\u001b[0m\n\u001b[1;32m    275\u001b[0m model \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mbuild_model()\n\u001b[1;32m    276\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m create_optimizer(task, params)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer_cls(\n\u001b[1;32m    278\u001b[0m     params,\n\u001b[1;32m    279\u001b[0m     task,\n\u001b[1;32m    280\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    281\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    282\u001b[0m     train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    283\u001b[0m     evaluate\u001b[38;5;241m=\u001b[39mevaluate,\n\u001b[1;32m    284\u001b[0m     checkpoint_exporter\u001b[38;5;241m=\u001b[39mcheckpoint_exporter)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in scope \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scope_str) \u001b[38;5;28;01mif\u001b[39;00m scope_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[38;5;241m=\u001b[39m err_str\u001b[38;5;241m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m utils\u001b[38;5;241m.\u001b[39maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[38;5;241m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(exception)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mwith_traceback(exception\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/core/base_trainer.py:231\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, config, task, model, optimizer, train, evaluate, train_dataset, validation_dataset, checkpoint_exporter)\u001b[0m\n\u001b[1;32m    222\u001b[0m   orbit\u001b[38;5;241m.\u001b[39mStandardTrainer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    223\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    224\u001b[0m       train_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m           use_tf_function\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain_tf_function,\n\u001b[1;32m    228\u001b[0m           use_tpu_summary_optimization\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mallow_tpu_summary))\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate:\n\u001b[0;32m--> 231\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validation_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mbuild_metrics(\n\u001b[1;32m    232\u001b[0m       training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m+\u001b[39m model_metrics\n\u001b[1;32m    233\u001b[0m   validation_dataset \u001b[38;5;241m=\u001b[39m validation_dataset \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_dataset(\n\u001b[1;32m    234\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mbuild_inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mvalidation_data)\n\u001b[1;32m    235\u001b[0m   orbit\u001b[38;5;241m.\u001b[39mStandardEvaluator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    236\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    237\u001b[0m       validation_dataset,\n\u001b[1;32m    238\u001b[0m       options\u001b[38;5;241m=\u001b[39morbit\u001b[38;5;241m.\u001b[39mStandardEvaluatorOptions(\n\u001b[1;32m    239\u001b[0m           use_tf_function\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39meval_tf_function,\n\u001b[1;32m    240\u001b[0m           use_tf_while_loop\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39meval_tf_while_loop))\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/vision/tasks/maskrcnn.py:358\u001b[0m, in \u001b[0;36mMaskRCNNTask.build_metrics\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39muse_coco_metrics:\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_coco_metrics()\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39muse_wod_metrics:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# To use Waymo open dataset metrics, please install one of the pip\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# package `waymo-open-dataset-tf-*` from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# will produce error if it does not match the tf version that is\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# currently used.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/vision/tasks/maskrcnn.py:308\u001b[0m, in \u001b[0;36mMaskRCNNTask._build_coco_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Builds COCO metrics evaluator.\"\"\"\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minclude_mask\n\u001b[1;32m    307\u001b[0m    ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39mannotation_file:\n\u001b[0;32m--> 308\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoco_metric \u001b[38;5;241m=\u001b[39m coco_evaluator\u001b[38;5;241m.\u001b[39mCOCOEvaluator(\n\u001b[1;32m    309\u001b[0m       annotation_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39mannotation_file,\n\u001b[1;32m    310\u001b[0m       include_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minclude_mask,\n\u001b[1;32m    311\u001b[0m       per_category_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_config\u001b[38;5;241m.\u001b[39mper_category_metrics)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;66;03m# Builds COCO-style annotation file if include_mask is True, and\u001b[39;00m\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;66;03m# annotation_file isn't provided.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m   annotation_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logging_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/vision/evaluation/coco_evaluator.py:90\u001b[0m, in \u001b[0;36mCOCOEvaluator.__init__\u001b[0;34m(self, annotation_file, include_mask, include_keypoint, need_rescale_bboxes, need_rescale_keypoints, per_category_metrics, max_num_eval_detections, kpt_oks_sigmas)\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     local_val_json \u001b[38;5;241m=\u001b[39m annotation_file\n\u001b[0;32m---> 90\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coco_gt \u001b[38;5;241m=\u001b[39m coco_utils\u001b[38;5;241m.\u001b[39mCOCOWrapper(\n\u001b[1;32m     91\u001b[0m       eval_type\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     92\u001b[0m       annotation_file\u001b[38;5;241m=\u001b[39mlocal_val_json)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_annotation_file \u001b[38;5;241m=\u001b[39m annotation_file\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_include_mask \u001b[38;5;241m=\u001b[39m include_mask\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/official/vision/evaluation/coco_utils.py:65\u001b[0m, in \u001b[0;36mCOCOWrapper.__init__\u001b[0;34m(self, eval_type, annotation_file, gt_dataset)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `eval_type` can only be either `box` or `mask`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m coco\u001b[38;5;241m.\u001b[39mCOCO\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, annotation_file\u001b[38;5;241m=\u001b[39mannotation_file)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_type \u001b[38;5;241m=\u001b[39m eval_type\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gt_dataset:\n",
      "File \u001b[0;32m~/.conda/envs/tf_models/lib/python3.11/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading annotations into memory...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(annotation_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation file format \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(dataset))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'coco/instances_val2017.json'\n  In call to configurable 'Trainer' (<class 'official.core.base_trainer.Trainer'>)\n  In call to configurable 'create_trainer' (<function create_trainer at 0x14fa47c8f1a0>)"
     ]
    }
   ],
   "source": [
    "#send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "#with intercept_stdout(tfm_log):\n",
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train_and_eval',\n",
    "        params=exp_config,\n",
    "        model_dir=MODEL_DIR,\n",
    "        run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'{MODEL_DIR}/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch w/ CUDA 12.4",
   "language": "python",
   "name": "pytorch_cuda_12.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
