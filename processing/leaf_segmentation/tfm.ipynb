{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial\n",
    "from tfm_configs import *\n",
    "import re\n",
    "import tensorflow_datasets as tfdsw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "#MODEL = \"maskrcnn_mobilenet_fpn\"\n",
    "#MODEL = \"retinanet_resnet_fpn\"\n",
    "MODEL = \"maskrcnn_resnet_fpn\"\n",
    "MODEL_DIR = \"out/\" + MODEL\n",
    "START = time.time()\n",
    "RESTORE_METRICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exp_config = maskrcnn_mobilenet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config = retinanet_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "exp_config = maskrcnn_resnet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "#exp_config.trainer.validation_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution Strategy on Device /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 13:44:49.589621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79198 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:06:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vertical integrity not given [512, 4, 4, 4, 4, 4, 4] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([4])), ('groundtruth_is_crowd', TensorShape([4])), ('groundtruth_area', TensorShape([4])), ('groundtruth_boxes', TensorShape([4, 4])), ('groundtruth_instance_masks', TensorShape([4, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([4]))]\n",
      "Val vertical integrity not given [512, 4, 4, 4, 4, 4, 4] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([4])), ('groundtruth_is_crowd', TensorShape([4])), ('groundtruth_area', TensorShape([4])), ('groundtruth_boxes', TensorShape([4, 4])), ('groundtruth_instance_masks', TensorShape([4, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([4]))]\n",
      "Train vertical integrity not given [512, 6, 6, 6, 6, 6, 6] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([6])), ('groundtruth_is_crowd', TensorShape([6])), ('groundtruth_area', TensorShape([6])), ('groundtruth_boxes', TensorShape([6, 4])), ('groundtruth_instance_masks', TensorShape([6, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([6]))]\n",
      "Val vertical integrity not given [512, 3, 3, 3, 3, 3, 3] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([3])), ('groundtruth_is_crowd', TensorShape([3])), ('groundtruth_area', TensorShape([3])), ('groundtruth_boxes', TensorShape([3, 4])), ('groundtruth_instance_masks', TensorShape([3, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([3]))]\n",
      "integrity given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 13:44:51.102029: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 100\n",
    "num_of_examples = 2\n",
    "tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(raw_records)\n",
    "\n",
    "val_tfrecords = tf.io.gfile.glob(exp_config.task.validation_data.input_path)\n",
    "val_raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(val_raw_records)\n",
    "show = True\n",
    "for train, val in zip(raw_records, val_raw_records):\n",
    "    train_decoded = tf_ex_decoder.decode(train)\n",
    "    val_decoded = tf_ex_decoder.decode(val)\n",
    "    \n",
    "    for key in train_decoded.keys():\n",
    "        hor_ok = train_decoded[key].shape[1:] == val_decoded[key].shape[1:]\n",
    "        if not hor_ok:\n",
    "            print(\"Horizontal Integrity not given\", key, train_decoded[key].shape[1:], val_decoded[key].shape[1:])\n",
    "\n",
    "    sizes_train = [train_decoded[key].shape[0] for key in train_decoded.keys() if len(train_decoded[key].shape) > 0]\n",
    "    train_ver_ok = len(set(sizes_train)) == 1\n",
    "    if not train_ver_ok:\n",
    "        print(\"Train vertical integrity not given\", sizes_train,  [(key, value.shape) for key, value in train_decoded.items()])\n",
    "\n",
    "    sizes_val = [val_decoded[key].shape[0] for key in val_decoded.keys() if len(val_decoded[key].shape) > 0]\n",
    "    val_ver_ok = len(set(sizes_val)) == 1\n",
    "    if not val_ver_ok:\n",
    "        print(\"Val vertical integrity not given\", sizes_val, [(key, value.shape) for key, value in val_decoded.items()])\n",
    "print(\"integrity given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_notification(text):\n",
    "    if \"loss\" not in text or 'eval' not in text:\n",
    "        return\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    losses.reverse()\n",
    "    msg = f\"Step #{step}:\" + ' - '.join([f\"{name} Loss: {value}\" for name, value in losses])\n",
    "    send_pushover_notification(msg, title=\"Training Losses\", priority=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "data_val = []\n",
    "os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "\n",
    "if RESTORE_METRICS:\n",
    "    files = os.listdir(f\"metrics/{MODEL}\")\n",
    "    vals = [file for file in files if \"val\" in file]\n",
    "    trains = [file for file in files if \"train\" in file]\n",
    "    vals.sort()\n",
    "    trains.sort()\n",
    "    last_val = vals[-1]\n",
    "    last_train = trains[-1]\n",
    "    data_train = pd.read_csv(os.path.join(f\"metrics/{MODEL}\", last_train)).to_dict('records')\n",
    "    data_val = pd.read_csv(os.path.join(f\"metrics/{MODEL}\", last_val)).to_dict('records')\n",
    "    \n",
    "def log_eval(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    metrics_dict = re.findall(r\"\\s+.'(.*?)':\\s(.*\\d)\", text)\n",
    "    metrics = {name: value for name, value in metrics_dict}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "    \n",
    "    data_val.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_val)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_val_{START}.csv\", index=False)\n",
    "    \n",
    "def log_train(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    metrics = {name: value for name, value in losses}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "\n",
    "    data_train.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_train)\n",
    "    os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_train_{START}.csv\", index=False)\n",
    "    \n",
    "    \n",
    "def tfm_log(text):\n",
    "    if \"output\" not in text:\n",
    "        return\n",
    "    if \"eval\" in text:\n",
    "        log_eval(text)\n",
    "        return\n",
    "    if \"train\" in text:\n",
    "        log_train(text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "restoring or initializing model...\n",
      "restored model from out/maskrcnn_resnet_fpn/ckpt-131000.\n",
      "restored from checkpoint: out/maskrcnn_resnet_fpn/ckpt-131000\n",
      "train | step:  131000 | training until step 136000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1722685519.102181  325147 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -59 } dim { size: -44 } dim { size: -45 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-03 13:45:57.811363: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:  132000 | steps/sec:    2.7 | output: \n",
      "    {'frcnn_box_loss': 0.07962263,\n",
      "     'frcnn_cls_loss': 0.07559917,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08639078,\n",
      "     'model_loss': 0.26603794,\n",
      "     'rpn_box_loss': 0.020058924,\n",
      "     'rpn_score_loss': 0.004366598,\n",
      "     'total_loss': 0.44734827,\n",
      "     'training_loss': 0.44734827}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-132000.\n",
      "train | step:  133000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.077345505,\n",
      "     'frcnn_cls_loss': 0.073531434,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.085494004,\n",
      "     'model_loss': 0.25988424,\n",
      "     'rpn_box_loss': 0.01941177,\n",
      "     'rpn_score_loss': 0.004101641,\n",
      "     'total_loss': 0.44060132,\n",
      "     'training_loss': 0.44060132}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-133000.\n",
      "train | step:  134000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07752171,\n",
      "     'frcnn_cls_loss': 0.07436591,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08511554,\n",
      "     'model_loss': 0.26008642,\n",
      "     'rpn_box_loss': 0.019011429,\n",
      "     'rpn_score_loss': 0.0040719244,\n",
      "     'total_loss': 0.4402057,\n",
      "     'training_loss': 0.4402057}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-134000.\n",
      "train | step:  135000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07777059,\n",
      "     'frcnn_cls_loss': 0.073018,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08854171,\n",
      "     'model_loss': 0.26244032,\n",
      "     'rpn_box_loss': 0.019065116,\n",
      "     'rpn_score_loss': 0.004044963,\n",
      "     'total_loss': 0.44196847,\n",
      "     'training_loss': 0.44196847}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-135000.\n",
      "train | step:  136000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.076275535,\n",
      "     'frcnn_cls_loss': 0.073173426,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.086265944,\n",
      "     'model_loss': 0.258858,\n",
      "     'rpn_box_loss': 0.019107798,\n",
      "     'rpn_score_loss': 0.004035158,\n",
      "     'total_loss': 0.43779394,\n",
      "     'training_loss': 0.43779394}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-136000.\n",
      " eval | step:  136000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722687160.516044  325147 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-03 14:13:07.728069: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-03 14:13:07.730314: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-03 14:13:08.616059: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-08-03 14:13:08.616124: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 12127018411382889574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.848\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.767\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.706\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.729\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  136000 | steps/sec:    6.3 | eval time:   81.6 sec | output: \n",
      "    {'AP': 0.69753313,\n",
      "     'AP50': 0.848394,\n",
      "     'AP75': 0.76717556,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.7059908,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17417434,\n",
      "     'ARmax10': 0.72938097,\n",
      "     'ARmax100': 0.73409134,\n",
      "     'ARs': 0.73409134,\n",
      "     'mask_AP': 0.0046870857,\n",
      "     'mask_AP50': 0.011201948,\n",
      "     'mask_AP75': 0.0030653551,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.006240244,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.012055586,\n",
      "     'mask_ARmax10': 0.05374481,\n",
      "     'mask_ARmax100': 0.054574985,\n",
      "     'mask_ARs': 0.054574985,\n",
      "     'steps_per_second': 6.2777333714285755,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  136000 | training until step 141000...\n",
      "train | step:  137000 | steps/sec:    2.5 | output: \n",
      "    {'frcnn_box_loss': 0.07745537,\n",
      "     'frcnn_cls_loss': 0.073528424,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08504118,\n",
      "     'model_loss': 0.25959086,\n",
      "     'rpn_box_loss': 0.019417051,\n",
      "     'rpn_score_loss': 0.0041487436,\n",
      "     'total_loss': 0.43792987,\n",
      "     'training_loss': 0.43792987}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-137000.\n",
      "train | step:  138000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.0778318,\n",
      "     'frcnn_cls_loss': 0.07497164,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08268829,\n",
      "     'model_loss': 0.2588969,\n",
      "     'rpn_box_loss': 0.019325742,\n",
      "     'rpn_score_loss': 0.004079374,\n",
      "     'total_loss': 0.43664375,\n",
      "     'training_loss': 0.43664375}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-138000.\n",
      "train | step:  139000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07596419,\n",
      "     'frcnn_cls_loss': 0.07247484,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08647033,\n",
      "     'model_loss': 0.25755382,\n",
      "     'rpn_box_loss': 0.018636545,\n",
      "     'rpn_score_loss': 0.004007666,\n",
      "     'total_loss': 0.43471766,\n",
      "     'training_loss': 0.43471766}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-139000.\n",
      "train | step:  140000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07614264,\n",
      "     'frcnn_cls_loss': 0.072948456,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.085335545,\n",
      "     'model_loss': 0.25784448,\n",
      "     'rpn_box_loss': 0.019362533,\n",
      "     'rpn_score_loss': 0.004055431,\n",
      "     'total_loss': 0.4344363,\n",
      "     'training_loss': 0.4344363}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-140000.\n",
      "train | step:  141000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07807116,\n",
      "     'frcnn_cls_loss': 0.07413578,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.083504885,\n",
      "     'model_loss': 0.25799048,\n",
      "     'rpn_box_loss': 0.018293755,\n",
      "     'rpn_score_loss': 0.003985017,\n",
      "     'total_loss': 0.4340162,\n",
      "     'training_loss': 0.4340162}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-141000.\n",
      " eval | step:  141000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722688833.143028  325147 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-03 14:40:50.976549: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-03 14:40:50.976645: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-03 14:40:51.013242: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-08-03 14:40:51.013322: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 12127018411382889574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.705\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.849\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.771\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.735\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.741\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  141000 | steps/sec:    7.1 | eval time:   71.8 sec | output: \n",
      "    {'AP': 0.7053064,\n",
      "     'AP50': 0.8490994,\n",
      "     'AP75': 0.7711654,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.7166567,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.17614149,\n",
      "     'ARmax10': 0.7353005,\n",
      "     'ARmax100': 0.7413283,\n",
      "     'ARs': 0.7413283,\n",
      "     'mask_AP': 0.02251561,\n",
      "     'mask_AP50': 0.05116433,\n",
      "     'mask_AP75': 0.017704202,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.032720894,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.028027432,\n",
      "     'mask_ARmax10': 0.12257715,\n",
      "     'mask_ARmax100': 0.123714134,\n",
      "     'mask_ARs': 0.123714134,\n",
      "     'steps_per_second': 7.133821992289315,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  141000 | training until step 146000...\n",
      "train | step:  142000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.07825384,\n",
      "     'frcnn_cls_loss': 0.073385075,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.083698094,\n",
      "     'model_loss': 0.25835136,\n",
      "     'rpn_box_loss': 0.019062445,\n",
      "     'rpn_score_loss': 0.003952014,\n",
      "     'total_loss': 0.43379998,\n",
      "     'training_loss': 0.43379998}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-142000.\n",
      "train | step:  143000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07655282,\n",
      "     'frcnn_cls_loss': 0.072940156,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.083821334,\n",
      "     'model_loss': 0.25628152,\n",
      "     'rpn_box_loss': 0.018912688,\n",
      "     'rpn_score_loss': 0.004054275,\n",
      "     'total_loss': 0.4311666,\n",
      "     'training_loss': 0.4311666}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-143000.\n",
      "train | step:  144000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07620259,\n",
      "     'frcnn_cls_loss': 0.072529264,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08308537,\n",
      "     'model_loss': 0.2550607,\n",
      "     'rpn_box_loss': 0.019198453,\n",
      "     'rpn_score_loss': 0.0040449016,\n",
      "     'total_loss': 0.42938527,\n",
      "     'training_loss': 0.42938527}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-144000.\n",
      "train | step:  145000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.075817965,\n",
      "     'frcnn_cls_loss': 0.071550444,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.087502666,\n",
      "     'model_loss': 0.25783616,\n",
      "     'rpn_box_loss': 0.018989552,\n",
      "     'rpn_score_loss': 0.003975496,\n",
      "     'total_loss': 0.4316046,\n",
      "     'training_loss': 0.4316046}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-145000.\n",
      "train | step:  146000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07378019,\n",
      "     'frcnn_cls_loss': 0.07096246,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08391358,\n",
      "     'model_loss': 0.25126404,\n",
      "     'rpn_box_loss': 0.018707354,\n",
      "     'rpn_score_loss': 0.0039004353,\n",
      "     'total_loss': 0.42447272,\n",
      "     'training_loss': 0.42447272}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-146000.\n",
      " eval | step:  146000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722690497.066499  325147 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-03 15:08:34.802854: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-03 15:08:34.802960: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-03 15:08:34.837315: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-08-03 15:08:34.837374: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 12127018411382889574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.848\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.769\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.704\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.728\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=5.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  146000 | steps/sec:    7.1 | eval time:   72.0 sec | output: \n",
      "    {'AP': 0.6975352,\n",
      "     'AP50': 0.84796923,\n",
      "     'AP75': 0.7690662,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.70379245,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.1747699,\n",
      "     'ARmax10': 0.72752213,\n",
      "     'ARmax100': 0.73264754,\n",
      "     'ARs': 0.73264754,\n",
      "     'mask_AP': 0.004082652,\n",
      "     'mask_AP50': 0.009255357,\n",
      "     'mask_AP75': 0.00309343,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.005338436,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.012506768,\n",
      "     'mask_ARmax10': 0.04995488,\n",
      "     'mask_ARmax100': 0.050514348,\n",
      "     'mask_ARs': 0.050514348,\n",
      "     'steps_per_second': 7.109010587087321,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  146000 | training until step 151000...\n",
      "train | step:  147000 | steps/sec:    2.6 | output: \n",
      "    {'frcnn_box_loss': 0.07444053,\n",
      "     'frcnn_cls_loss': 0.07015817,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08060623,\n",
      "     'model_loss': 0.24889776,\n",
      "     'rpn_box_loss': 0.019680647,\n",
      "     'rpn_score_loss': 0.004011963,\n",
      "     'total_loss': 0.42154038,\n",
      "     'training_loss': 0.42154038}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-147000.\n",
      "train | step:  148000 | steps/sec:    3.1 | output: \n",
      "    {'frcnn_box_loss': 0.07523451,\n",
      "     'frcnn_cls_loss': 0.07172731,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08418285,\n",
      "     'model_loss': 0.25445983,\n",
      "     'rpn_box_loss': 0.01931732,\n",
      "     'rpn_score_loss': 0.003997853,\n",
      "     'total_loss': 0.42654505,\n",
      "     'training_loss': 0.42654505}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-148000.\n",
      "train | step:  149000 | steps/sec:    3.0 | output: \n",
      "    {'frcnn_box_loss': 0.073817015,\n",
      "     'frcnn_cls_loss': 0.07057551,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08502917,\n",
      "     'model_loss': 0.25168413,\n",
      "     'rpn_box_loss': 0.018364782,\n",
      "     'rpn_score_loss': 0.003897533,\n",
      "     'total_loss': 0.4232256,\n",
      "     'training_loss': 0.4232256}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-149000.\n",
      "train | step:  150000 | steps/sec:    2.8 | output: \n",
      "    {'frcnn_box_loss': 0.07486674,\n",
      "     'frcnn_cls_loss': 0.07054469,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.0853201,\n",
      "     'model_loss': 0.25300592,\n",
      "     'rpn_box_loss': 0.018387096,\n",
      "     'rpn_score_loss': 0.003887453,\n",
      "     'total_loss': 0.4239945,\n",
      "     'training_loss': 0.4239945}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-150000.\n",
      "train | step:  151000 | steps/sec:    2.8 | output: \n",
      "    {'frcnn_box_loss': 0.07331657,\n",
      "     'frcnn_cls_loss': 0.06998515,\n",
      "     'learning_rate': 0.0054,\n",
      "     'mask_loss': 0.08127592,\n",
      "     'model_loss': 0.24647678,\n",
      "     'rpn_box_loss': 0.018037634,\n",
      "     'rpn_score_loss': 0.003861662,\n",
      "     'total_loss': 0.41691703,\n",
      "     'training_loss': 0.41691703}\n",
      "saved checkpoint to out/maskrcnn_resnet_fpn/ckpt-151000.\n",
      " eval | step:  151000 | running 512 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1722692253.684186  325147 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -6 } dim { size: -7 } dim { size: -8 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2699 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-08-03 15:38:04.394767: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-08-03 15:38:04.395336: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-08-03 15:38:04.490770: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.36s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.773\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.708\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.731\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=11.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  151000 | steps/sec:    3.6 | eval time:  142.8 sec | output: \n",
      "    {'AP': 0.7007546,\n",
      "     'AP50': 0.85079724,\n",
      "     'AP75': 0.7728814,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.70792073,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.1761054,\n",
      "     'ARmax10': 0.7312579,\n",
      "     'ARmax100': 0.7338928,\n",
      "     'ARs': 0.7338928,\n",
      "     'mask_AP': 0.0032007848,\n",
      "     'mask_AP50': 0.0073388238,\n",
      "     'mask_AP75': 0.0024900266,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.004323429,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.010250857,\n",
      "     'mask_ARmax10': 0.044955783,\n",
      "     'mask_ARmax100': 0.045352824,\n",
      "     'mask_ARs': 0.045352824,\n",
      "     'steps_per_second': 3.586099853844653,\n",
      "     'validation_loss': 0.0}\n",
      "train | step:  151000 | training until step 156000...\n"
     ]
    }
   ],
   "source": [
    "send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "with intercept_stdout(tfm_log):\n",
    "    model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train_and_eval',\n",
    "        params=exp_config,\n",
    "        model_dir=MODEL_DIR,\n",
    "        run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'{MODEL_DIR}/final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow Models",
   "language": "python",
   "name": "tf_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
