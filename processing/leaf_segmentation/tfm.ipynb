{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 20:37:42.738156: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-23 20:37:42.752454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 20:37:42.767909: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 20:37:42.767957: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 20:37:42.779924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 20:37:43.451486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.vision.configs import maskrcnn as exp_cfg\n",
    "from official.core import config_definitions as cfg\n",
    "from official.core import exp_factory\n",
    "from official.vision.tasks import maskrcnn\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.configs import backbones as backbones_cfg\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "import time\n",
    "from custom_utils import send_pushover_notification, intercept_stdout\n",
    "from functools import partial\n",
    "from tfm_configs import *\n",
    "import re\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "BATCH_SIZE = 4\n",
    "TFDS_NAME = 'leaf_instance_dataset'\n",
    "INPUT_PATH = \"/home/stefan.steinheber/tensorflow_datasets/leaf_instance_dataset/1.0.0/\"\n",
    "MODEL = \"maskrcnn_mobilenet_fpn\"\n",
    "MODEL_DIR = \"out/\" + MODEL\n",
    "START = time.time()\n",
    "RESTORE_METRICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_config = maskrcnn_mobilenet_fpn(INPUT_PATH, image_size=IMAGE_SIZE)\n",
    "exp_config.trainer.steps_per_loop = 100\n",
    "exp_config.trainer.validation_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution Strategy on Device /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 20:37:45.503360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46866 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices('GPU')]\n",
    "\n",
    "if len(logical_device_names) == 0:\n",
    "    logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print(\"Created distribution Strategy on Device\", logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index={\n",
    "                1: {\n",
    "                    'id': 1,\n",
    "                    'name': 'leaf',\n",
    "                },\n",
    "            },\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"out/fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vertical integrity not given [512, 4, 4, 4, 4, 4, 4] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([4])), ('groundtruth_is_crowd', TensorShape([4])), ('groundtruth_area', TensorShape([4])), ('groundtruth_boxes', TensorShape([4, 4])), ('groundtruth_instance_masks', TensorShape([4, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([4]))]\n",
      "Val vertical integrity not given [512, 2, 2, 2, 2, 2, 2] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([2])), ('groundtruth_is_crowd', TensorShape([2])), ('groundtruth_area', TensorShape([2])), ('groundtruth_boxes', TensorShape([2, 4])), ('groundtruth_instance_masks', TensorShape([2, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([2]))]\n",
      "Train vertical integrity not given [512, 6, 6, 6, 6, 6, 6] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([6])), ('groundtruth_is_crowd', TensorShape([6])), ('groundtruth_area', TensorShape([6])), ('groundtruth_boxes', TensorShape([6, 4])), ('groundtruth_instance_masks', TensorShape([6, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([6]))]\n",
      "Val vertical integrity not given [512, 8, 8, 8, 8, 8, 8] [('source_id', TensorShape([])), ('image', TensorShape([512, 512, 3])), ('height', TensorShape([])), ('width', TensorShape([])), ('groundtruth_classes', TensorShape([8])), ('groundtruth_is_crowd', TensorShape([8])), ('groundtruth_area', TensorShape([8])), ('groundtruth_boxes', TensorShape([8, 4])), ('groundtruth_instance_masks', TensorShape([8, 512, 512])), ('groundtruth_instance_masks_png', TensorShape([8]))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 20:37:46.868145: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrity given\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 100\n",
    "num_of_examples = 2\n",
    "tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "\n",
    "train_tfrecords = tf.io.gfile.glob(exp_config.task.train_data.input_path)\n",
    "raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(raw_records)\n",
    "\n",
    "val_tfrecords = tf.io.gfile.glob(exp_config.task.validation_data.input_path)\n",
    "val_raw_records = tf.data.TFRecordDataset(train_tfrecords).shuffle(buffer_size=buffer_size).take(num_of_examples)\n",
    "#show_batch(val_raw_records)\n",
    "show = True\n",
    "for train, val in zip(raw_records, val_raw_records):\n",
    "    train_decoded = tf_ex_decoder.decode(train)\n",
    "    val_decoded = tf_ex_decoder.decode(val)\n",
    "    \n",
    "    for key in train_decoded.keys():\n",
    "        hor_ok = train_decoded[key].shape[1:] == val_decoded[key].shape[1:]\n",
    "        if not hor_ok:\n",
    "            print(\"Horizontal Integrity not given\", key, train_decoded[key].shape[1:], val_decoded[key].shape[1:])\n",
    "\n",
    "    sizes_train = [train_decoded[key].shape[0] for key in train_decoded.keys() if len(train_decoded[key].shape) > 0]\n",
    "    train_ver_ok = len(set(sizes_train)) == 1\n",
    "    if not train_ver_ok:\n",
    "        print(\"Train vertical integrity not given\", sizes_train,  [(key, value.shape) for key, value in train_decoded.items()])\n",
    "\n",
    "    sizes_val = [val_decoded[key].shape[0] for key in val_decoded.keys() if len(val_decoded[key].shape) > 0]\n",
    "    val_ver_ok = len(set(sizes_val)) == 1\n",
    "    if not val_ver_ok:\n",
    "        print(\"Val vertical integrity not given\", sizes_val, [(key, value.shape) for key, value in val_decoded.items()])\n",
    "print(\"integrity given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_notification(text):\n",
    "    if \"loss\" not in text or 'eval' not in text:\n",
    "        return\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    losses.reverse()\n",
    "    msg = f\"Step #{step}:\" + ' - '.join([f\"{name} Loss: {value}\" for name, value in losses])\n",
    "    send_pushover_notification(msg, title=\"Training Losses\", priority=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "data_val = []\n",
    "os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "    \n",
    "def log_eval(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    metrics_dict = re.findall(r\"\\s+{?'(.*?)': (.*?)(?:,|}),\", text)\n",
    "    print(metrics_dict)\n",
    "    metrics = {name: value for name, value in metrics_dict}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "    \n",
    "    data_val.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_val)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_val_{START}.csv\", index=False)\n",
    "    \n",
    "def log_train(text):\n",
    "    step = re.search(r\"step:.*?(\\d+).*?\\|\", text)\n",
    "    step = step.group(1)\n",
    "    losses = re.findall(r\"'(.*)_loss':.*?(\\d+\\.\\d+)\", text)\n",
    "    metrics = {name: value for name, value in losses}\n",
    "    metrics.update({'step': step, 'mode': 'train' if 'train' in text else 'eval'})\n",
    "\n",
    "    data_train.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(data_train)\n",
    "    os.makedirs(f\"metrics/{MODEL}\", exist_ok=True)\n",
    "    df.to_csv(f\"metrics/{MODEL}/metrics_train_{START}.csv\", index=False)\n",
    "    \n",
    "    \n",
    "def tfm_log(text):\n",
    "    if \"output\" not in text:\n",
    "        return\n",
    "    if \"eval\" in text:\n",
    "        log_eval(text)\n",
    "        return\n",
    "    if \"train\" in text:\n",
    "        log_train(text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/__autograph_generated_fileogbf0eqg.py:63: UserWarning: Input dict contained keys ['6'] which did not match any model input. They will be ignored by the model.\n",
      "  ag__.converted_call(ag__.ld(warnings).warn, (ag__.converted_call('Input dict contained keys {} which did not match any model input. They will be ignored by the model.'.format, ([ag__.ld(n) for n in ag__.converted_call(ag__.ld(tensors).keys, (), None, fscope) if ag__.ld(n) not in ag__.ld(ref_input_names)],), None, fscope),), dict(stacklevel=2), fscope)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
      "/home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan.steinheber/.conda/envs/tf_models/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "restoring or initializing model...\n",
      "restored model from out/maskrcnn_mobilenet_fpn/ckpt-10000.\n",
      "restored from checkpoint: out/maskrcnn_mobilenet_fpn/ckpt-10000\n",
      "train | step:  10000 | training until step 10100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1721759895.956551 2681704 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -58 } dim { size: -43 } dim { size: -44 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2700 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "2024-07-23 20:38:52.663669: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:  10100 | steps/sec:    1.5 | output: \n",
      "    {'frcnn_box_loss': 0.20523308,\n",
      "     'frcnn_cls_loss': 0.07739122,\n",
      "     'learning_rate': 0.12,\n",
      "     'mask_loss': 0.18824834,\n",
      "     'model_loss': 0.5338817,\n",
      "     'rpn_box_loss': 0.055377863,\n",
      "     'rpn_score_loss': 0.0076312465,\n",
      "     'total_loss': 0.71559393,\n",
      "     'training_loss': 0.71559393}\n",
      " eval | step:  10100 | running 278 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1721759963.200437 2681704 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -6 } dim { size: -7 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2700 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n",
      "2024-07-23 20:39:47.037707: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-07-23 20:39:47.037770: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-07-23 20:39:47.835998: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.524\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=6.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " eval | step:  10100 | steps/sec:    3.5 | eval time:   79.3 sec | output: \n",
      "    {'AP': 0.4637765,\n",
      "     'AP50': 0.74545,\n",
      "     'AP75': 0.5240075,\n",
      "     'APl': -1.0,\n",
      "     'APm': -1.0,\n",
      "     'APs': 0.47270262,\n",
      "     'ARl': -1.0,\n",
      "     'ARm': -1.0,\n",
      "     'ARmax1': 0.14421585,\n",
      "     'ARmax10': 0.52665585,\n",
      "     'ARmax100': 0.5408049,\n",
      "     'ARs': 0.5408049,\n",
      "     'mask_AP': 0.0017932071,\n",
      "     'mask_AP50': 0.0025099474,\n",
      "     'mask_AP75': 0.001980198,\n",
      "     'mask_APl': -1.0,\n",
      "     'mask_APm': -1.0,\n",
      "     'mask_APs': 0.004271929,\n",
      "     'mask_ARl': -1.0,\n",
      "     'mask_ARm': -1.0,\n",
      "     'mask_ARmax1': 0.0047464357,\n",
      "     'mask_ARmax10': 0.010377188,\n",
      "     'mask_ARmax100': 0.010467425,\n",
      "     'mask_ARs': 0.010467425,\n",
      "     'steps_per_second': 3.5037263329680224,\n",
      "     'validation_loss': 0.0}[]\n",
      "\n",
      "train | step:  10100 | training until step 10200...\n",
      "train | step:  10200 | steps/sec:    1.0 | output: \n",
      "    {'frcnn_box_loss': 0.19505887,\n",
      "     'frcnn_cls_loss': 0.07382937,\n",
      "     'learning_rate': 0.12,\n",
      "     'mask_loss': 0.20373163,\n",
      "     'model_loss': 0.52813315,\n",
      "     'rpn_box_loss': 0.048442375,\n",
      "     'rpn_score_loss': 0.0070709344,\n",
      "     'total_loss': 0.7089471,\n",
      "     'training_loss': 0.7089471}\n",
      " eval | step:  10200 | running 278 steps of evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1721760066.365365 2681704 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -6 } dim { size: -7 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 112 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2700 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 134217728 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 112 } dim { size: 112 } dim { size: 1 } } }\n"
     ]
    }
   ],
   "source": [
    "send_pushover_notification(\"Starting Training\", \"Tensorflow Models\")\n",
    "\n",
    "with intercept_stdout(tfm_log):\n",
    "    model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train_and_eval',\n",
    "        params=exp_config,\n",
    "        model_dir=MODEL_DIR,\n",
    "        run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "send_pushover_notification(\"Finished Training\", \"Tensorflow Models\")\n",
    "\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[IMAGE_SIZE[1], IMAGE_SIZE[0]],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(MODEL_DIR),\n",
    "    export_dir=f'{MODEL_DIR}/final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow Models",
   "language": "python",
   "name": "tf_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
