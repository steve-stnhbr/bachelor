{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/.conda/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lib.Mask2Former as m2f\n",
    "import lib.Mask2Former.mask2former as mask2former\n",
    "import os\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from detectron2.engine import (launch)\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from lib.Mask2Former.train_net import Trainer\n",
    "import numpy as np\n",
    "from detectron2.structures import Boxes, Instances, BitMasks\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"combined\"\n",
    "DATA_LOCATION = \"_data\"\n",
    "DATA_DIR = \"coco\"\n",
    "os.environ[\"DETECTRON2_DATASETS\"] = os.path.join(DATA_LOCATION, DATA_DIR)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the dataset to COCO format\n",
    "The following commands convert the existing PNG mask-based dataset to the coco annotations required for training Mask2Former"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!cd {DATA_LOCATION} && python mask_to_coco.py --images {DATA_SOURCE}/val/images/ --masks {DATA_SOURCE}/val/leaf_instances/ --output {DATA_DIR}/annotations/instances_val2017.json --fixed-category-id 58 --fixed-category-name \"potted plant\" --default-categories\n",
    "!cd {DATA_LOCATION} && python mask_to_coco.py --images {DATA_SOURCE}/train/images/ --masks {DATA_SOURCE}/train/leaf_instances/ --output {DATA_DIR}/annotations/instances_train2017.json --fixed-category-id 58 --fixed-category-name \"potted plant\" --default-categories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!cd {DATA_LOCATION} && mkdir {DATA_DIR}/train2017\n",
    "!cd {DATA_LOCATION} && cp {DATA_SOURCE}/train/images/* {DATA_DIR}/train2017\n",
    "!cd {DATA_LOCATION} && mkdir {DATA_DIR}/val2017\n",
    "!cd {DATA_LOCATION} && cp {DATA_SOURCE}/val/images/* {DATA_DIR}/val2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = \"lib/Mask2Former/configs/coco/instance-segmentation/swin/maskformer2_swin_base_IN21k_384_bs16_50ep.yaml\"\n",
    "NUM_GPUS = 1\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_DIR = \"_data/urban_street_combined\"\n",
    "IMAGES_DIR_NAME = \"images\"\n",
    "IMAGE_DIR = os.path.join(DATASET_DIR, IMAGES_DIR_NAME)\n",
    "INSTANCES_DIR_NAME = \"leaf_instances\"\n",
    "INSTANCES_DIR = os.path.join(DATASET_DIR, INSTANCES_DIR_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeavesDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[index])\n",
    "        label_path = os.path.join(self.label_dir, self.image_files[index])\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = Image.open(label_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label).squeeze()\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "\n",
    "        # Create instances\n",
    "        instances = Instances(image.shape[1:])\n",
    "\n",
    "        # Create gt_boxes\n",
    "        boxes = []\n",
    "        gt_classes = []\n",
    "        gt_masks = []\n",
    "        unique_labels = torch.unique(label)\n",
    "        if len(unique_labels) > 1:\n",
    "            if 255 in unique_labels: \n",
    "                print(\"Invalid label in file\", image_path)\n",
    "            for obj_class in unique_labels:\n",
    "                if obj_class > 0:\n",
    "                    mask = label == obj_class\n",
    "                    coords = torch.nonzero(mask)\n",
    "                    xmin, ymin = coords.min(dim=0).values\n",
    "                    xmax, ymax = coords.max(dim=0).values\n",
    "                    boxes.append([xmin, ymin, xmax, ymax])\n",
    "                    gt_classes.append(obj_class.item())\n",
    "                    gt_masks.append(mask)\n",
    "\n",
    "            instances.gt_boxes = Boxes(torch.tensor(boxes))\n",
    "            instances.gt_classes = torch.tensor(gt_classes, dtype=torch.long)\n",
    "\n",
    "            # Resize masks to match the image size\n",
    "            resized_masks = []\n",
    "            for mask in gt_masks:\n",
    "                resized_mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=image.shape[1:], mode='nearest').squeeze().to(torch.bool)\n",
    "                resized_masks.append(resized_mask)\n",
    "\n",
    "            if len(resized_masks) > 0:\n",
    "                instances.gt_masks = torch.stack(resized_masks)\n",
    "            else:\n",
    "                print(\"Masks empty, class lenght is\", len(gt_classes))\n",
    "                instances.gt_masks = torch.Tensor()\n",
    "\n",
    "            return {\n",
    "                \"image\": image,\n",
    "                \"height\": image.shape[1],\n",
    "                \"width\": image.shape[2],\n",
    "                \"instances\": instances,\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"height\": image.shape[1],\n",
    "            \"width\": image.shape[2]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    instances = []\n",
    "    extras = {}\n",
    "\n",
    "    for item in batch:\n",
    "        images.append(item[\"image\"])\n",
    "        \n",
    "        item_instances = item[\"instances\"]\n",
    "        item_instances[\"gt_boxes\"] = torch.tensor(item_instances[\"gt_boxes\"])\n",
    "        item_instances[\"gt_classes\"] = torch.tensor(item_instances[\"gt_classes\"], dtype=torch.long)\n",
    "        item_instances[\"gt_masks\"] = torch.tensor(item_instances[\"gt_masks\"])\n",
    "        instances.append(item_instances)\n",
    "        \n",
    "        extras[\"height\"] = item[\"height\"]\n",
    "        extras[\"width\"] = item[\"width\"]\n",
    "\n",
    "    batched_inputs = [\n",
    "        {\"image\": image, \"instances\": instance, **extras}\n",
    "        for image, instance in zip(images, instances)\n",
    "    ]\n",
    "\n",
    "    return batched_inputs\n",
    "\n",
    "class LeavesTrainer(Trainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, _):\n",
    "        # Define your data transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((800, 800)),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        # Create the dataset\n",
    "        dataset = LeavesDataset(IMAGE_DIR, INSTANCES_DIR, transform=transform, )\n",
    "        \n",
    "        # Create the DataLoader\n",
    "        dataloader = build_detection_train_loader(dataset, mapper=None, total_batch_size=1)\n",
    "        #dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_trainer(cfg):\n",
    "    trainer = LeavesTrainer(cfg)\n",
    "    #trainer.resume_or_load(resume=args.resume)\n",
    "    return trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/.conda/envs/pytorch/lib/python3.12/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/16 19:31:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "MaskFormer(\n",
      "  (backbone): D2SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.013)\n",
      "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.026)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.039)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.052)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.065)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.078)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.091)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.104)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.117)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.130)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.143)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.157)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.170)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.183)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.196)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (12): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.209)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (13): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.222)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (14): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.235)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (15): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.248)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (16): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.261)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (17): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.274)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.287)\n",
      "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (sem_seg_head): MaskFormerHead(\n",
      "    (pixel_decoder): MSDeformAttnPixelDecoder(\n",
      "      (input_proj): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (transformer): MSDeformAttnTransformerEncoderOnly(\n",
      "        (encoder): MSDeformAttnTransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(\n",
      "              (self_attn): MSDeformAttn(\n",
      "                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
      "                (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
      "                (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (dropout1): Dropout(p=0.0, inplace=False)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.0, inplace=False)\n",
      "              (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (dropout3): Dropout(p=0.0, inplace=False)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 128\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (adapter_1): Conv2d(\n",
      "        128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (predictor): MultiScaleMaskedTransformerDecoder(\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 128\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "      (transformer_self_attention_layers): ModuleList(\n",
      "        (0-8): 9 x SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (transformer_cross_attention_layers): ModuleList(\n",
      "        (0-8): 9 x CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (transformer_ffn_layers): ModuleList(\n",
      "        (0-8): 9 x FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (query_feat): Embedding(100, 256)\n",
      "      (query_embed): Embedding(100, 256)\n",
      "      (level_embed): Embedding(3, 256)\n",
      "      (input_proj): ModuleList(\n",
      "        (0-2): 3 x Sequential()\n",
      "      )\n",
      "      (class_embed): Linear(in_features=256, out_features=81, bias=True)\n",
      "      (mask_embed): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): Criterion SetCriterion\n",
      "      matcher: Matcher HungarianMatcher\n",
      "          cost_class: 2.0\n",
      "          cost_mask: 5.0\n",
      "          cost_dice: 5.0\n",
      "      losses: ['labels', 'masks']\n",
      "      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}\n",
      "      num_classes: 80\n",
      "      eos_coef: 0.1\n",
      "      num_points: 12544\n",
      "      oversample_ratio: 3.0\n",
      "      importance_sample_ratio: 0.75\n",
      ")\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "\u001b[32m[07/16 19:31:46 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[07/16 19:31:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/.conda/envs/pytorch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/16 19:31:56 d2.utils.events]: \u001b[0m eta: 1 day, 22:26:17  iter: 19  total_loss: 123.4  loss_ce: 5.416  loss_mask: 2.164  loss_dice: 4.68  loss_ce_0: 8.857  loss_mask_0: 2.087  loss_dice_0: 4.352  loss_ce_1: 6.32  loss_mask_1: 2.261  loss_dice_1: 4.452  loss_ce_2: 6.239  loss_mask_2: 2.354  loss_dice_2: 4.508  loss_ce_3: 6.153  loss_mask_3: 2.237  loss_dice_3: 4.521  loss_ce_4: 5.983  loss_mask_4: 2.081  loss_dice_4: 4.653  loss_ce_5: 5.822  loss_mask_5: 2.271  loss_dice_5: 4.575  loss_ce_6: 5.702  loss_mask_6: 2.156  loss_dice_6: 4.611  loss_ce_7: 5.416  loss_mask_7: 2.503  loss_dice_7: 4.57  loss_ce_8: 5.408  loss_mask_8: 2.242  loss_dice_8: 4.677    time: 0.4683  last_time: 0.4544  data_time: 0.0270  last_data_time: 0.0200   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:32:06 d2.utils.events]: \u001b[0m eta: 1 day, 22:14:44  iter: 39  total_loss: 105.9  loss_ce: 3.757  loss_mask: 1.954  loss_dice: 4.659  loss_ce_0: 9.027  loss_mask_0: 1.613  loss_dice_0: 4.334  loss_ce_1: 3.895  loss_mask_1: 1.556  loss_dice_1: 4.346  loss_ce_2: 3.778  loss_mask_2: 1.578  loss_dice_2: 4.409  loss_ce_3: 3.777  loss_mask_3: 1.661  loss_dice_3: 4.443  loss_ce_4: 3.816  loss_mask_4: 1.813  loss_dice_4: 4.548  loss_ce_5: 3.816  loss_mask_5: 1.858  loss_dice_5: 4.595  loss_ce_6: 3.767  loss_mask_6: 1.994  loss_dice_6: 4.568  loss_ce_7: 3.77  loss_mask_7: 1.806  loss_dice_7: 4.598  loss_ce_8: 3.755  loss_mask_8: 1.866  loss_dice_8: 4.646    time: 0.4613  last_time: 0.4501  data_time: 0.0238  last_data_time: 0.0215   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:32:15 d2.utils.events]: \u001b[0m eta: 1 day, 22:06:58  iter: 59  total_loss: 106.4  loss_ce: 3.803  loss_mask: 2.144  loss_dice: 4.531  loss_ce_0: 8.934  loss_mask_0: 1.448  loss_dice_0: 4.397  loss_ce_1: 3.783  loss_mask_1: 1.539  loss_dice_1: 4.394  loss_ce_2: 3.74  loss_mask_2: 1.566  loss_dice_2: 4.372  loss_ce_3: 3.771  loss_mask_3: 1.748  loss_dice_3: 4.421  loss_ce_4: 3.725  loss_mask_4: 1.905  loss_dice_4: 4.435  loss_ce_5: 3.767  loss_mask_5: 2.053  loss_dice_5: 4.51  loss_ce_6: 3.766  loss_mask_6: 2.086  loss_dice_6: 4.528  loss_ce_7: 3.787  loss_mask_7: 2.063  loss_dice_7: 4.544  loss_ce_8: 3.856  loss_mask_8: 2.069  loss_dice_8: 4.523    time: 0.4585  last_time: 0.4692  data_time: 0.0241  last_data_time: 0.0210   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:32:24 d2.utils.events]: \u001b[0m eta: 1 day, 22:06:49  iter: 79  total_loss: 102.3  loss_ce: 3.572  loss_mask: 1.759  loss_dice: 4.541  loss_ce_0: 8.859  loss_mask_0: 1.61  loss_dice_0: 4.446  loss_ce_1: 3.512  loss_mask_1: 1.547  loss_dice_1: 4.427  loss_ce_2: 3.557  loss_mask_2: 1.637  loss_dice_2: 4.47  loss_ce_3: 3.462  loss_mask_3: 1.633  loss_dice_3: 4.465  loss_ce_4: 3.453  loss_mask_4: 1.532  loss_dice_4: 4.47  loss_ce_5: 3.54  loss_mask_5: 1.703  loss_dice_5: 4.472  loss_ce_6: 3.574  loss_mask_6: 1.757  loss_dice_6: 4.512  loss_ce_7: 3.623  loss_mask_7: 1.678  loss_dice_7: 4.578  loss_ce_8: 3.608  loss_mask_8: 1.766  loss_dice_8: 4.549    time: 0.4562  last_time: 0.4612  data_time: 0.0231  last_data_time: 0.0242   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:32:33 d2.utils.events]: \u001b[0m eta: 1 day, 21:59:50  iter: 99  total_loss: 100.6  loss_ce: 3.459  loss_mask: 1.847  loss_dice: 4.55  loss_ce_0: 8.786  loss_mask_0: 1.663  loss_dice_0: 4.309  loss_ce_1: 3.23  loss_mask_1: 1.664  loss_dice_1: 4.414  loss_ce_2: 3.198  loss_mask_2: 1.63  loss_dice_2: 4.392  loss_ce_3: 3.152  loss_mask_3: 1.754  loss_dice_3: 4.399  loss_ce_4: 3.293  loss_mask_4: 1.652  loss_dice_4: 4.396  loss_ce_5: 3.333  loss_mask_5: 1.64  loss_dice_5: 4.385  loss_ce_6: 3.384  loss_mask_6: 1.65  loss_dice_6: 4.404  loss_ce_7: 3.497  loss_mask_7: 1.833  loss_dice_7: 4.573  loss_ce_8: 3.451  loss_mask_8: 1.74  loss_dice_8: 4.513    time: 0.4558  last_time: 0.4779  data_time: 0.0241  last_data_time: 0.0231   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:32:42 d2.utils.events]: \u001b[0m eta: 1 day, 21:59:41  iter: 119  total_loss: 99.42  loss_ce: 3.352  loss_mask: 1.831  loss_dice: 4.655  loss_ce_0: 8.84  loss_mask_0: 1.77  loss_dice_0: 4.35  loss_ce_1: 3.192  loss_mask_1: 1.769  loss_dice_1: 4.385  loss_ce_2: 3.025  loss_mask_2: 1.72  loss_dice_2: 4.346  loss_ce_3: 3.106  loss_mask_3: 1.74  loss_dice_3: 4.501  loss_ce_4: 3.45  loss_mask_4: 1.512  loss_dice_4: 4.422  loss_ce_5: 3.309  loss_mask_5: 1.496  loss_dice_5: 4.393  loss_ce_6: 3.174  loss_mask_6: 1.587  loss_dice_6: 4.45  loss_ce_7: 3.338  loss_mask_7: 1.875  loss_dice_7: 4.619  loss_ce_8: 3.293  loss_mask_8: 1.508  loss_dice_8: 4.395    time: 0.4556  last_time: 0.4392  data_time: 0.0233  last_data_time: 0.0217   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:32:51 d2.utils.events]: \u001b[0m eta: 1 day, 22:05:42  iter: 139  total_loss: 95.61  loss_ce: 2.957  loss_mask: 1.492  loss_dice: 4.556  loss_ce_0: 8.783  loss_mask_0: 1.705  loss_dice_0: 4.26  loss_ce_1: 3.1  loss_mask_1: 1.786  loss_dice_1: 4.255  loss_ce_2: 3.076  loss_mask_2: 1.82  loss_dice_2: 4.443  loss_ce_3: 2.922  loss_mask_3: 1.794  loss_dice_3: 4.491  loss_ce_4: 2.802  loss_mask_4: 1.544  loss_dice_4: 4.464  loss_ce_5: 2.916  loss_mask_5: 1.543  loss_dice_5: 4.538  loss_ce_6: 2.923  loss_mask_6: 1.452  loss_dice_6: 4.609  loss_ce_7: 2.94  loss_mask_7: 1.588  loss_dice_7: 4.567  loss_ce_8: 2.963  loss_mask_8: 1.459  loss_dice_8: 4.562    time: 0.4557  last_time: 0.4700  data_time: 0.0241  last_data_time: 0.0158   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:00 d2.utils.events]: \u001b[0m eta: 1 day, 22:05:33  iter: 159  total_loss: 100  loss_ce: 3.603  loss_mask: 1.497  loss_dice: 4.41  loss_ce_0: 8.696  loss_mask_0: 1.681  loss_dice_0: 4.195  loss_ce_1: 3.481  loss_mask_1: 1.639  loss_dice_1: 4.21  loss_ce_2: 3.635  loss_mask_2: 1.635  loss_dice_2: 4.198  loss_ce_3: 3.625  loss_mask_3: 1.626  loss_dice_3: 4.308  loss_ce_4: 3.521  loss_mask_4: 1.524  loss_dice_4: 4.24  loss_ce_5: 3.653  loss_mask_5: 1.56  loss_dice_5: 4.379  loss_ce_6: 3.602  loss_mask_6: 1.472  loss_dice_6: 4.477  loss_ce_7: 3.623  loss_mask_7: 1.429  loss_dice_7: 4.506  loss_ce_8: 3.846  loss_mask_8: 1.471  loss_dice_8: 4.489    time: 0.4555  last_time: 0.4731  data_time: 0.0244  last_data_time: 0.0278   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:09 d2.utils.events]: \u001b[0m eta: 1 day, 22:03:43  iter: 179  total_loss: 98.97  loss_ce: 3.539  loss_mask: 1.592  loss_dice: 4.595  loss_ce_0: 8.736  loss_mask_0: 1.837  loss_dice_0: 4.072  loss_ce_1: 3.314  loss_mask_1: 1.79  loss_dice_1: 4.091  loss_ce_2: 3.188  loss_mask_2: 1.885  loss_dice_2: 4.097  loss_ce_3: 3.305  loss_mask_3: 1.806  loss_dice_3: 4.219  loss_ce_4: 3.139  loss_mask_4: 1.701  loss_dice_4: 4.228  loss_ce_5: 3.431  loss_mask_5: 1.656  loss_dice_5: 4.311  loss_ce_6: 3.417  loss_mask_6: 1.642  loss_dice_6: 4.522  loss_ce_7: 3.416  loss_mask_7: 1.519  loss_dice_7: 4.619  loss_ce_8: 3.453  loss_mask_8: 1.497  loss_dice_8: 4.639    time: 0.4553  last_time: 0.4388  data_time: 0.0241  last_data_time: 0.0209   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:18 d2.utils.events]: \u001b[0m eta: 1 day, 22:03:34  iter: 199  total_loss: 94.59  loss_ce: 3.27  loss_mask: 1.429  loss_dice: 4.494  loss_ce_0: 8.654  loss_mask_0: 1.709  loss_dice_0: 4.012  loss_ce_1: 3.054  loss_mask_1: 1.757  loss_dice_1: 4.057  loss_ce_2: 2.757  loss_mask_2: 1.712  loss_dice_2: 4.091  loss_ce_3: 3.081  loss_mask_3: 1.698  loss_dice_3: 4.103  loss_ce_4: 3.032  loss_mask_4: 1.706  loss_dice_4: 4.21  loss_ce_5: 3.12  loss_mask_5: 1.639  loss_dice_5: 4.226  loss_ce_6: 2.986  loss_mask_6: 1.62  loss_dice_6: 4.195  loss_ce_7: 3.144  loss_mask_7: 1.526  loss_dice_7: 4.504  loss_ce_8: 3.208  loss_mask_8: 1.616  loss_dice_8: 4.401    time: 0.4556  last_time: 0.4538  data_time: 0.0247  last_data_time: 0.0291   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:28 d2.utils.events]: \u001b[0m eta: 1 day, 22:02:08  iter: 219  total_loss: 97.23  loss_ce: 3.432  loss_mask: 1.452  loss_dice: 4.473  loss_ce_0: 8.611  loss_mask_0: 1.932  loss_dice_0: 3.93  loss_ce_1: 3.308  loss_mask_1: 1.973  loss_dice_1: 3.929  loss_ce_2: 3.12  loss_mask_2: 1.913  loss_dice_2: 4.076  loss_ce_3: 2.951  loss_mask_3: 2.069  loss_dice_3: 4.062  loss_ce_4: 2.91  loss_mask_4: 1.928  loss_dice_4: 4.284  loss_ce_5: 2.933  loss_mask_5: 1.899  loss_dice_5: 4.364  loss_ce_6: 2.845  loss_mask_6: 1.953  loss_dice_6: 4.33  loss_ce_7: 3.154  loss_mask_7: 1.634  loss_dice_7: 4.505  loss_ce_8: 3.344  loss_mask_8: 1.698  loss_dice_8: 4.381    time: 0.4554  last_time: 0.4521  data_time: 0.0235  last_data_time: 0.0238   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:37 d2.utils.events]: \u001b[0m eta: 1 day, 22:03:05  iter: 239  total_loss: 96.11  loss_ce: 3.194  loss_mask: 2.179  loss_dice: 4.171  loss_ce_0: 8.52  loss_mask_0: 2.013  loss_dice_0: 3.865  loss_ce_1: 2.989  loss_mask_1: 2.168  loss_dice_1: 3.864  loss_ce_2: 2.948  loss_mask_2: 2.127  loss_dice_2: 3.865  loss_ce_3: 3.073  loss_mask_3: 2.2  loss_dice_3: 3.883  loss_ce_4: 3.002  loss_mask_4: 2.021  loss_dice_4: 3.948  loss_ce_5: 3.046  loss_mask_5: 2.051  loss_dice_5: 4.049  loss_ce_6: 2.877  loss_mask_6: 1.94  loss_dice_6: 4.128  loss_ce_7: 2.892  loss_mask_7: 1.822  loss_dice_7: 4.252  loss_ce_8: 3.052  loss_mask_8: 2.05  loss_dice_8: 3.971    time: 0.4554  last_time: 0.4500  data_time: 0.0248  last_data_time: 0.0261   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:46 d2.utils.events]: \u001b[0m eta: 1 day, 22:04:15  iter: 259  total_loss: 92.57  loss_ce: 2.78  loss_mask: 2.28  loss_dice: 3.704  loss_ce_0: 8.59  loss_mask_0: 1.996  loss_dice_0: 3.566  loss_ce_1: 2.681  loss_mask_1: 2.059  loss_dice_1: 3.547  loss_ce_2: 2.892  loss_mask_2: 2.083  loss_dice_2: 3.576  loss_ce_3: 2.935  loss_mask_3: 1.947  loss_dice_3: 3.657  loss_ce_4: 2.751  loss_mask_4: 2.226  loss_dice_4: 3.628  loss_ce_5: 2.772  loss_mask_5: 2.165  loss_dice_5: 3.709  loss_ce_6: 2.586  loss_mask_6: 2.279  loss_dice_6: 3.976  loss_ce_7: 2.764  loss_mask_7: 2.081  loss_dice_7: 3.939  loss_ce_8: 2.699  loss_mask_8: 2.293  loss_dice_8: 3.655    time: 0.4554  last_time: 0.4459  data_time: 0.0234  last_data_time: 0.0200   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:33:55 d2.utils.events]: \u001b[0m eta: 1 day, 22:06:00  iter: 279  total_loss: 93.97  loss_ce: 3.208  loss_mask: 2.433  loss_dice: 3.568  loss_ce_0: 8.581  loss_mask_0: 2.24  loss_dice_0: 3.471  loss_ce_1: 3.116  loss_mask_1: 2.333  loss_dice_1: 3.411  loss_ce_2: 2.992  loss_mask_2: 2.349  loss_dice_2: 3.372  loss_ce_3: 3.035  loss_mask_3: 2.403  loss_dice_3: 3.285  loss_ce_4: 3.074  loss_mask_4: 2.322  loss_dice_4: 3.452  loss_ce_5: 3.067  loss_mask_5: 2.451  loss_dice_5: 3.44  loss_ce_6: 3.06  loss_mask_6: 2.38  loss_dice_6: 3.444  loss_ce_7: 3.163  loss_mask_7: 2.441  loss_dice_7: 3.515  loss_ce_8: 3.254  loss_mask_8: 2.544  loss_dice_8: 3.479    time: 0.4555  last_time: 0.4649  data_time: 0.0229  last_data_time: 0.0200   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:04 d2.utils.events]: \u001b[0m eta: 1 day, 22:08:34  iter: 299  total_loss: 93.67  loss_ce: 3.084  loss_mask: 2.12  loss_dice: 3.615  loss_ce_0: 8.464  loss_mask_0: 1.958  loss_dice_0: 3.55  loss_ce_1: 3.124  loss_mask_1: 2.071  loss_dice_1: 3.428  loss_ce_2: 3.062  loss_mask_2: 2.104  loss_dice_2: 3.488  loss_ce_3: 3.093  loss_mask_3: 2.06  loss_dice_3: 3.618  loss_ce_4: 2.965  loss_mask_4: 2.224  loss_dice_4: 3.711  loss_ce_5: 3.222  loss_mask_5: 2.007  loss_dice_5: 3.651  loss_ce_6: 3.327  loss_mask_6: 2.107  loss_dice_6: 3.674  loss_ce_7: 3.061  loss_mask_7: 2.146  loss_dice_7: 3.701  loss_ce_8: 2.932  loss_mask_8: 2.119  loss_dice_8: 3.507    time: 0.4555  last_time: 0.4513  data_time: 0.0251  last_data_time: 0.0245   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:13 d2.utils.events]: \u001b[0m eta: 1 day, 22:08:25  iter: 319  total_loss: 90.89  loss_ce: 3.025  loss_mask: 2.075  loss_dice: 3.709  loss_ce_0: 8.475  loss_mask_0: 2.13  loss_dice_0: 3.49  loss_ce_1: 3.248  loss_mask_1: 2.04  loss_dice_1: 3.487  loss_ce_2: 3.221  loss_mask_2: 2.227  loss_dice_2: 3.546  loss_ce_3: 3.068  loss_mask_3: 2.185  loss_dice_3: 3.465  loss_ce_4: 3.224  loss_mask_4: 2.137  loss_dice_4: 3.504  loss_ce_5: 3.194  loss_mask_5: 2.121  loss_dice_5: 3.389  loss_ce_6: 3.151  loss_mask_6: 2.204  loss_dice_6: 3.583  loss_ce_7: 3.337  loss_mask_7: 2.016  loss_dice_7: 3.767  loss_ce_8: 3.022  loss_mask_8: 2.143  loss_dice_8: 3.685    time: 0.4553  last_time: 0.4485  data_time: 0.0241  last_data_time: 0.0232   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:22 d2.utils.events]: \u001b[0m eta: 1 day, 22:08:16  iter: 339  total_loss: 95.96  loss_ce: 3.109  loss_mask: 2.114  loss_dice: 3.491  loss_ce_0: 8.385  loss_mask_0: 1.953  loss_dice_0: 3.367  loss_ce_1: 3.206  loss_mask_1: 2.2  loss_dice_1: 3.431  loss_ce_2: 3.166  loss_mask_2: 2.057  loss_dice_2: 3.287  loss_ce_3: 3.154  loss_mask_3: 2.091  loss_dice_3: 3.42  loss_ce_4: 3.247  loss_mask_4: 2.154  loss_dice_4: 3.483  loss_ce_5: 3.284  loss_mask_5: 2.205  loss_dice_5: 3.863  loss_ce_6: 3.407  loss_mask_6: 2.152  loss_dice_6: 3.595  loss_ce_7: 3.26  loss_mask_7: 2.026  loss_dice_7: 3.63  loss_ce_8: 3.273  loss_mask_8: 2.218  loss_dice_8: 3.542    time: 0.4552  last_time: 0.4338  data_time: 0.0246  last_data_time: 0.0167   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:31 d2.utils.events]: \u001b[0m eta: 1 day, 22:08:07  iter: 359  total_loss: 94.55  loss_ce: 3.445  loss_mask: 1.943  loss_dice: 3.375  loss_ce_0: 8.366  loss_mask_0: 2.062  loss_dice_0: 3.439  loss_ce_1: 3.371  loss_mask_1: 2.164  loss_dice_1: 3.327  loss_ce_2: 3.195  loss_mask_2: 2.086  loss_dice_2: 3.321  loss_ce_3: 3.287  loss_mask_3: 2.113  loss_dice_3: 3.382  loss_ce_4: 3.37  loss_mask_4: 2.092  loss_dice_4: 3.332  loss_ce_5: 3.36  loss_mask_5: 2.014  loss_dice_5: 3.348  loss_ce_6: 3.375  loss_mask_6: 2.029  loss_dice_6: 3.45  loss_ce_7: 3.357  loss_mask_7: 2.019  loss_dice_7: 3.471  loss_ce_8: 3.297  loss_mask_8: 2.088  loss_dice_8: 3.452    time: 0.4552  last_time: 0.4561  data_time: 0.0270  last_data_time: 0.0287   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:40 d2.utils.events]: \u001b[0m eta: 1 day, 22:08:46  iter: 379  total_loss: 90  loss_ce: 3.114  loss_mask: 2.284  loss_dice: 3.372  loss_ce_0: 8.341  loss_mask_0: 2.16  loss_dice_0: 3.233  loss_ce_1: 3.107  loss_mask_1: 2.227  loss_dice_1: 3.128  loss_ce_2: 2.998  loss_mask_2: 2.107  loss_dice_2: 3.067  loss_ce_3: 2.964  loss_mask_3: 2.107  loss_dice_3: 3.187  loss_ce_4: 3.185  loss_mask_4: 2.248  loss_dice_4: 3.101  loss_ce_5: 3.166  loss_mask_5: 2.138  loss_dice_5: 3.129  loss_ce_6: 3.229  loss_mask_6: 2.12  loss_dice_6: 3.245  loss_ce_7: 3.424  loss_mask_7: 2.188  loss_dice_7: 3.334  loss_ce_8: 2.995  loss_mask_8: 2.401  loss_dice_8: 3.382    time: 0.4553  last_time: 0.4532  data_time: 0.0226  last_data_time: 0.0227   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:50 d2.utils.events]: \u001b[0m eta: 1 day, 22:07:49  iter: 399  total_loss: 91.24  loss_ce: 3.375  loss_mask: 2.062  loss_dice: 3.28  loss_ce_0: 8.402  loss_mask_0: 2.016  loss_dice_0: 3.413  loss_ce_1: 3.181  loss_mask_1: 1.944  loss_dice_1: 3.26  loss_ce_2: 3.354  loss_mask_2: 2.043  loss_dice_2: 3.302  loss_ce_3: 3.329  loss_mask_3: 1.967  loss_dice_3: 3.304  loss_ce_4: 3.376  loss_mask_4: 1.961  loss_dice_4: 3.282  loss_ce_5: 3.321  loss_mask_5: 2.044  loss_dice_5: 3.289  loss_ce_6: 3.258  loss_mask_6: 1.918  loss_dice_6: 3.527  loss_ce_7: 3.296  loss_mask_7: 2.02  loss_dice_7: 3.464  loss_ce_8: 3.338  loss_mask_8: 2.057  loss_dice_8: 3.262    time: 0.4551  last_time: 0.4370  data_time: 0.0236  last_data_time: 0.0167   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:34:59 d2.utils.events]: \u001b[0m eta: 1 day, 22:06:11  iter: 419  total_loss: 91.9  loss_ce: 3.128  loss_mask: 2.083  loss_dice: 3.371  loss_ce_0: 8.311  loss_mask_0: 1.956  loss_dice_0: 3.238  loss_ce_1: 3.119  loss_mask_1: 2.108  loss_dice_1: 3.288  loss_ce_2: 3.2  loss_mask_2: 1.918  loss_dice_2: 3.12  loss_ce_3: 3.122  loss_mask_3: 2.029  loss_dice_3: 3.146  loss_ce_4: 3.115  loss_mask_4: 2.198  loss_dice_4: 3.236  loss_ce_5: 3.26  loss_mask_5: 2.038  loss_dice_5: 3.156  loss_ce_6: 3.074  loss_mask_6: 1.977  loss_dice_6: 3.283  loss_ce_7: 3.055  loss_mask_7: 2.086  loss_dice_7: 3.342  loss_ce_8: 3.049  loss_mask_8: 2.105  loss_dice_8: 3.31    time: 0.4550  last_time: 0.4591  data_time: 0.0228  last_data_time: 0.0211   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:35:08 d2.utils.events]: \u001b[0m eta: 1 day, 22:07:43  iter: 439  total_loss: 92.34  loss_ce: 3.575  loss_mask: 1.897  loss_dice: 3.421  loss_ce_0: 8.204  loss_mask_0: 1.86  loss_dice_0: 3.435  loss_ce_1: 3.51  loss_mask_1: 1.921  loss_dice_1: 3.418  loss_ce_2: 3.586  loss_mask_2: 1.86  loss_dice_2: 3.236  loss_ce_3: 3.672  loss_mask_3: 1.984  loss_dice_3: 3.232  loss_ce_4: 3.604  loss_mask_4: 1.918  loss_dice_4: 3.283  loss_ce_5: 3.487  loss_mask_5: 1.938  loss_dice_5: 3.234  loss_ce_6: 3.52  loss_mask_6: 2.044  loss_dice_6: 3.397  loss_ce_7: 3.595  loss_mask_7: 2.183  loss_dice_7: 3.528  loss_ce_8: 3.503  loss_mask_8: 1.931  loss_dice_8: 3.487    time: 0.4550  last_time: 0.4630  data_time: 0.0245  last_data_time: 0.0241   lr: 1e-05  max_mem: 6713M\n",
      "\u001b[32m[07/16 19:35:17 d2.utils.events]: \u001b[0m eta: 1 day, 22:06:37  iter: 459  total_loss: 91.27  loss_ce: 3.419  loss_mask: 1.942  loss_dice: 3.255  loss_ce_0: 8.262  loss_mask_0: 1.784  loss_dice_0: 3.225  loss_ce_1: 3.398  loss_mask_1: 2.007  loss_dice_1: 3.223  loss_ce_2: 3.412  loss_mask_2: 1.809  loss_dice_2: 2.993  loss_ce_3: 3.392  loss_mask_3: 1.978  loss_dice_3: 3.412  loss_ce_4: 3.512  loss_mask_4: 1.984  loss_dice_4: 3.303  loss_ce_5: 3.514  loss_mask_5: 1.912  loss_dice_5: 3.066  loss_ce_6: 3.532  loss_mask_6: 1.902  loss_dice_6: 3.113  loss_ce_7: 3.405  loss_mask_7: 1.853  loss_dice_7: 3.031  loss_ce_8: 3.307  loss_mask_8: 1.785  loss_dice_8: 3.165    time: 0.4550  last_time: 0.4485  data_time: 0.0247  last_data_time: 0.0257   lr: 1e-05  max_mem: 6713M\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "mask2former.add_maskformer2_config(cfg)\n",
    "cfg.merge_from_file(CONFIG)\n",
    "\n",
    "launch(get_trainer, 1, args=(cfg,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
