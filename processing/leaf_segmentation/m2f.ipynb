{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/.conda/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lib.Mask2Former as m2f\n",
    "import lib.Mask2Former.mask2former as mask2former\n",
    "import os\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from detectron2.engine import (launch)\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from lib.Mask2Former.train_net import Trainer\n",
    "import numpy as np\n",
    "from detectron2.structures import Boxes, Instances, BitMasks\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from detectron2.evaluation import DatasetEvaluator, DatasetEvaluators\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.utils import comm\n",
    "from detectron2.structures import BoxMode, pairwise_iou\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"combined\"\n",
    "DATA_LOCATION = \"_data\"\n",
    "DATA_DIR = \"coco\"\n",
    "os.environ[\"DETECTRON2_DATASETS\"] = os.path.join(DATA_LOCATION, DATA_DIR)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the dataset to COCO format\n",
    "The following commands convert the existing PNG mask-based dataset to the coco annotations required for training Mask2Former"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!cd {DATA_LOCATION} && python mask_to_coco.py --images {DATA_SOURCE}/val/images/ --masks {DATA_SOURCE}/val/leaf_instances/ --output {DATA_DIR}/annotations/instances_val2017.json --fixed-category-id 58 --fixed-category-name \"potted plant\" --default-categories\n",
    "!cd {DATA_LOCATION} && python mask_to_coco.py --images {DATA_SOURCE}/train/images/ --masks {DATA_SOURCE}/train/leaf_instances/ --output {DATA_DIR}/annotations/instances_train2017.json --fixed-category-id 58 --fixed-category-name \"potted plant\" --default-categories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!cd {DATA_LOCATION} && mkdir {DATA_DIR}/train2017\n",
    "!cd {DATA_LOCATION} && cp {DATA_SOURCE}/train/images/* {DATA_DIR}/train2017\n",
    "!cd {DATA_LOCATION} && mkdir {DATA_DIR}/val2017\n",
    "!cd {DATA_LOCATION} && cp {DATA_SOURCE}/val/images/* {DATA_DIR}/val2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = \"lib/Mask2Former/configs/coco/instance-segmentation/swin/maskformer2_swin_base_IN21k_384_bs16_50ep.yaml\"\n",
    "#CONFIG = \"configs/mask2former.yaml\"\n",
    "NUM_GPUS = 1\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_DIR = \"_data/urban_street_combined\"\n",
    "DATASET_DIR_VAL = \"_data/combined/val\"\n",
    "IMAGES_DIR_NAME = \"images\"\n",
    "IMAGE_DIR = os.path.join(DATASET_DIR, IMAGES_DIR_NAME)\n",
    "INSTANCES_DIR_NAME = \"leaf_instances\"\n",
    "INSTANCES_DIR = os.path.join(DATASET_DIR, INSTANCES_DIR_NAME)\n",
    "IMAGE_DIR_VAL = os.path.join(DATASET_DIR_VAL, IMAGES_DIR_NAME)\n",
    "INSTANCES_DIR_VAL = os.path.join(DATASET_DIR_VAL, INSTANCES_DIR_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeavesDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[index])\n",
    "        label_path = os.path.join(self.label_dir, self.image_files[index])\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = Image.open(label_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label).squeeze()\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "\n",
    "        # Create instances\n",
    "        instances = Instances(image.shape[1:])\n",
    "\n",
    "        # Create gt_boxes\n",
    "        boxes = []\n",
    "        gt_classes = []\n",
    "        gt_masks = []\n",
    "        unique_labels = torch.unique(label)\n",
    "        if len(unique_labels) > 1:\n",
    "            if 255 in unique_labels: \n",
    "                print(\"Invalid label in file\", image_path)\n",
    "            for obj_class in unique_labels:\n",
    "                if obj_class > 0:\n",
    "                    mask = label == obj_class\n",
    "                    coords = torch.nonzero(mask)\n",
    "                    xmin, ymin = coords.min(dim=0).values\n",
    "                    xmax, ymax = coords.max(dim=0).values\n",
    "                    boxes.append([xmin, ymin, xmax, ymax])\n",
    "                    gt_classes.append(obj_class.item())\n",
    "                    gt_masks.append(mask)\n",
    "\n",
    "            instances.gt_boxes = Boxes(torch.tensor(boxes))\n",
    "            instances.gt_classes = torch.tensor(gt_classes, dtype=torch.long)\n",
    "\n",
    "            # Resize masks to match the image size\n",
    "            resized_masks = []\n",
    "            for mask in gt_masks:\n",
    "                resized_mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=image.shape[1:], mode='nearest').squeeze().to(torch.bool)\n",
    "                resized_masks.append(resized_mask)\n",
    "\n",
    "            if len(resized_masks) > 0:\n",
    "                instances.gt_masks = torch.stack(resized_masks)\n",
    "            else:\n",
    "                print(\"Masks empty, class lenght is\", len(gt_classes))\n",
    "                instances.gt_masks = torch.Tensor()\n",
    "\n",
    "            return {\n",
    "                \"image\": image,\n",
    "                \"height\": image.shape[1],\n",
    "                \"width\": image.shape[2],\n",
    "                \"instances\": instances,\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"height\": image.shape[1],\n",
    "            \"width\": image.shape[2]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeavesEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "        self._cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "    def reset(self):\n",
    "        self._predictions = []\n",
    "        self._targets = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        # sample single random instance\n",
    "#        idx = random.randrange(len(inputs))\n",
    "#        self._predictions.append(outputs[idx][\"instances\"].to(self._cpu_device))\n",
    "#        self._targets.append(inputs[idx][\"instances\"].to(self._cpu_device))\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            self._predictions.append(output[\"instances\"].to(self._cpu_device))\n",
    "            self._targets.append(input[\"instances\"].to(self._cpu_device))\n",
    "\n",
    "    def evaluate(self):\n",
    "        if comm.is_main_process():\n",
    "            self._evaluate()\n",
    "\n",
    "        if comm.is_main_process():\n",
    "            return copy.deepcopy(self._results)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _evaluate(self):\n",
    "        self._results = {}\n",
    "        iou_thresholds = [0.5, 0.75]\n",
    "        for iou_threshold in iou_thresholds:\n",
    "            self._results[f\"IoU_{iou_threshold}\"] = self._compute_iou(iou_threshold)\n",
    "        #self._results[\"mask_mse_loss\"] = self._compute_mask_mse_loss()\n",
    "        print(self._results)\n",
    "\n",
    "    def _compute_iou(self, iou_threshold):\n",
    "        print(\"Computing IoU\")\n",
    "        num_instances = len(self._predictions)\n",
    "        iou_sum = 0.0\n",
    "\n",
    "        for pred, target in zip(self._predictions, self._targets):\n",
    "            pred_boxes = pred.pred_boxes.tensor\n",
    "            target_boxes = target.gt_boxes.tensor\n",
    "\n",
    "            if len(pred_boxes) == 0 or len(target_boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            # Convert the boxes to the format expected by the pairwise_iou function\n",
    "            pred_boxes = BoxMode.convert(pred_boxes, BoxMode.XYXY_ABS, BoxMode.XYXY_ABS)\n",
    "            target_boxes = BoxMode.convert(target_boxes, BoxMode.XYXY_ABS, BoxMode.XYXY_ABS)\n",
    "\n",
    "            # Compute IoU between predicted and target boxes\n",
    "            iou_matrix = pairwise_iou(Boxes(pred_boxes), Boxes(target_boxes))\n",
    "            max_iou, _ = iou_matrix.max(dim=1)\n",
    "\n",
    "            # Count the number of predicted boxes with IoU above the threshold\n",
    "            num_above_threshold = (max_iou > iou_threshold).sum().item()\n",
    "            iou_sum += num_above_threshold\n",
    "\n",
    "        avg_iou = iou_sum / num_instances\n",
    "        return avg_iou\n",
    "    \n",
    "    def _compute_mask_mse_loss(self):\n",
    "        print(\"Computing Mask MSE Loss\")\n",
    "        loss = 0\n",
    "        for pred, target in zip(self._predictions, self._targets):\n",
    "            for pred_mask, target_mask in zip(pred.pred_masks, target.gt_masks):\n",
    "                print(\"Single MSE\")\n",
    "                target_mask = target_mask.float()\n",
    "                diff2 = (torch.flatten(pred_mask) - torch.flatten(target_mask)) ** 2.0\n",
    "                sum2 = 0.0\n",
    "                num = 0\n",
    "\n",
    "                flat_mask = torch.flatten(target_mask)\n",
    "                assert(len(flat_mask) == len(diff2))\n",
    "                for i in range(len(diff2)):\n",
    "                    if flat_mask[i] == 1:\n",
    "                        sum2 += diff2[i]\n",
    "                        num += 1\n",
    "\n",
    "                loss += sum2 / num\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    instances = []\n",
    "    extras = {}\n",
    "\n",
    "    for item in batch:\n",
    "        images.append(item[\"image\"])\n",
    "        \n",
    "        item_instances = item[\"instances\"]\n",
    "        item_instances[\"gt_boxes\"] = torch.tensor(item_instances[\"gt_boxes\"])\n",
    "        item_instances[\"gt_classes\"] = torch.tensor(item_instances[\"gt_classes\"], dtype=torch.long)\n",
    "        item_instances[\"gt_masks\"] = torch.tensor(item_instances[\"gt_masks\"])\n",
    "        instances.append(item_instances)\n",
    "        \n",
    "        extras[\"height\"] = item[\"height\"]\n",
    "        extras[\"width\"] = item[\"width\"]\n",
    "\n",
    "    batched_inputs = [\n",
    "        {\"image\": image, \"instances\": instance, **extras}\n",
    "        for image, instance in zip(images, instances)\n",
    "    ]\n",
    "\n",
    "    return batched_inputs\n",
    "\n",
    "class LeavesTrainer(Trainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, _):\n",
    "        # Define your data transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((800, 800)),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        # Create the dataset\n",
    "        dataset = LeavesDataset(IMAGE_DIR, INSTANCES_DIR, transform=transform, )\n",
    "        \n",
    "        # Create the DataLoader\n",
    "        dataloader = build_detection_train_loader(dataset, mapper=None, total_batch_size=1)\n",
    "        return dataloader\n",
    "    \n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        # Define your data transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((800, 800)),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        # Create the dataset\n",
    "        dataset = LeavesDataset(IMAGE_DIR_VAL, INSTANCES_DIR_VAL, transform=transform, )\n",
    "        \n",
    "        # Create the DataLoader\n",
    "        dataloader = build_detection_test_loader(dataset, mapper=None)\n",
    "        return dataloader\n",
    "        \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return LeavesEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_trainer(cfg):\n",
    "    trainer = LeavesTrainer(cfg)\n",
    "    #trainer.resume_or_load(resume=args.resume)\n",
    "    return trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/.conda/envs/pytorch/lib/python3.12/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/17 13:17:57 d2.engine.defaults]: \u001b[0mModel:\n",
      "MaskFormer(\n",
      "  (backbone): D2SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.013)\n",
      "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.026)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.039)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.052)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.065)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.078)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.091)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.104)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.117)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.130)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.143)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.157)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.170)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.183)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.196)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (12): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.209)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (13): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.222)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (14): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.235)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (15): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.248)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (16): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.261)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (17): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.274)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.287)\n",
      "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (sem_seg_head): MaskFormerHead(\n",
      "    (pixel_decoder): MSDeformAttnPixelDecoder(\n",
      "      (input_proj): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (transformer): MSDeformAttnTransformerEncoderOnly(\n",
      "        (encoder): MSDeformAttnTransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(\n",
      "              (self_attn): MSDeformAttn(\n",
      "                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
      "                (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
      "                (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (dropout1): Dropout(p=0.0, inplace=False)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.0, inplace=False)\n",
      "              (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (dropout3): Dropout(p=0.0, inplace=False)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 128\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (adapter_1): Conv2d(\n",
      "        128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (predictor): MultiScaleMaskedTransformerDecoder(\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 128\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "      (transformer_self_attention_layers): ModuleList(\n",
      "        (0-8): 9 x SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (transformer_cross_attention_layers): ModuleList(\n",
      "        (0-8): 9 x CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (transformer_ffn_layers): ModuleList(\n",
      "        (0-8): 9 x FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (query_feat): Embedding(100, 256)\n",
      "      (query_embed): Embedding(100, 256)\n",
      "      (level_embed): Embedding(3, 256)\n",
      "      (input_proj): ModuleList(\n",
      "        (0-2): 3 x Sequential()\n",
      "      )\n",
      "      (class_embed): Linear(in_features=256, out_features=81, bias=True)\n",
      "      (mask_embed): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): Criterion SetCriterion\n",
      "      matcher: Matcher HungarianMatcher\n",
      "          cost_class: 2.0\n",
      "          cost_mask: 5.0\n",
      "          cost_dice: 5.0\n",
      "      losses: ['labels', 'masks']\n",
      "      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}\n",
      "      num_classes: 80\n",
      "      eos_coef: 0.1\n",
      "      num_points: 12544\n",
      "      oversample_ratio: 3.0\n",
      "      importance_sample_ratio: 0.75\n",
      ")\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "relative_position_bias_table\n",
      "\u001b[32m[07/17 13:17:57 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[07/17 13:17:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/.conda/envs/pytorch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/17 13:18:07 d2.utils.events]: \u001b[0m eta: 1 day, 22:30:23  iter: 19  total_loss: 123.8  loss_ce: 5.645  loss_mask: 3.125  loss_dice: 4.55  loss_ce_0: 9.081  loss_mask_0: 2.052  loss_dice_0: 4.103  loss_ce_1: 6.476  loss_mask_1: 2.465  loss_dice_1: 4.167  loss_ce_2: 5.377  loss_mask_2: 2.474  loss_dice_2: 4.455  loss_ce_3: 5.071  loss_mask_3: 2.617  loss_dice_3: 4.43  loss_ce_4: 5.116  loss_mask_4: 2.751  loss_dice_4: 4.404  loss_ce_5: 4.81  loss_mask_5: 2.609  loss_dice_5: 4.458  loss_ce_6: 4.862  loss_mask_6: 3.194  loss_dice_6: 4.504  loss_ce_7: 4.975  loss_mask_7: 2.961  loss_dice_7: 4.411  loss_ce_8: 5.389  loss_mask_8: 2.617  loss_dice_8: 4.519    time: 0.4626  last_time: 0.4405  data_time: 0.0263  last_data_time: 0.0194   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:18:15 d2.utils.events]: \u001b[0m eta: 1 day, 21:09:39  iter: 39  total_loss: 106.9  loss_ce: 3.962  loss_mask: 1.695  loss_dice: 4.584  loss_ce_0: 8.836  loss_mask_0: 1.597  loss_dice_0: 4.377  loss_ce_1: 3.741  loss_mask_1: 1.454  loss_dice_1: 4.415  loss_ce_2: 3.952  loss_mask_2: 1.48  loss_dice_2: 4.475  loss_ce_3: 3.974  loss_mask_3: 1.457  loss_dice_3: 4.538  loss_ce_4: 3.989  loss_mask_4: 1.609  loss_dice_4: 4.609  loss_ce_5: 3.933  loss_mask_5: 1.609  loss_dice_5: 4.644  loss_ce_6: 3.951  loss_mask_6: 1.448  loss_dice_6: 4.665  loss_ce_7: 3.945  loss_mask_7: 1.494  loss_dice_7: 4.646  loss_ce_8: 4.037  loss_mask_8: 1.693  loss_dice_8: 4.606    time: 0.4514  last_time: 0.4336  data_time: 0.0234  last_data_time: 0.0202   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:18:24 d2.utils.events]: \u001b[0m eta: 1 day, 20:56:48  iter: 59  total_loss: 101.5  loss_ce: 3.21  loss_mask: 1.953  loss_dice: 4.498  loss_ce_0: 9.076  loss_mask_0: 1.722  loss_dice_0: 4.382  loss_ce_1: 3.026  loss_mask_1: 1.893  loss_dice_1: 4.419  loss_ce_2: 2.983  loss_mask_2: 1.818  loss_dice_2: 4.308  loss_ce_3: 2.945  loss_mask_3: 1.811  loss_dice_3: 4.403  loss_ce_4: 3.139  loss_mask_4: 1.934  loss_dice_4: 4.371  loss_ce_5: 3.186  loss_mask_5: 1.963  loss_dice_5: 4.428  loss_ce_6: 3.227  loss_mask_6: 2.044  loss_dice_6: 4.534  loss_ce_7: 3.256  loss_mask_7: 2.105  loss_dice_7: 4.441  loss_ce_8: 3.268  loss_mask_8: 2.144  loss_dice_8: 4.464    time: 0.4478  last_time: 0.4384  data_time: 0.0244  last_data_time: 0.0256   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:18:33 d2.utils.events]: \u001b[0m eta: 1 day, 20:55:50  iter: 79  total_loss: 101.6  loss_ce: 3.211  loss_mask: 1.832  loss_dice: 4.643  loss_ce_0: 8.942  loss_mask_0: 1.818  loss_dice_0: 4.338  loss_ce_1: 2.927  loss_mask_1: 1.74  loss_dice_1: 4.412  loss_ce_2: 2.772  loss_mask_2: 1.58  loss_dice_2: 4.444  loss_ce_3: 2.8  loss_mask_3: 1.632  loss_dice_3: 4.495  loss_ce_4: 2.91  loss_mask_4: 1.703  loss_dice_4: 4.471  loss_ce_5: 3.066  loss_mask_5: 1.704  loss_dice_5: 4.49  loss_ce_6: 3.216  loss_mask_6: 1.677  loss_dice_6: 4.558  loss_ce_7: 3.16  loss_mask_7: 1.868  loss_dice_7: 4.649  loss_ce_8: 3.217  loss_mask_8: 1.747  loss_dice_8: 4.595    time: 0.4452  last_time: 0.4312  data_time: 0.0228  last_data_time: 0.0196   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:18:42 d2.utils.events]: \u001b[0m eta: 1 day, 20:51:54  iter: 99  total_loss: 100.6  loss_ce: 3.586  loss_mask: 1.845  loss_dice: 4.582  loss_ce_0: 8.894  loss_mask_0: 1.515  loss_dice_0: 4.494  loss_ce_1: 3.297  loss_mask_1: 1.658  loss_dice_1: 4.389  loss_ce_2: 3.098  loss_mask_2: 1.629  loss_dice_2: 4.435  loss_ce_3: 3.248  loss_mask_3: 1.736  loss_dice_3: 4.423  loss_ce_4: 3.248  loss_mask_4: 1.584  loss_dice_4: 4.438  loss_ce_5: 3.263  loss_mask_5: 1.61  loss_dice_5: 4.472  loss_ce_6: 3.412  loss_mask_6: 1.704  loss_dice_6: 4.478  loss_ce_7: 3.54  loss_mask_7: 1.778  loss_dice_7: 4.568  loss_ce_8: 3.586  loss_mask_8: 1.798  loss_dice_8: 4.558    time: 0.4440  last_time: 0.4330  data_time: 0.0233  last_data_time: 0.0204   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:18:51 d2.utils.events]: \u001b[0m eta: 1 day, 20:50:03  iter: 119  total_loss: 97.54  loss_ce: 3.248  loss_mask: 1.432  loss_dice: 4.649  loss_ce_0: 8.801  loss_mask_0: 1.529  loss_dice_0: 4.442  loss_ce_1: 2.826  loss_mask_1: 1.438  loss_dice_1: 4.506  loss_ce_2: 2.755  loss_mask_2: 1.362  loss_dice_2: 4.562  loss_ce_3: 2.956  loss_mask_3: 1.513  loss_dice_3: 4.636  loss_ce_4: 2.814  loss_mask_4: 1.592  loss_dice_4: 4.532  loss_ce_5: 2.992  loss_mask_5: 1.606  loss_dice_5: 4.538  loss_ce_6: 3.146  loss_mask_6: 1.519  loss_dice_6: 4.532  loss_ce_7: 3.241  loss_mask_7: 1.409  loss_dice_7: 4.616  loss_ce_8: 3.244  loss_mask_8: 1.412  loss_dice_8: 4.68    time: 0.4430  last_time: 0.4383  data_time: 0.0221  last_data_time: 0.0215   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:18:59 d2.utils.events]: \u001b[0m eta: 1 day, 20:48:58  iter: 139  total_loss: 99.95  loss_ce: 3.572  loss_mask: 1.951  loss_dice: 4.632  loss_ce_0: 8.726  loss_mask_0: 1.775  loss_dice_0: 4.326  loss_ce_1: 3.341  loss_mask_1: 1.691  loss_dice_1: 4.398  loss_ce_2: 2.84  loss_mask_2: 1.621  loss_dice_2: 4.43  loss_ce_3: 3.11  loss_mask_3: 1.596  loss_dice_3: 4.396  loss_ce_4: 3.23  loss_mask_4: 1.731  loss_dice_4: 4.398  loss_ce_5: 3.343  loss_mask_5: 1.676  loss_dice_5: 4.501  loss_ce_6: 3.485  loss_mask_6: 1.491  loss_dice_6: 4.478  loss_ce_7: 3.457  loss_mask_7: 1.614  loss_dice_7: 4.51  loss_ce_8: 3.538  loss_mask_8: 1.804  loss_dice_8: 4.624    time: 0.4428  last_time: 0.4338  data_time: 0.0248  last_data_time: 0.0237   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:19:08 d2.utils.events]: \u001b[0m eta: 1 day, 20:50:12  iter: 159  total_loss: 100.9  loss_ce: 3.509  loss_mask: 1.615  loss_dice: 4.444  loss_ce_0: 8.769  loss_mask_0: 2.07  loss_dice_0: 4.09  loss_ce_1: 3.691  loss_mask_1: 1.973  loss_dice_1: 4.114  loss_ce_2: 3.329  loss_mask_2: 1.921  loss_dice_2: 4.157  loss_ce_3: 3.44  loss_mask_3: 1.859  loss_dice_3: 4.23  loss_ce_4: 3.43  loss_mask_4: 1.768  loss_dice_4: 4.22  loss_ce_5: 3.382  loss_mask_5: 1.787  loss_dice_5: 4.224  loss_ce_6: 3.459  loss_mask_6: 1.84  loss_dice_6: 4.284  loss_ce_7: 3.487  loss_mask_7: 1.709  loss_dice_7: 4.354  loss_ce_8: 3.588  loss_mask_8: 1.706  loss_dice_8: 4.407    time: 0.4429  last_time: 0.4289  data_time: 0.0261  last_data_time: 0.0223   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:19:17 d2.utils.events]: \u001b[0m eta: 1 day, 20:52:19  iter: 179  total_loss: 98.27  loss_ce: 3.372  loss_mask: 1.649  loss_dice: 4.316  loss_ce_0: 8.685  loss_mask_0: 1.553  loss_dice_0: 4.18  loss_ce_1: 3.324  loss_mask_1: 1.61  loss_dice_1: 4.189  loss_ce_2: 3.539  loss_mask_2: 1.583  loss_dice_2: 4.212  loss_ce_3: 3.514  loss_mask_3: 1.58  loss_dice_3: 4.281  loss_ce_4: 3.586  loss_mask_4: 1.508  loss_dice_4: 4.372  loss_ce_5: 3.478  loss_mask_5: 1.446  loss_dice_5: 4.438  loss_ce_6: 3.504  loss_mask_6: 1.425  loss_dice_6: 4.419  loss_ce_7: 3.412  loss_mask_7: 1.495  loss_dice_7: 4.496  loss_ce_8: 3.514  loss_mask_8: 1.388  loss_dice_8: 4.442    time: 0.4430  last_time: 0.4303  data_time: 0.0241  last_data_time: 0.0197   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:19:26 d2.utils.events]: \u001b[0m eta: 1 day, 20:52:11  iter: 199  total_loss: 95.71  loss_ce: 3.009  loss_mask: 1.867  loss_dice: 4.065  loss_ce_0: 8.609  loss_mask_0: 1.895  loss_dice_0: 3.91  loss_ce_1: 2.999  loss_mask_1: 1.801  loss_dice_1: 3.958  loss_ce_2: 2.874  loss_mask_2: 1.906  loss_dice_2: 3.974  loss_ce_3: 3.01  loss_mask_3: 1.945  loss_dice_3: 3.953  loss_ce_4: 3.066  loss_mask_4: 1.934  loss_dice_4: 4.07  loss_ce_5: 3.047  loss_mask_5: 1.957  loss_dice_5: 4.191  loss_ce_6: 3.221  loss_mask_6: 1.688  loss_dice_6: 4.341  loss_ce_7: 3.264  loss_mask_7: 1.875  loss_dice_7: 4.15  loss_ce_8: 3.233  loss_mask_8: 1.884  loss_dice_8: 4.09    time: 0.4426  last_time: 0.4289  data_time: 0.0228  last_data_time: 0.0190   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:19:35 d2.utils.events]: \u001b[0m eta: 1 day, 20:52:02  iter: 219  total_loss: 92.07  loss_ce: 2.835  loss_mask: 1.803  loss_dice: 3.973  loss_ce_0: 8.694  loss_mask_0: 2  loss_dice_0: 3.84  loss_ce_1: 2.614  loss_mask_1: 2.04  loss_dice_1: 3.876  loss_ce_2: 2.714  loss_mask_2: 1.931  loss_dice_2: 3.842  loss_ce_3: 2.581  loss_mask_3: 1.95  loss_dice_3: 3.928  loss_ce_4: 2.648  loss_mask_4: 1.952  loss_dice_4: 3.912  loss_ce_5: 2.496  loss_mask_5: 1.959  loss_dice_5: 3.971  loss_ce_6: 2.628  loss_mask_6: 1.871  loss_dice_6: 4.143  loss_ce_7: 2.658  loss_mask_7: 1.91  loss_dice_7: 4.037  loss_ce_8: 2.694  loss_mask_8: 1.868  loss_dice_8: 4.051    time: 0.4423  last_time: 0.4343  data_time: 0.0223  last_data_time: 0.0216   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:19:44 d2.utils.events]: \u001b[0m eta: 1 day, 20:51:21  iter: 239  total_loss: 96.96  loss_ce: 3.535  loss_mask: 2.041  loss_dice: 3.88  loss_ce_0: 8.634  loss_mask_0: 2.105  loss_dice_0: 3.804  loss_ce_1: 3.376  loss_mask_1: 2.029  loss_dice_1: 3.788  loss_ce_2: 3.206  loss_mask_2: 2.095  loss_dice_2: 3.846  loss_ce_3: 3.11  loss_mask_3: 2.133  loss_dice_3: 3.826  loss_ce_4: 3.104  loss_mask_4: 2.146  loss_dice_4: 3.768  loss_ce_5: 3.397  loss_mask_5: 2.046  loss_dice_5: 3.907  loss_ce_6: 3.356  loss_mask_6: 2.098  loss_dice_6: 3.869  loss_ce_7: 3.355  loss_mask_7: 2.163  loss_dice_7: 3.841  loss_ce_8: 3.217  loss_mask_8: 2.1  loss_dice_8: 4.027    time: 0.4423  last_time: 0.4416  data_time: 0.0254  last_data_time: 0.0235   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:19:52 d2.utils.events]: \u001b[0m eta: 1 day, 20:51:13  iter: 259  total_loss: 99.88  loss_ce: 3.541  loss_mask: 1.953  loss_dice: 4.004  loss_ce_0: 8.549  loss_mask_0: 2.1  loss_dice_0: 3.792  loss_ce_1: 3.258  loss_mask_1: 2.055  loss_dice_1: 3.874  loss_ce_2: 3.243  loss_mask_2: 2.027  loss_dice_2: 3.87  loss_ce_3: 3.404  loss_mask_3: 2.018  loss_dice_3: 3.876  loss_ce_4: 3.49  loss_mask_4: 2.098  loss_dice_4: 4.005  loss_ce_5: 3.585  loss_mask_5: 2.079  loss_dice_5: 3.96  loss_ce_6: 3.394  loss_mask_6: 1.856  loss_dice_6: 4.147  loss_ce_7: 3.464  loss_mask_7: 1.911  loss_dice_7: 4.162  loss_ce_8: 3.585  loss_mask_8: 2.035  loss_dice_8: 4.061    time: 0.4421  last_time: 0.4365  data_time: 0.0226  last_data_time: 0.0207   lr: 1e-05  max_mem: 6709M\n",
      "\u001b[32m[07/17 13:20:01 d2.utils.events]: \u001b[0m eta: 1 day, 20:50:41  iter: 279  total_loss: 97.39  loss_ce: 3.322  loss_mask: 1.9  loss_dice: 3.837  loss_ce_0: 8.522  loss_mask_0: 2.002  loss_dice_0: 3.591  loss_ce_1: 3.237  loss_mask_1: 1.968  loss_dice_1: 3.575  loss_ce_2: 3.257  loss_mask_2: 1.959  loss_dice_2: 3.727  loss_ce_3: 3.399  loss_mask_3: 2.047  loss_dice_3: 3.705  loss_ce_4: 3.643  loss_mask_4: 1.978  loss_dice_4: 3.699  loss_ce_5: 3.39  loss_mask_5: 1.968  loss_dice_5: 3.827  loss_ce_6: 3.468  loss_mask_6: 1.896  loss_dice_6: 3.731  loss_ce_7: 3.592  loss_mask_7: 1.941  loss_dice_7: 3.717  loss_ce_8: 3.401  loss_mask_8: 1.875  loss_dice_8: 3.761    time: 0.4419  last_time: 0.4332  data_time: 0.0236  last_data_time: 0.0208   lr: 1e-05  max_mem: 6709M\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "mask2former.add_maskformer2_config(cfg)\n",
    "cfg.merge_from_file(CONFIG)\n",
    "\n",
    "launch(get_trainer, 1, args=(cfg,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
