{
 "cells": [
  {
   "cell_type": "raw",
   "id": "faaa53f5-0968-4909-a0a8-cb962bc8ee3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "!git clone https://github.com/lrpalmer27/Mask-RCNN-TF2.git -d lib/mrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62362bdb-3708-4b45-b56c-f8b8c617ce85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan.steinheber/bachelor/processing/leaf_segmentation/lib/mrcnn_tf2/mrcnn/model.py:2402: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if os.name is 'nt':\n",
      "2024-11-10 14:06:06.751951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-10 14:06:06.751979: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(ROOT_DIR)  \u001b[38;5;66;03m# To find local version of the library\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrcnn_tf2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrcnn_tf2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model \u001b[38;5;28;01mas\u001b[39;00m modellib, utils\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Path to trained weights file\u001b[39;00m\n\u001b[1;32m     29\u001b[0m COCO_MODEL_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_rcnn_coco.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/bachelor/processing/leaf_segmentation/lib/mrcnn_tf2/mrcnn/model.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mK\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mKL\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_source_inputs\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_summary\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/vis_utils.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wrapper\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# `pydot` is an optional dependency,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# see `extras_require` in `setup.py`.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/models.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_arg\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_list\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# note: `Node` is an internal class,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# it isn't meant to be used by Keras users.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputSpec\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/input_layer.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count_params\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_arg\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/initializers/__init__.py:124\u001b[0m\n\u001b[1;32m    118\u001b[0m   LOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m LOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# For backwards compatibility, we populate this file with the objects\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# using their correct version.\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mpopulate_deserializable_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(LOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Utility functions\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/initializers/__init__.py:82\u001b[0m, in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m v2_objs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     81\u001b[0m base_cls \u001b[38;5;241m=\u001b[39m initializers_v2\u001b[38;5;241m.\u001b[39mInitializer\n\u001b[0;32m---> 82\u001b[0m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_dict_with_module_objects\u001b[49m(\n\u001b[1;32m     83\u001b[0m     v2_objs,\n\u001b[1;32m     84\u001b[0m     [initializers_v2],\n\u001b[1;32m     85\u001b[0m     obj_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: inspect\u001b[38;5;241m.\u001b[39misclass(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x, base_cls))\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m v2_objs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     87\u001b[0m   LOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS[key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"Mask_RCNN\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from lib.mrcnn_tf2.mrcnn.config import Config\n",
    "from lib.mrcnn_tf2.mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(\"logs/mp_mrcnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf25731-80d5-45a2-a812-3809406e2442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeafConfig(Config):\n",
    "    \"\"\"Configuration for training on MS COCO.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"leaves\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    # GPU_COUNT = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # COCO has 80 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefa09a-c74a-4266-a49a-912aecf61b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CocoDataset(utils.Dataset):\n",
    "    def load_coco(self, dataset_dir, ann_file, class_ids=None,\n",
    "                  class_map=None, return_coco=False, auto_download=False):\n",
    "        \"\"\"Load a subset of the COCO dataset.\n",
    "        dataset_dir: The root directory of the COCO dataset.\n",
    "        subset: What to load (train, val, minival, valminusminival)\n",
    "        year: What dataset year to load (2014, 2017) as a string, not an integer\n",
    "        class_ids: If provided, only loads images that have the given classes.\n",
    "        class_map: TODO: Not implemented yet. Supports maping classes from\n",
    "            different datasets to the same class ID.\n",
    "        return_coco: If True, returns the COCO object.\n",
    "        auto_download: Automatically download and unzip MS-COCO images and annotations\n",
    "        \"\"\"\n",
    "\n",
    "        if auto_download is True:\n",
    "            self.auto_download(dataset_dir, subset, year)\n",
    "\n",
    "        coco = COCO(ann_file)\n",
    "        image_dir = dataset_dir\n",
    "\n",
    "        # Load all classes or a subset?\n",
    "        if not class_ids:\n",
    "            # All classes\n",
    "            class_ids = sorted(coco.getCatIds())\n",
    "\n",
    "        # All images or a subset?\n",
    "        if class_ids:\n",
    "            image_ids = []\n",
    "            for id in class_ids:\n",
    "                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n",
    "            # Remove duplicates\n",
    "            image_ids = list(set(image_ids))\n",
    "        else:\n",
    "            # All images\n",
    "            image_ids = list(coco.imgs.keys())\n",
    "\n",
    "        # Add classes\n",
    "        for i in class_ids:\n",
    "            self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n",
    "\n",
    "        # Add images\n",
    "        for i in image_ids:\n",
    "            self.add_image(\n",
    "                \"coco\", image_id=i,\n",
    "                path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
    "                width=coco.imgs[i][\"width\"],\n",
    "                height=coco.imgs[i][\"height\"],\n",
    "                annotations=coco.loadAnns(coco.getAnnIds(\n",
    "                    imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
    "        if return_coco:\n",
    "            return coco\n",
    "\n",
    "    def auto_download(self, dataDir, dataType, dataYear):\n",
    "        \"\"\"Download the COCO dataset/annotations if requested.\n",
    "        dataDir: The root directory of the COCO dataset.\n",
    "        dataType: What to load (train, val, minival, valminusminival)\n",
    "        dataYear: What dataset year to load (2014, 2017) as a string, not an integer\n",
    "        Note:\n",
    "            For 2014, use \"train\", \"val\", \"minival\", or \"valminusminival\"\n",
    "            For 2017, only \"train\" and \"val\" annotations are available\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup paths and file names\n",
    "        if dataType == \"minival\" or dataType == \"valminusminival\":\n",
    "            imgDir = \"{}/{}{}\".format(dataDir, \"val\", dataYear)\n",
    "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, \"val\", dataYear)\n",
    "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(\"val\", dataYear)\n",
    "        else:\n",
    "            imgDir = \"{}/{}{}\".format(dataDir, dataType, dataYear)\n",
    "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, dataType, dataYear)\n",
    "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(dataType, dataYear)\n",
    "        # print(\"Image paths:\"); print(imgDir); print(imgZipFile); print(imgURL)\n",
    "\n",
    "        # Create main folder if it doesn't exist yet\n",
    "        if not os.path.exists(dataDir):\n",
    "            os.makedirs(dataDir)\n",
    "\n",
    "        # Download images if not available locally\n",
    "        if not os.path.exists(imgDir):\n",
    "            os.makedirs(imgDir)\n",
    "            print(\"Downloading images to \" + imgZipFile + \" ...\")\n",
    "            with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n",
    "                shutil.copyfileobj(resp, out)\n",
    "            print(\"... done downloading.\")\n",
    "            print(\"Unzipping \" + imgZipFile)\n",
    "            with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(dataDir)\n",
    "            print(\"... done unzipping\")\n",
    "        print(\"Will use images in \" + imgDir)\n",
    "\n",
    "        # Setup annotations data paths\n",
    "        annDir = \"{}/annotations\".format(dataDir)\n",
    "        if dataType == \"minival\":\n",
    "            annZipFile = \"{}/instances_minival2014.json.zip\".format(dataDir)\n",
    "            annFile = \"{}/instances_minival2014.json\".format(annDir)\n",
    "            annURL = \"https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0\"\n",
    "            unZipDir = annDir\n",
    "        elif dataType == \"valminusminival\":\n",
    "            annZipFile = \"{}/instances_valminusminival2014.json.zip\".format(dataDir)\n",
    "            annFile = \"{}/instances_valminusminival2014.json\".format(annDir)\n",
    "            annURL = \"https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0\"\n",
    "            unZipDir = annDir\n",
    "        else:\n",
    "            annZipFile = \"{}/annotations_trainval{}.zip\".format(dataDir, dataYear)\n",
    "            annFile = \"{}/instances_{}{}.json\".format(annDir, dataType, dataYear)\n",
    "            annURL = \"http://images.cocodataset.org/annotations/annotations_trainval{}.zip\".format(dataYear)\n",
    "            unZipDir = dataDir\n",
    "        # print(\"Annotations paths:\"); print(annDir); print(annFile); print(annZipFile); print(annURL)\n",
    "\n",
    "        # Download annotations if not available locally\n",
    "        if not os.path.exists(annDir):\n",
    "            os.makedirs(annDir)\n",
    "        if not os.path.exists(annFile):\n",
    "            if not os.path.exists(annZipFile):\n",
    "                print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
    "                with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
    "                    shutil.copyfileobj(resp, out)\n",
    "                print(\"... done downloading.\")\n",
    "            print(\"Unzipping \" + annZipFile)\n",
    "            with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(unZipDir)\n",
    "            print(\"... done unzipping\")\n",
    "        print(\"Will use annotations in \" + annFile)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Load instance masks for the given image.\n",
    "\n",
    "        Different datasets use different ways to store masks. This\n",
    "        function converts the different mask format to one format\n",
    "        in the form of a bitmap [height, width, instances].\n",
    "\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a COCO image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"coco\":\n",
    "            return super(CocoDataset, self).load_mask(image_id)\n",
    "\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        annotations = self.image_info[image_id][\"annotations\"]\n",
    "        # Build mask of shape [height, width, instance_count] and list\n",
    "        # of class IDs that correspond to each channel of the mask.\n",
    "        for annotation in annotations:\n",
    "            class_id = self.map_source_class_id(\n",
    "                \"coco.{}\".format(annotation['category_id']))\n",
    "            if class_id:\n",
    "                m = self.annToMask(annotation, image_info[\"height\"],\n",
    "                                   image_info[\"width\"])\n",
    "                # Some objects are so small that they're less than 1 pixel area\n",
    "                # and end up rounded out. Skip those objects.\n",
    "                if m.max() < 1:\n",
    "                    continue\n",
    "                # Is it a crowd? If so, use a negative class ID.\n",
    "                if annotation['iscrowd']:\n",
    "                    # Use negative class ID for crowds\n",
    "                    class_id *= -1\n",
    "                    # For crowd masks, annToMask() sometimes returns a mask\n",
    "                    # smaller than the given dimensions. If so, resize it.\n",
    "                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n",
    "                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n",
    "                instance_masks.append(m)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        # Pack instance masks into an array\n",
    "        if class_ids:\n",
    "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
    "            class_ids = np.array(class_ids, dtype=np.int32)\n",
    "            return mask, class_ids\n",
    "        else:\n",
    "            # Call super class to return an empty mask\n",
    "            return super(CocoDataset, self).load_mask(image_id)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return a link to the image in the COCO Website.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"coco\":\n",
    "            return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n",
    "        else:\n",
    "            super(CocoDataset, self).image_reference(image_id)\n",
    "\n",
    "    # The following two functions are from pycocotools with a few changes.\n",
    "\n",
    "    def annToRLE(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        segm = ann['segmentation']\n",
    "        if isinstance(segm, list):\n",
    "            # polygon -- a single object might consist of multiple parts\n",
    "            # we merge all parts into one mask rle code\n",
    "            rles = maskUtils.frPyObjects(segm, height, width)\n",
    "            rle = maskUtils.merge(rles)\n",
    "        elif isinstance(segm['counts'], list):\n",
    "            # uncompressed RLE\n",
    "            rle = maskUtils.frPyObjects(segm, height, width)\n",
    "        else:\n",
    "            # rle\n",
    "            rle = ann['segmentation']\n",
    "        return rle\n",
    "\n",
    "    def annToMask(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        rle = self.annToRLE(ann, height, width)\n",
    "        m = maskUtils.decode(rle)\n",
    "        return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341edd26-f228-4fa7-b98a-0136c8c08d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_coco_results(dataset, image_ids, rois, class_ids, scores, masks):\n",
    "    \"\"\"Arrange resutls to match COCO specs in http://cocodataset.org/#format\n",
    "    \"\"\"\n",
    "    # If no results, return an empty list\n",
    "    if rois is None:\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for image_id in image_ids:\n",
    "        # Loop through detections\n",
    "        for i in range(rois.shape[0]):\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i]\n",
    "            bbox = np.around(rois[i], 1)\n",
    "            mask = masks[:, :, i]\n",
    "\n",
    "            result = {\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": dataset.get_source_class_id(class_id, \"coco\"),\n",
    "                \"bbox\": [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]],\n",
    "                \"score\": score,\n",
    "                \"segmentation\": maskUtils.encode(np.asfortranarray(mask))\n",
    "            }\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_coco(model, dataset, coco, eval_type=\"bbox\", limit=0, image_ids=None):\n",
    "    \"\"\"Runs official COCO evaluation.\n",
    "    dataset: A Dataset object with valiadtion data\n",
    "    eval_type: \"bbox\" or \"segm\" for bounding box or segmentation evaluation\n",
    "    limit: if not 0, it's the number of images to use for evaluation\n",
    "    \"\"\"\n",
    "    # Pick COCO images from the dataset\n",
    "    image_ids = image_ids or dataset.image_ids\n",
    "\n",
    "    # Limit to a subset\n",
    "    if limit:\n",
    "        image_ids = image_ids[:limit]\n",
    "\n",
    "    # Get corresponding COCO image IDs.\n",
    "    coco_image_ids = [dataset.image_info[id][\"id\"] for id in image_ids]\n",
    "\n",
    "    t_prediction = 0\n",
    "    t_start = time.time()\n",
    "\n",
    "    results = []\n",
    "    for i, image_id in enumerate(image_ids):\n",
    "        # Load image\n",
    "        image = dataset.load_image(image_id)\n",
    "\n",
    "        # Run detection\n",
    "        t = time.time()\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        t_prediction += (time.time() - t)\n",
    "\n",
    "        # Convert results to COCO format\n",
    "        # Cast masks to uint8 because COCO tools errors out on bool\n",
    "        image_results = build_coco_results(dataset, coco_image_ids[i:i + 1],\n",
    "                                           r[\"rois\"], r[\"class_ids\"],\n",
    "                                           r[\"scores\"],\n",
    "                                           r[\"masks\"].astype(np.uint8))\n",
    "        results.extend(image_results)\n",
    "\n",
    "    # Load results. This modifies results with additional attributes.\n",
    "    coco_results = coco.loadRes(results)\n",
    "\n",
    "    # Evaluate\n",
    "    cocoEval = COCOeval(coco, coco_results, eval_type)\n",
    "    cocoEval.params.imgIds = coco_image_ids\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "\n",
    "    print(\"Prediction time: {}. Average {}/image\".format(\n",
    "        t_prediction, t_prediction / len(image_ids)))\n",
    "    print(\"Total time: \", time.time() - t_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bf9db-7745-45aa-9384-6528d737f430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODE = \"train\"\n",
    "MODEL_PATH = \"\"\n",
    "\n",
    "TRAIN_DATASET_DIR = \"_data/synthetic_leaf_instances/train/images\"\n",
    "TRAIN_ANN_FILE = \"_data/coco_synthetic_train.json\"\n",
    "\n",
    "VAL_DATASET_DIR = \"_data/synthetic_leaf_instances/val/images\"\n",
    "VAL_ANN_FILE = \"_data/coco_synthetic_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993ab4f-db83-4784-ba7a-58edd1e7b992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "# Configurations\n",
    "if MODE == \"train\":\n",
    "    config = LeafConfig()\n",
    "else:\n",
    "    class InferenceConfig(LeafConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "        DETECTION_MIN_CONFIDENCE = 0\n",
    "    config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# Create model\n",
    "if MODE == \"train\":\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=DEFAULT_LOGS_DIR)\n",
    "else:\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                              model_dir=DEFAULT_LOGS_DIR)\n",
    "    \n",
    "# Load weights\n",
    "if MODEL_PATH is not None and len(MODEL_PATH) > 0:\n",
    "    print(\"Loading weights \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be41498-6f3c-429f-8cfe-bcf8e062558a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training dataset. Use the training set and 35K from the\n",
    "        # validation set, as as in the Mask RCNN paper.\n",
    "dataset_train = CocoDataset()\n",
    "dataset_train.load_coco(TRAIN_DATASET_DIR, TRAIN_ANN_FILE)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CocoDataset()\n",
    "dataset_val.load_coco(VAL_DATASET_DIR, VAL_ANN_FILE)\n",
    "dataset_val.prepare()\n",
    "\n",
    "# *** This training schedule is an example. Update to your needs ***\n",
    "if MODE == \"train\":\n",
    "    # Training - Stage 1\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                layers='heads')\n",
    "\n",
    "    print(\"Fine tune Resnet stage 4 and up\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=120,\n",
    "                layers='4+')\n",
    "\n",
    "    # Training - Stage 3\n",
    "    # Fine tune all layers\n",
    "    print(\"Fine tune all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE / 10,\n",
    "                epochs=160,\n",
    "                layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0b211-1718-4be0-b13c-caaa73326100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_pt",
   "language": "python",
   "name": "tf_pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
