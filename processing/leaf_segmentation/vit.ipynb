{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vit-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import vit_keras as vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"\"\n",
    "IMAGE_SIZE = (644, 644)\n",
    "CLASSES = 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(path, mask_subdir, batch_size, lab, input_shape):\n",
    "    x = keras.utils.image_dataset_from_directory(os.path.join(path, \"images\"),\n",
    "                                                 batch_size=1,\n",
    "                                                 image_size=input_shape[:2],\n",
    "                                                 crop_to_aspect_ratio=True,\n",
    "                                                 labels=None).map(lambda x0: x0 / 255)#.map(lambda x1: tf.expand_dims(x1, 0) if len(x1.shape) == 3 else x1)\n",
    "    y = keras.utils.image_dataset_from_directory(os.path.join(path, mask_subdir),\n",
    "                                                 batch_size=1,\n",
    "                                                 image_size=input_shape[:2],\n",
    "                                                 crop_to_aspect_ratio=True,\n",
    "                                                 labels=None,\n",
    "                                                 color_mode='grayscale').map(lambda y: to_categorical(y, num_classes=CLASSES))\n",
    "    print(\"Dataset Sizes:\", len(x), len(y))\n",
    "    datagen = tf.data.Dataset.zip((x, y))\n",
    "    datagen = datagen.map(lambda x,y: (tf.squeeze(x, axis=0), tf.squeeze(y, axis=0))).batch(batch_size=batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "    for s in datagen.take(1).as_numpy_iterator():\n",
    "        print(\"X\", s[0].shape, tf.reduce_max(s[0]).numpy())\n",
    "        print(\"Y\", s[1].shape, tf.reduce_max(s[1]).numpy())\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit.vit_l32(\n",
    "    image_size=IMAGE_SIZE[0],\n",
    "    activation='sigmoid',\n",
    "    pretrained=True,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=200\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
