{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import tqdm\n",
    "import shutil\n",
    "import pprint\n",
    "import pathlib\n",
    "import tempfile\n",
    "import requests\n",
    "import collections\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from etils import epath\n",
    "from IPython import display\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbit\n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.data import tfrecord_lib\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.ops.preprocess_ops import normalize_image, resize_and_crop_image\n",
    "from official.vision.data.create_coco_tf_record import coco_annotations_to_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = \"out/mask_rcnn_\"\n",
    "IMAGE_SIZE=(640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(raw_records):\n",
    "    tf_ex_decoder = TfExampleDecoder(include_mask=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates=True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "        scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "        # print(decoded_tensors['groundtruth_instance_masks'].numpy().shape)\n",
    "        # print(decoded_tensors.keys())\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "            decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "            scores,\n",
    "            category_index=category_index,\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            instance_masks=decoded_tensors['groundtruth_instance_masks'].numpy().astype('uint8'),\n",
    "            line_thickness=4)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  image = None\n",
    "  if(path.startswith('http')):\n",
    "    response = urlopen(path)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def build_inputs_for_object_detection(image, input_image_size):\n",
    "  \"\"\"Builds Object Detection model inputs for serving.\"\"\"\n",
    "  image, _ = resize_and_crop_image(\n",
    "      image,\n",
    "      input_image_size,\n",
    "      padded_size=input_image_size,\n",
    "      aug_scale_min=1.0,\n",
    "      aug_scale_max=1.0)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reframe_image_corners_relative_to_boxes(boxes):\n",
    "  \"\"\"Reframe the image corners ([0, 0, 1, 1]) to be relative to boxes.\n",
    "  The local coordinate frame of each box is assumed to be relative to\n",
    "  its own for corners.\n",
    "  Args:\n",
    "    boxes: A float tensor of [num_boxes, 4] of (ymin, xmin, ymax, xmax)\n",
    "      coordinates in relative coordinate space of each bounding box.\n",
    "  Returns:\n",
    "    reframed_boxes: Reframes boxes with same shape as input.\n",
    "  \"\"\"\n",
    "  ymin, xmin, ymax, xmax = (boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3])\n",
    "\n",
    "  height = tf.maximum(ymax - ymin, 1e-4)\n",
    "  width = tf.maximum(xmax - xmin, 1e-4)\n",
    "\n",
    "  ymin_out = (0 - ymin) / height\n",
    "  xmin_out = (0 - xmin) / width\n",
    "  ymax_out = (1 - ymin) / height\n",
    "  xmax_out = (1 - xmin) / width\n",
    "  return tf.stack([ymin_out, xmin_out, ymax_out, xmax_out], axis=1)\n",
    "\n",
    "def reframe_box_masks_to_image_masks(box_masks, boxes, image_height,\n",
    "                                     image_width, resize_method='bilinear'):\n",
    "  \"\"\"Transforms the box masks back to full image masks.\n",
    "  Embeds masks in bounding boxes of larger masks whose shapes correspond to\n",
    "  image shape.\n",
    "  Args:\n",
    "    box_masks: A tensor of size [num_masks, mask_height, mask_width].\n",
    "    boxes: A tf.float32 tensor of size [num_masks, 4] containing the box\n",
    "           corners. Row i contains [ymin, xmin, ymax, xmax] of the box\n",
    "           corresponding to mask i. Note that the box corners are in\n",
    "           normalized coordinates.\n",
    "    image_height: Image height. The output mask will have the same height as\n",
    "                  the image height.\n",
    "    image_width: Image width. The output mask will have the same width as the\n",
    "                 image width.\n",
    "    resize_method: The resize method, either 'bilinear' or 'nearest'. Note that\n",
    "      'bilinear' is only respected if box_masks is a float.\n",
    "  Returns:\n",
    "    A tensor of size [num_masks, image_height, image_width] with the same dtype\n",
    "    as `box_masks`.\n",
    "  \"\"\"\n",
    "  resize_method = 'nearest' if box_masks.dtype == tf.uint8 else resize_method\n",
    "  # TODO(rathodv): Make this a public function.\n",
    "  def reframe_box_masks_to_image_masks_default():\n",
    "    \"\"\"The default function when there are more than 0 box masks.\"\"\"\n",
    "\n",
    "    num_boxes = tf.shape(box_masks)[0]\n",
    "    box_masks_expanded = tf.expand_dims(box_masks, axis=3)\n",
    "\n",
    "    resized_crops = tf.image.crop_and_resize(\n",
    "        image=box_masks_expanded,\n",
    "        boxes=reframe_image_corners_relative_to_boxes(boxes),\n",
    "        box_indices=tf.range(num_boxes),\n",
    "        crop_size=[image_height, image_width],\n",
    "        method=resize_method,\n",
    "        extrapolation_value=0)\n",
    "    return tf.cast(resized_crops, box_masks.dtype)\n",
    "\n",
    "  image_masks = tf.cond(\n",
    "      tf.shape(box_masks)[0] > 0,\n",
    "      reframe_box_masks_to_image_masks_default,\n",
    "      lambda: tf.zeros([0, image_height, image_width, 1], box_masks.dtype))\n",
    "  return tf.squeeze(image_masks, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_examples = 3\n",
    "\n",
    "test_tfrecords = tf.io.gfile.glob('./lvis_tfrecords/val*')\n",
    "test_ds = tf.data.TFRecordDataset(test_tfrecords).take(num_of_examples)\n",
    "show_batch(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(EXPORT_DIR)\n",
    "model_fn = imported.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = (IMAGE_SIZE[1], IMAGE_SIZE[0])\n",
    "plt.figure(figsize=(20, 20))\n",
    "min_score_thresh = 0.40 # Change minimum score for threshold to see all bounding boxes confidences\n",
    "\n",
    "for i, serialized_example in enumerate(test_ds):\n",
    "  plt.subplot(1, 3, i+1)\n",
    "  decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "  image = build_inputs_for_object_detection(decoded_tensors['image'], input_image_size)\n",
    "  image = tf.expand_dims(image, axis=0)\n",
    "  image = tf.cast(image, dtype = tf.uint8)\n",
    "  image_np = image[0].numpy()\n",
    "  result = model_fn(image)\n",
    "  # Visualize detection and masks\n",
    "  if 'detection_masks' in result:\n",
    "    # we need to convert np.arrays to tensors\n",
    "    detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n",
    "    detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n",
    "    detection_masks_reframed = reframe_box_masks_to_image_masks(\n",
    "              detection_masks, detection_boxes/256.0,\n",
    "                image_np.shape[0], image_np.shape[1])\n",
    "    detection_masks_reframed = tf.cast(\n",
    "        detection_masks_reframed > min_score_thresh,\n",
    "        np.uint8)\n",
    "\n",
    "    result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "  visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        result['detection_boxes'][0].numpy(),\n",
    "        (result['detection_classes'][0] + 0).numpy().astype(int),\n",
    "        result['detection_scores'][0].numpy(),\n",
    "        category_index=category_index,\n",
    "        use_normalized_coordinates=False,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        instance_masks=result.get('detection_masks_reframed', None),\n",
    "        line_thickness=4)\n",
    "\n",
    "  plt.imshow(image_np)\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
