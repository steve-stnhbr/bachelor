{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"1INFFo_GO7_9"},"outputs":[],"source":["lab=True\n","epochs=30"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"2UM3KoChCuQa","outputId":"48c9a049-96ca-46d0-d201-924e9333315c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bereits aktuell.\n","Processing /Users/steve/Desktop/Uni/8. Semester Medieninformatik/BCA - Bachelorarbeit/bachelor/processing/disease_detection/schuler_two_branch/raw/two-paths-plant-village/k\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: pandas>=2.2.0 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from cai==0.1.7) (2.2.2)\n","Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from cai==0.1.7) (0.23.2)\n","Requirement already satisfied: opencv-python>=4.1.2.30 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from cai==0.1.7) (4.9.0.80)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from cai==0.1.7) (1.5.0)\n","Requirement already satisfied: numpy in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from cai==0.1.7) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from pandas>=2.2.0->cai==0.1.7) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from pandas>=2.2.0->cai==0.1.7) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from pandas>=2.2.0->cai==0.1.7) (2024.1)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.13.1)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (3.3)\n","Requirement already satisfied: pillow>=9.1 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (10.3.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (2.34.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (2024.5.22)\n","Requirement already satisfied: packaging>=21 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (24.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-learn>=0.21.0->cai==0.1.7) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from scikit-learn>=0.21.0->cai==0.1.7) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/envs/ml/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->cai==0.1.7) (1.16.0)\n","Building wheels for collected packages: cai\n","  Building wheel for cai (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for cai: filename=cai-0.1.7-py3-none-any.whl size=61390 sha256=8abd460430618b856e28dc573256d8bf7ecbcb976f21deeb5197a0d447cd8beb\n","  Stored in directory: /private/var/folders/wk/vf7qm4sj2057ywz857m9vcg40000gn/T/pip-ephem-wheel-cache-e5x4ws25/wheels/b1/36/9d/e647786bdfc02b8abcef4dc11bf4e9cbeb6a4b900b9ef7bf72\n","Successfully built cai\n","Installing collected packages: cai\n","  Attempting uninstall: cai\n","    Found existing installation: cai 0.1.7\n","    Uninstalling cai-0.1.7:\n","      Successfully uninstalled cai-0.1.7\n","Successfully installed cai-0.1.7\n"]}],"source":["#apt-get install git python3-opencv\n","import os\n","\n","if not os.path.isdir('k'):\n","  !git clone https://github.com/joaopauloschuler/k-neural-api.git k\n","else:\n","  !cd k && git pull\n","\n","!cd k && pip install ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxPcxp99jys9","outputId":"5dd3187c-26bf-46f7-ba10-bfbecf8d5bf6"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import cai.layers\n","import cai.datasets\n","import cai.models\n","import numpy as np\n","from keras import backend\n","from keras import layers\n","import keras.applications\n","import keras.applications.inception_v3\n","from keras.applications.inception_v3 import InceptionV3\n","from keras_applications import imagenet_utils\n","from keras_applications import get_submodules_from_kwargs\n","from keras_applications.imagenet_utils import decode_predictions\n","from keras_applications.imagenet_utils import _obtain_input_shape\n","from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from keras.utils import np_utils\n","from sklearn.utils import class_weight\n","from skimage import color as skimage_color\n","import gc\n","from keras.callbacks import EarlyStopping\n","import multiprocessing\n","import random\n","import glob"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_B901QwcshkE"},"outputs":[],"source":["def load_plantvillage(seed=None, root_dir=None, lab=False, \n","  verbose=True, bipolar=False, base_model_name='plant_leaf'):\n","  if root_dir == None:\n","    print(\"define where the plantvillage folder is.\")\n","    return\n","  random.seed(seed)\n","  def read_from_paths(paths):\n","    x=[]\n","    for path in paths:\n","      img = load_img(path, target_size=(224,224))\n","      img = img_to_array(img)\n","      x.append(img)\n","    return x\n","  \n","  classes = os.listdir(root_dir)\n","  classes = sorted(classes)\n","\n","  train_path = []\n","  val_path = []\n","  test_path = []\n","\n","  train_x,train_y = [],[]\n","  val_x,val_y = [],[]\n","  test_x,test_y =[],[]\n","\n","  #read path and categorize to three groups , 6,2,2\n","  for i,_class in enumerate(classes):\n","      paths = glob.glob(os.path.join(root_dir,_class,\"*\"))\n","      paths = [n for n in paths if n.endswith(\".JPG\") or n.endswith(\".jpg\")]\n","      random.shuffle(paths)\n","      cat_total = len(paths)\n","      train_path.extend(paths[:int(cat_total*0.6)])\n","      train_y.extend([i]*int(cat_total*0.6))\n","      val_path.extend(paths[int(cat_total*0.6):int(cat_total*0.8)])\n","      val_y.extend([i]*len(paths[int(cat_total*0.6):int(cat_total*0.8)]))\n","      test_path.extend(paths[int(cat_total*0.8):])\n","      test_y.extend([i]*len(paths[int(cat_total*0.8):]))\n","  \n","  if (verbose):\n","    print (\"loading train images\")\n","  train_x = np.array(read_from_paths(train_path), dtype='float16')\n","  \n","  if (verbose):\n","    print (\"loading validation images\")\n","  val_x = np.array(read_from_paths(val_path), dtype='float16')\n","\n","  if (verbose):\n","    print (\"loading test images\")\n","  test_x = np.array(read_from_paths(test_path), dtype='float16')\n","\n","  train_y = np.array(train_y)\n","  val_y = np.array(val_y)\n","  test_y = np.array(test_y)\n","\n","  #convert everything to numpy\n","  #train_x = np.array(train_x)/255.\n","  #val_x = np.array(val_x)/255.\n","  #test_x = np.array(test_x)/255.\n","\n","  if (lab):\n","        # LAB datasets are cached\n","        cachefilename = 'cache-lab-'+base_model_name+'-'+str(bipolar)+'-'+str(train_x.shape[1])+'-'+str(train_x.shape[2])+'.npz'\n","        if (verbose):\n","            print(\"Converting RGB to LAB: \"+cachefilename)\n","        if not os.path.isfile(cachefilename):            \n","            train_x /= 255\n","            val_x /= 255\n","            test_x /= 255\n","            if (verbose):\n","                print(\"Converting training.\")\n","            cai.datasets.skimage_rgb2lab_a(train_x,  verbose)\n","            if (verbose):\n","                print(\"Converting validation.\")\n","            cai.datasets.skimage_rgb2lab_a(val_x,  verbose)\n","            if (verbose):\n","                print(\"Converting test.\")\n","            cai.datasets.skimage_rgb2lab_a(test_x,  verbose)\n","            gc.collect()\n","            if (bipolar):\n","                # JP prefers bipolar input [-2,+2]\n","                train_x[:,:,:,0:3] /= [25, 50, 50]\n","                train_x[:,:,:,0] -= 2\n","                val_x[:,:,:,0:3] /= [25, 50, 50]\n","                val_x[:,:,:,0] -= 2\n","                test_x[:,:,:,0:3] /= [25, 50, 50]\n","                test_x[:,:,:,0] -= 2\n","            else:\n","                train_x[:,:,:,0:3] /= [100, 200, 200]\n","                train_x[:,:,:,1:3] += 0.5\n","                val_x[:,:,:,0:3] /= [100, 200, 200]\n","                val_x[:,:,:,1:3] += 0.5\n","                test_x[:,:,:,0:3] /= [100, 200, 200]\n","                test_x[:,:,:,1:3] += 0.5\n","            #if (verbose):\n","              #print(\"Saving: \"+cachefilename)\n","              #np.savez_compressed(cachefilename, a=train_x,  b=val_x, c=test_x)\n","        else:\n","            if (verbose):\n","              print(\"Loading: \"+cachefilename)\n","            loaded = np.load(cachefilename)\n","            train_x = loaded['a']\n","            val_x = loaded['b']\n","            test_x = loaded['c']\n","            gc.collect()\n","  else:\n","        if (verbose):\n","            print(\"Loading RGB.\")\n","        if (bipolar):\n","            train_x /= 64\n","            val_x /= 64\n","            test_x /= 64\n","            train_x -= 2\n","            val_x -= 2\n","            test_x -= 2\n","        else:\n","            train_x /= 255\n","            val_x /= 255\n","            test_x /= 255\n","\n","  if (verbose):\n","        for channel in range(0, train_x.shape[3]):\n","            sub_matrix = train_x[:,:,:,channel]\n","            print('Channel ', channel, ' min:', np.min(sub_matrix), ' max:', np.max(sub_matrix))\n","  #calculate class weight\n","  classweight = class_weight.compute_class_weight('balanced', np.unique(train_y), train_y)\n","\n","  #convert to categorical\n","  train_y = np_utils.to_categorical(train_y, 38)\n","  val_y = np_utils.to_categorical(val_y, 38)\n","  test_y = np_utils.to_categorical(test_y, 38)\n","  print(\"loaded\")\n","\n","  return train_x,val_x,test_x,train_y,val_y,test_y,classweight,classes"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"w09iVsxw1VuB"},"outputs":[{"ename":"NameError","evalue":"name 'cai' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m expected_folder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplant_leaf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m Verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m cai\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mdownload_zip_and_extract(\n\u001b[1;32m      6\u001b[0m     url_zip_file\u001b[38;5;241m=\u001b[39murl_zip_file, local_zip_file\u001b[38;5;241m=\u001b[39mlocal_zip_file, \n\u001b[1;32m      7\u001b[0m     expected_folder_name\u001b[38;5;241m=\u001b[39mexpected_folder_name, Verbose\u001b[38;5;241m=\u001b[39mVerbose)\n","\u001b[0;31mNameError\u001b[0m: name 'cai' is not defined"]}],"source":["url_zip_file=\"https://data.mendeley.com/datasets/tywbtsjrjv/1/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/Plant_leaf_diseases_dataset_without_augmentation.zip?dl=1\"\n","local_zip_file=\"plant_leaf.zip\"\n","expected_folder_name=\"plant_leaf\"\n","Verbose=True\n","cai.datasets.download_zip_and_extract(\n","    url_zip_file=url_zip_file, local_zip_file=local_zip_file, \n","    expected_folder_name=expected_folder_name, Verbose=Verbose)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"WVbr_8wT1L_F","outputId":"cd83ec25-fb40-4414-da6d-21b6d1b3f246"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'ml' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n ml ipykernel --update-deps --force-reinstall'"]}],"source":["!rm -r plant_leaf/Plant_leave_diseases_dataset_without_augmentation/Background_without_leaves -R\n","data_dir = \"plant_leaf/Plant_leave_diseases_dataset_without_augmentation/\"\n","print(os.listdir(data_dir))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"jkUsv2NRrKKy","outputId":"4a78be01-7e70-40f2-dc5c-758caa8efe9b"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'ml' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n ml ipykernel --update-deps --force-reinstall'"]}],"source":["train_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = load_plantvillage(seed=7, root_dir=data_dir, lab=lab)\n","print(train_x.shape,val_x.shape,test_x.shape)\n","print(train_y.shape,val_y.shape,test_y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rD7YV-zjPeTb","outputId":"0bf4cffb-b006-4d7f-8210-e69a9e90c27d"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'ml' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n ml ipykernel --update-deps --force-reinstall'"]}],"source":["for two_paths_second_block in [False, True]:\n","  for l_ratio in [0.1, 0.2, 0.33, 0.5, 0.66, 0.8, 0.9]:\n","    basefilename = 'two-path-inception-v6-'+str(two_paths_second_block)+'-'+str(l_ratio)\n","    print('Running: '+basefilename)\n","    model = cai.models.compiled_two_path_inception_v3(\n","      input_shape=(224,224,3),\n","      classes=38, \n","      two_paths_first_block=True,\n","      two_paths_second_block=two_paths_second_block,\n","      l_ratio=l_ratio,\n","      ab_ratio=(1-l_ratio),\n","      max_mix_idx=5, \n","      model_name='two_path_inception_v3'\n","      )    \n","    monitor='val_accuracy'\n","    best_result_file_name = basefilename+'-best_result.hdf5'\n","    save_best = keras.callbacks.ModelCheckpoint(\n","      filepath=best_result_file_name, \n","      monitor=monitor, \n","      verbose=1, \n","      save_best_only=True, \n","      save_weights_only=False, \n","      mode='max', \n","      period=1)\n","    history = model.fit(train_x, train_y, epochs=epochs, batch_size=32,\n","      validation_data=(val_x,val_y),\n","      callbacks=[save_best],class_weight=classweight,\n","      workers=multiprocessing.cpu_count())\n","    print('Testing Last Model: '+basefilename)\n","    evaluated = model.evaluate(test_x,test_y)\n","    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n","      print(name,metric)\n","    print('Best Model Results: '+basefilename)\n","    model = keras.models.load_model(best_result_file_name, custom_objects={'CopyChannels': cai.layers.CopyChannels})\n","    evaluated = model.evaluate(test_x,test_y)\n","    cai.models.save_model(model, basefilename)\n","    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n","      print(name,metric)\n","    print('Finished: '+basefilename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmgZj-E0yB6K"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'ml' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n ml ipykernel --update-deps --force-reinstall'"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lX_BKeaO8BD"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'ml' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n ml ipykernel --update-deps --force-reinstall'"]}],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"two_path_inception_v6_save_best_max5 - results to paper - don't touch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
