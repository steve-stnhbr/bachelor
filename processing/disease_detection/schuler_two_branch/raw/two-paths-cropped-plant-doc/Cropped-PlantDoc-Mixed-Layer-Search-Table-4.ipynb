{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXWocLnz38N"
      },
      "source": [
        "# This source code searches for the ideal number of mixed layers on Inception V3 with the Cropped-PlantDoc dataset\n",
        "\n",
        "This raw file supports the paper [Color-aware two-branch DCNN for efficient plant disease classification](https://github.com/joaopauloschuler/two-branch-plant-disease).\n",
        "\n",
        "You might need to install this on your system:\n",
        "\n",
        "apt-get install python3-opencv git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQKpflNl7m63"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('k'):\n",
        " !git clone https://github.com/joaopauloschuler/k-neural-api.git k\n",
        "else:\n",
        " !cd k && git pull\n",
        "\n",
        "!cd k && pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FWmCCX96ndE",
        "outputId": "f4d83122-2759-48c3-e318-c42505522261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.4.1\n",
            "Keras version: 2.4.0\n"
          ]
        }
      ],
      "source": [
        "import cai.layers\n",
        "import cai.datasets\n",
        "import cai.models\n",
        "import cai.densenet\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "import gc\n",
        "import multiprocessing\n",
        "import random\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.version.VERSION)\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "import PIL\n",
        "import cv2\n",
        "#print(\"Pillow version:\", PIL.PILLOW_VERSION)\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WqdOtor61VZ"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('up'):\n",
        "  !git clone https://github.com/joaopauloschuler/PlantDoc-Object-Detection-Dataset.git up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2LGtzGBx5IR"
      },
      "outputs": [],
      "source": [
        "up_data_dir = os.getcwd()+\"/up/TRAIN\"\n",
        "up_test_dir = os.getcwd()+\"/up/TEST\"\n",
        "data_dir = \"cropped_train/\"\n",
        "test_dir = \"cropped_test/\"\n",
        "all_dir = \"cropped_all/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf3vmsbT-4JZ"
      },
      "outputs": [],
      "source": [
        "def CropImages(orig_data_dir, dest_data_dir, csv_file, include_original=False, verbose=True, prefix='img_'):\n",
        "  # Load the CSV file.\n",
        "  with open (csv_file, \"r\") as myfile:\n",
        "    csv_lines=myfile.readlines()\n",
        "\n",
        "  # Transform the CSV file into an array  \n",
        "  line_count = 0\n",
        "  a_lines = []\n",
        "  for str_line in csv_lines:\n",
        "    if line_count > 0: \n",
        "      a_line = str_line.replace('\\n', '').split(',')\n",
        "      a_lines.append(a_line)\n",
        "    line_count = line_count + 1\n",
        "  #a_lines = np.array(a_lines, dtype=object)\n",
        "  \n",
        "  # create destination folder\n",
        "  if not os.path.isdir(dest_data_dir):\n",
        "    os.mkdir(dest_data_dir)\n",
        "\n",
        "  # Save cropped images\n",
        "  line_count = 0\n",
        "  failed_count = 0\n",
        "  original_count = 0\n",
        "  last_image_file = ''\n",
        "  for a_line in a_lines:\n",
        "    dest_folder_name = dest_data_dir+'/'+a_line[3]\n",
        "    dest_file_name = dest_folder_name+'/'+prefix+str(line_count)+'.jpg'\n",
        "    orig_file_name = orig_data_dir+'/'+ a_line[0]\n",
        "    print(line_count,':', a_line, dest_file_name)\n",
        "    if last_image_file != orig_file_name:\n",
        "      if os.path.isfile(orig_file_name):\n",
        "        img = cv2.imread(orig_file_name)\n",
        "        #cv2_imshow(img)\n",
        "        last_image_file = orig_file_name\n",
        "        can_load = True\n",
        "        original_count = original_count + 1\n",
        "        if verbose: print(\"Original imgage shape\",img.shape)\n",
        "        if (include_original):\n",
        "          if not os.path.isdir(dest_folder_name):\n",
        "            os.mkdir(dest_folder_name)\n",
        "          cv2.imwrite(dest_folder_name+'/ori_'+prefix+str(original_count)+'.jpg',img)  \n",
        "      else:\n",
        "        if verbose: print('File does not exist:', orig_file_name)\n",
        "        can_load = False\n",
        "        #break\n",
        "    if (can_load):\n",
        "      y1 = int(a_line[4])\n",
        "      x1 = int(a_line[5])\n",
        "      y2 = int(a_line[6])\n",
        "      x2 = int(a_line[7])\n",
        "\n",
        "      x_min = np.min([x1, x2])\n",
        "      x_max = np.max([x1, x2])\n",
        "      y_min = np.min([y1, y2])\n",
        "      y_max = np.max([y1, y2])\n",
        "\n",
        "      crop_img = img[x_min:x_max, y_min:y_max]\n",
        "      if verbose: print(\"Cropped imgage shape\",crop_img.shape,':', x_min, x_max, y_min, y_max,' deltas:',x_max - x_min, y_max - y_min)\n",
        "      if not os.path.isdir(dest_folder_name):\n",
        "        os.mkdir(dest_folder_name)\n",
        "      if ( (crop_img.shape[0]==0) or (crop_img.shape[1]==0)):\n",
        "        failed_count = failed_count + 1\n",
        "        if verbose: print(\"Failed cropping.\");\n",
        "      else:\n",
        "        cv2.imwrite(dest_file_name,crop_img)\n",
        "    else:\n",
        "      failed_count = failed_count + 1\n",
        "    line_count = line_count + 1\n",
        "  print(\"Processed files:\", line_count, \"Failed count: \", failed_count, \"Original count:\", original_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw2aKihS-4_K"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(data_dir):\n",
        "  CropImages(orig_data_dir=up_data_dir, dest_data_dir=data_dir, csv_file='up/train_labels.csv', include_original=False, prefix='train_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgTgkDce-8KQ"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(test_dir):\n",
        "  CropImages(orig_data_dir=up_test_dir, dest_data_dir=test_dir, csv_file='up/test_labels.csv', include_original=False, prefix='test_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG3lzAXJAxS6",
        "outputId": "4eee42e3-d78f-45c4-9515-c18c3ebf29a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['grape leaf black rot', 'Apple Scab Leaf', 'Tomato Septoria leaf spot', 'Peach leaf', 'Tomato leaf late blight', 'Potato leaf late blight', 'Potato leaf early blight', 'Tomato leaf bacterial spot', 'Corn Gray leaf spot', 'Bell_pepper leaf', 'Apple rust leaf', 'Strawberry leaf', 'grape leaf', 'Cherry leaf', 'Corn rust leaf', 'Tomato leaf yellow virus', 'Tomato mold leaf', 'Potato leaf', 'Bell_pepper leaf spot', 'Squash Powdery mildew leaf', 'Apple leaf', 'Corn leaf blight', 'Raspberry leaf', 'Blueberry leaf', 'Tomato leaf', 'Soyabean leaf', 'Tomato two spotted spider mites leaf', 'Tomato Early blight leaf', 'Tomato leaf mosaic virus']\n",
            "['grape leaf black rot', 'Apple Scab Leaf', 'Tomato Septoria leaf spot', 'Peach leaf', 'Tomato leaf late blight', 'Potato leaf late blight', 'Potato leaf early blight', 'Tomato leaf bacterial spot', 'Corn Gray leaf spot', 'Bell_pepper leaf', 'Apple rust leaf', 'Strawberry leaf', 'grape leaf', 'Cherry leaf', 'Corn rust leaf', 'Tomato leaf yellow virus', 'Tomato mold leaf', 'Potato leaf', 'Bell_pepper leaf spot', 'Squash Powdery mildew leaf', 'Apple leaf', 'Corn leaf blight', 'Raspberry leaf', 'Blueberry leaf', 'Tomato leaf', 'Soyabean leaf', 'Tomato two spotted spider mites leaf', 'Tomato Early blight leaf', 'Tomato leaf mosaic virus']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(data_dir))\n",
        "print(os.listdir(test_dir))\n",
        "if not os.path.isdir('cropped_test/Potato leaf'):\n",
        "  !mkdir 'cropped_test/Potato leaf'\n",
        "if not os.path.isdir('cropped_test/Tomato two spotted spider mites leaf'):\n",
        "  !mkdir 'cropped_test/Tomato two spotted spider mites leaf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_8zcdsPzj02"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(all_dir):\n",
        "  !mkdir cropped_all\n",
        "  ! cp -r cropped_test/* cropped_all/\n",
        "  ! cp -r cropped_train/* cropped_all/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN8LdqheVEkj"
      },
      "outputs": [],
      "source": [
        "datagen = cai.util.create_image_generator(vertical_flip=True, rotation_range=90) # width_shift_range=0.5, height_shift_range=0.5\n",
        "\n",
        "def lrscheduler(epoch):\n",
        "  return 0.01 * (0.99**epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRjrBiQ7O6l"
      },
      "source": [
        "# Load the dataset again with LAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6WYfTY_h8zn"
      },
      "outputs": [],
      "source": [
        "num_classes = 28\n",
        "batch_size = 32\n",
        "epochs = 240\n",
        "target_size_x = 224 # default value is 224\n",
        "target_size_y = 224 # default value is 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e8GfhjGZqwV",
        "outputId": "aae847c7-8b97-458f-cda1-9006fff58d81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading  29  classes.\n",
            "loading train images\n",
            "train shape is: (5761, 224, 224, 3)\n",
            "loading validation images\n",
            "validation shape is: (1333, 224, 224, 3)\n",
            "loading test images\n",
            "test shape is: (1789, 224, 224, 3)\n",
            "Converting RGB to LAB: \n",
            "Converting training.\n",
            "1000  images converted to lab.\n",
            "2000  images converted to lab.\n",
            "3000  images converted to lab.\n",
            "4000  images converted to lab.\n",
            "5000  images converted to lab.\n",
            "Converting validation.\n",
            "1000  images converted to lab.\n",
            "Converting test.\n",
            "1000  images converted to lab.\n",
            "Channel  0  min: 0.0  max: 1.0\n",
            "Channel  1  min: 0.11655408  max: 0.9557502\n",
            "Channel  2  min: 1.0877848e-05  max: 0.9704958\n",
            "Loaded.\n",
            "(5761, 224, 224, 3) (1333, 224, 224, 3) (1789, 224, 224, 3)\n",
            "(5761, 29) (1333, 29) (1789, 29)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28], y=[ 0  0  0 ... 28 28 28] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  \"will result in an error\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "train_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = cai.datasets.load_images_from_folders(seed=7,\n",
        "  root_dir=all_dir, lab=True, \n",
        "  verbose=True, bipolar=False, base_model_name='plant_doc',\n",
        "  has_training=True, has_validation=True, has_testing=True,\n",
        "  training_size=0.65, validation_size=0.15, test_size=0.2,\n",
        "  target_size=(target_size_x, target_size_y))\n",
        "\n",
        "print(train_x.shape,val_x.shape,test_x.shape)\n",
        "print(train_y.shape,val_y.shape,test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A7b9F3TVQUG"
      },
      "outputs": [],
      "source": [
        "def work_on_inception_v3(show_model=False, run_fit=False, test_results=False, calc_f1=False):\n",
        "  monitor='val_accuracy'\n",
        "  if (calc_f1): \n",
        "    test_results=True\n",
        "  if (show_model):\n",
        "    input_shape = (target_size_x, target_size_y, 3)\n",
        "  else:\n",
        "    input_shape = (None, None, 3)\n",
        "  deep_two_paths_compression=0.6\n",
        "  for l_ratio in [0.2]:\n",
        "    for max_mix_idx in [0, 1, 3, 5, 7, 9, 10]:\n",
        "      if l_ratio < 0:\n",
        "          two_paths_first_block=False\n",
        "          two_paths_second_block=False\n",
        "          deep_two_paths=False\n",
        "      else:\n",
        "          two_paths_first_block=True\n",
        "          two_paths_second_block=False\n",
        "          deep_two_paths=False\n",
        "      basefilename = 'JP27B17-InceptionV3-CroppedPlantDoc-'+str(l_ratio)\n",
        "      best_result_file_name = basefilename+'-best_result.hdf5'\n",
        "      print('Running: '+basefilename)\n",
        "      model = cai.models.compiled_two_path_inception_v3(\n",
        "        input_shape=input_shape,\n",
        "        classes=29, \n",
        "        two_paths_first_block=two_paths_first_block,\n",
        "        two_paths_second_block=two_paths_second_block,\n",
        "        deep_two_paths=deep_two_paths,\n",
        "        deep_two_paths_compression=deep_two_paths_compression,\n",
        "        l_ratio=l_ratio,\n",
        "        ab_ratio=(1-l_ratio),\n",
        "        max_mix_idx=max_mix_idx, \n",
        "        model_name='two_path_inception_v3_mixed5'\n",
        "        )\n",
        "\n",
        "      if (show_model): model.summary()\n",
        "\n",
        "      save_best = keras.callbacks.ModelCheckpoint(\n",
        "            filepath=best_result_file_name,\n",
        "            monitor=monitor,\n",
        "            verbose=1,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            mode='max',\n",
        "            save_freq='epoch')\n",
        "\n",
        "      if (run_fit):\n",
        "        history = model.fit(\n",
        "          x = datagen.flow(train_x, train_y, batch_size=batch_size),\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(val_x, val_y),\n",
        "          callbacks=[save_best, tf.keras.callbacks.LearningRateScheduler(lrscheduler)], # cai.densenet.cyclical_smooth_lrscheduler\n",
        "          workers=max([multiprocessing.cpu_count(), 4]) # this option \n",
        "          )\n",
        "      if (test_results):\n",
        "        print('Best Model Results: '+basefilename)\n",
        "        model = keras.models.load_model(best_result_file_name, custom_objects={'CopyChannels': cai.layers.CopyChannels})\n",
        "        evaluated = model.evaluate(test_x,test_y)\n",
        "        for metric, name in zip(evaluated,[\"loss\",\"acc\"]):\n",
        "              print(name,metric)\n",
        "      if (calc_f1):\n",
        "        pred_y = model.predict(test_x)\n",
        "        print(\"Predicted Shape:\", pred_y.shape)\n",
        "        pred_classes_y = np.array(list(np.argmax(pred_y, axis=1)))\n",
        "        test_classes_y = np.array(list(np.argmax(test_y, axis=1)))\n",
        "        print(\"Pred classes shape:\",pred_classes_y.shape)\n",
        "        print(\"Test classes shape:\",test_classes_y.shape)\n",
        "        report = classification_report(test_classes_y, pred_classes_y, digits=4)\n",
        "        print(report)\n",
        "      print('Finished: '+basefilename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRSxTd5GeU5p"
      },
      "source": [
        "# Show Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfjO1XESTCrY",
        "outputId": "c8e4aa8f-5a06-44d6-91af-b821bd03996b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels (CopyChannels)    (None, 224, 224, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_1 (CopyChannels)  (None, 224, 224, 2)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 111, 111, 6)  54          copy_channels[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 111, 111, 26) 468         copy_channels_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 111, 111, 6)  18          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 111, 111, 26) 78          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 111, 111, 6)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 111, 111, 26) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 109, 109, 6)  324         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 109, 109, 26) 6084        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 109, 109, 6)  18          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 109, 109, 26) 78          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 109, 109, 6)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 109, 109, 26) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 13) 702         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 109, 109, 51) 11934       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 13) 39          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 109, 109, 51) 153         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 13) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 109, 109, 51) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 13)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 51)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 54, 54, 80)   240         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 54, 54, 80)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 52, 52, 192)  138240      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 52, 52, 192)  576         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 52, 52, 192)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 256)          0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           7453        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 427,947\n",
            "Trainable params: 426,219\n",
            "Non-trainable params: 1,728\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_2 (CopyChannels)  (None, 224, 224, 1)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_3 (CopyChannels)  (None, 224, 224, 2)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 111, 111, 6)  54          copy_channels_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 111, 111, 26) 468         copy_channels_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 111, 111, 6)  18          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 111, 111, 26) 78          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 111, 111, 6)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 111, 111, 26) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 109, 109, 6)  324         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 109, 109, 26) 6084        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 109, 109, 6)  18          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 109, 109, 26) 78          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 109, 109, 6)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 109, 109, 26) 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 109, 109, 13) 702         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 109, 109, 51) 11934       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 109, 109, 13) 39          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 109, 109, 51) 153         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 109, 109, 13) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 109, 109, 51) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 54, 54, 13)   0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 51)   0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d_3[0][0]            \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 54, 54, 80)   240         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 54, 54, 80)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 52, 52, 192)  138240      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 52, 52, 192)  576         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 52, 52, 192)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c (Activation)         (None, 25, 25, 64)   0           mixed1_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_conv (Conv2D)        (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed1_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed1_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed1_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b (Activation)         (None, 25, 25, 48)   0           mixed1_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c (Activation)         (None, 25, 25, 96)   0           mixed1_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg (AveragePooling2D)   (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed1_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed1_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_conv (Conv2D)      (None, 25, 25, 64)   16384       mixed1_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed1_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed1_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a (Activation)         (None, 25, 25, 64)   0           mixed1_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b (Activation)         (None, 25, 25, 64)   0           mixed1_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc (Activation)        (None, 25, 25, 96)   0           mixed1_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11 (Activation)       (None, 25, 25, 64)   0           mixed1_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           mixed1_11a[0][0]                 \n",
            "                                                                 mixed1_55b[0][0]                 \n",
            "                                                                 mixed1_33cc[0][0]                \n",
            "                                                                 mixed1_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 288)          0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           8381        global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 706,843\n",
            "Trainable params: 704,123\n",
            "Non-trainable params: 2,720\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_4 (CopyChannels)  (None, 224, 224, 1)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_5 (CopyChannels)  (None, 224, 224, 2)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 111, 111, 6)  54          copy_channels_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 111, 111, 26) 468         copy_channels_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 111, 111, 6)  18          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 111, 111, 26) 78          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 111, 111, 6)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 111, 111, 26) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 109, 109, 6)  324         activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 109, 109, 26) 6084        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 109, 109, 6)  18          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 109, 109, 26) 78          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 109, 109, 6)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 109, 109, 26) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 109, 109, 13) 702         activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 109, 109, 51) 11934       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 109, 109, 13) 39          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 109, 109, 51) 153         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 109, 109, 13) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 109, 109, 51) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 54, 54, 13)   0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 54, 54, 51)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d_6[0][0]            \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 54, 54, 80)   240         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 54, 54, 80)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 52, 52, 192)  138240      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 52, 52, 192)  576         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 52, 52, 192)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c (Activation)         (None, 25, 25, 64)   0           mixed1_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_conv (Conv2D)        (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed1_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed1_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed1_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b (Activation)         (None, 25, 25, 48)   0           mixed1_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c (Activation)         (None, 25, 25, 96)   0           mixed1_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg (AveragePooling2D)   (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed1_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed1_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_conv (Conv2D)      (None, 25, 25, 64)   16384       mixed1_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed1_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed1_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a (Activation)         (None, 25, 25, 64)   0           mixed1_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b (Activation)         (None, 25, 25, 64)   0           mixed1_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc (Activation)        (None, 25, 25, 96)   0           mixed1_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11 (Activation)       (None, 25, 25, 64)   0           mixed1_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           mixed1_11a[0][0]                 \n",
            "                                                                 mixed1_55b[0][0]                 \n",
            "                                                                 mixed1_33cc[0][0]                \n",
            "                                                                 mixed1_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c (Activation)         (None, 25, 25, 64)   0           mixed2_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_conv (Conv2D)        (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed2_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed2_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed2_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b (Activation)         (None, 25, 25, 48)   0           mixed2_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c (Activation)         (None, 25, 25, 96)   0           mixed2_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg (AveragePooling2D)   (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed2_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed2_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_conv (Conv2D)      (None, 25, 25, 64)   18432       mixed2_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed2_33bb_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed2_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a (Activation)         (None, 25, 25, 64)   0           mixed2_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b (Activation)         (None, 25, 25, 64)   0           mixed2_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb (Activation)        (None, 25, 25, 96)   0           mixed2_33bb_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11 (Activation)       (None, 25, 25, 64)   0           mixed2_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           mixed2_11a[0][0]                 \n",
            "                                                                 mixed2_55b[0][0]                 \n",
            "                                                                 mixed2_33bb[0][0]                \n",
            "                                                                 mixed2_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed3_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b (Activation)         (None, 25, 25, 64)   0           mixed3_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed3_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed3_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b (Activation)         (None, 25, 25, 96)   0           mixed3_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_conv (Conv2D)        (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 12, 12, 96)   82944       mixed3_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_bn (BatchNormalizati (None, 12, 12, 384)  1152        mixed3_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 12, 12, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a (Activation)         (None, 12, 12, 384)  0           mixed3_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_max (MaxPooling2D)       (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           mixed3_33a[0][0]                 \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 mixed3_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 768)          0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           22301       global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,160,331\n",
            "Trainable params: 2,155,339\n",
            "Non-trainable params: 4,992\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_6 (CopyChannels)  (None, 224, 224, 1)  0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_7 (CopyChannels)  (None, 224, 224, 2)  0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 111, 111, 6)  54          copy_channels_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 111, 111, 26) 468         copy_channels_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 111, 111, 6)  18          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 111, 111, 26) 78          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 111, 111, 6)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 111, 111, 26) 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 109, 109, 6)  324         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 109, 109, 26) 6084        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 109, 109, 6)  18          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 109, 109, 26) 78          conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 109, 109, 6)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 109, 109, 26) 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 109, 109, 13) 702         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 109, 109, 51) 11934       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 109, 109, 13) 39          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 109, 109, 51) 153         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 109, 109, 13) 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 109, 109, 51) 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 54, 54, 13)   0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 54, 54, 51)   0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d_9[0][0]            \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 54, 54, 80)   240         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 54, 54, 80)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 52, 52, 192)  138240      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 52, 52, 192)  576         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 52, 52, 192)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 25, 25, 192)  0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c (Activation)         (None, 25, 25, 64)   0           mixed1_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_conv (Conv2D)        (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed1_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed1_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed1_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b (Activation)         (None, 25, 25, 48)   0           mixed1_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c (Activation)         (None, 25, 25, 96)   0           mixed1_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg (AveragePooling2D)   (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed1_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed1_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_conv (Conv2D)      (None, 25, 25, 64)   16384       mixed1_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed1_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed1_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a (Activation)         (None, 25, 25, 64)   0           mixed1_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b (Activation)         (None, 25, 25, 64)   0           mixed1_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc (Activation)        (None, 25, 25, 96)   0           mixed1_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11 (Activation)       (None, 25, 25, 64)   0           mixed1_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           mixed1_11a[0][0]                 \n",
            "                                                                 mixed1_55b[0][0]                 \n",
            "                                                                 mixed1_33cc[0][0]                \n",
            "                                                                 mixed1_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c (Activation)         (None, 25, 25, 64)   0           mixed2_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_conv (Conv2D)        (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed2_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed2_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed2_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b (Activation)         (None, 25, 25, 48)   0           mixed2_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c (Activation)         (None, 25, 25, 96)   0           mixed2_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg (AveragePooling2D)   (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed2_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed2_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_conv (Conv2D)      (None, 25, 25, 64)   18432       mixed2_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed2_33bb_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed2_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a (Activation)         (None, 25, 25, 64)   0           mixed2_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b (Activation)         (None, 25, 25, 64)   0           mixed2_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb (Activation)        (None, 25, 25, 96)   0           mixed2_33bb_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11 (Activation)       (None, 25, 25, 64)   0           mixed2_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           mixed2_11a[0][0]                 \n",
            "                                                                 mixed2_55b[0][0]                 \n",
            "                                                                 mixed2_33bb[0][0]                \n",
            "                                                                 mixed2_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed3_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b (Activation)         (None, 25, 25, 64)   0           mixed3_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed3_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed3_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b (Activation)         (None, 25, 25, 96)   0           mixed3_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_conv (Conv2D)        (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 96)   82944       mixed3_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_bn (BatchNormalizati (None, 12, 12, 384)  1152        mixed3_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 96)   288         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a (Activation)         (None, 12, 12, 384)  0           mixed3_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 96)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_max (MaxPooling2D)       (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           mixed3_33a[0][0]                 \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 mixed3_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c (Activation)         (None, 12, 12, 128)  0           mixed4_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c (Activation)         (None, 12, 12, 128)  0           mixed4_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b (Activation)         (None, 12, 12, 128)  0           mixed4_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c (Activation)         (None, 12, 12, 128)  0           mixed4_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_conv (Conv2D)       (None, 12, 12, 128)  114688      mixed4_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_bn (BatchNormalizat (None, 12, 12, 128)  384         mixed4_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b (Activation)         (None, 12, 12, 128)  0           mixed4_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc (Activation)        (None, 12, 12, 128)  0           mixed4_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_conv (Conv2D)        (None, 12, 12, 192)  172032      mixed4_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_conv (Conv2D)       (None, 12, 12, 192)  172032      mixed4_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed4_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed4_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed4_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a (Activation)         (None, 12, 12, 192)  0           mixed4_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b (Activation)         (None, 12, 12, 192)  0           mixed4_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc (Activation)        (None, 12, 12, 192)  0           mixed4_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11 (Activation)       (None, 12, 12, 192)  0           mixed4_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           mixed4_11a[0][0]                 \n",
            "                                                                 mixed4_71b[0][0]                 \n",
            "                                                                 mixed4_17cc[0][0]                \n",
            "                                                                 mixed4_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c (Activation)         (None, 12, 12, 160)  0           mixed5_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c (Activation)         (None, 12, 12, 160)  0           mixed5_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b (Activation)         (None, 12, 12, 160)  0           mixed5_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c (Activation)         (None, 12, 12, 160)  0           mixed5_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed5_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed5_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b (Activation)         (None, 12, 12, 160)  0           mixed5_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc (Activation)        (None, 12, 12, 160)  0           mixed5_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed5_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed5_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed5_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed5_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed5_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a (Activation)         (None, 12, 12, 192)  0           mixed5_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b (Activation)         (None, 12, 12, 192)  0           mixed5_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc (Activation)        (None, 12, 12, 192)  0           mixed5_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11 (Activation)       (None, 12, 12, 192)  0           mixed5_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           mixed5_11a[0][0]                 \n",
            "                                                                 mixed5_71b[0][0]                 \n",
            "                                                                 mixed5_17cc[0][0]                \n",
            "                                                                 mixed5_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 768)          0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           22301       global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 5,152,011\n",
            "Trainable params: 5,140,491\n",
            "Non-trainable params: 11,520\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_8 (CopyChannels)  (None, 224, 224, 1)  0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_9 (CopyChannels)  (None, 224, 224, 2)  0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 111, 111, 6)  54          copy_channels_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 111, 111, 26) 468         copy_channels_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 111, 111, 6)  18          conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 111, 111, 26) 78          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 111, 111, 6)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 111, 111, 26) 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 109, 109, 6)  324         activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 109, 109, 26) 6084        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 109, 109, 6)  18          conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 109, 109, 26) 78          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 109, 109, 6)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 109, 109, 26) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 109, 109, 13) 702         activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 109, 109, 51) 11934       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 109, 109, 13) 39          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 109, 109, 51) 153         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 109, 109, 13) 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 109, 109, 51) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 54, 54, 13)   0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 54, 54, 51)   0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d_12[0][0]           \n",
            "                                                                 max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 54, 54, 80)   240         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 54, 54, 80)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 52, 52, 192)  138240      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 52, 52, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 52, 52, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 25, 25, 192)  0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c (Activation)         (None, 25, 25, 64)   0           mixed1_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_conv (Conv2D)        (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed1_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed1_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed1_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b (Activation)         (None, 25, 25, 48)   0           mixed1_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c (Activation)         (None, 25, 25, 96)   0           mixed1_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg (AveragePooling2D)   (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed1_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed1_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_conv (Conv2D)      (None, 25, 25, 64)   16384       mixed1_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed1_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed1_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a (Activation)         (None, 25, 25, 64)   0           mixed1_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b (Activation)         (None, 25, 25, 64)   0           mixed1_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc (Activation)        (None, 25, 25, 96)   0           mixed1_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11 (Activation)       (None, 25, 25, 64)   0           mixed1_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           mixed1_11a[0][0]                 \n",
            "                                                                 mixed1_55b[0][0]                 \n",
            "                                                                 mixed1_33cc[0][0]                \n",
            "                                                                 mixed1_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c (Activation)         (None, 25, 25, 64)   0           mixed2_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_conv (Conv2D)        (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed2_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed2_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed2_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b (Activation)         (None, 25, 25, 48)   0           mixed2_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c (Activation)         (None, 25, 25, 96)   0           mixed2_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg (AveragePooling2D)   (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed2_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed2_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_conv (Conv2D)      (None, 25, 25, 64)   18432       mixed2_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed2_33bb_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed2_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a (Activation)         (None, 25, 25, 64)   0           mixed2_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b (Activation)         (None, 25, 25, 64)   0           mixed2_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb (Activation)        (None, 25, 25, 96)   0           mixed2_33bb_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11 (Activation)       (None, 25, 25, 64)   0           mixed2_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           mixed2_11a[0][0]                 \n",
            "                                                                 mixed2_55b[0][0]                 \n",
            "                                                                 mixed2_33bb[0][0]                \n",
            "                                                                 mixed2_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed3_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b (Activation)         (None, 25, 25, 64)   0           mixed3_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed3_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed3_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b (Activation)         (None, 25, 25, 96)   0           mixed3_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_conv (Conv2D)        (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 96)   82944       mixed3_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_bn (BatchNormalizati (None, 12, 12, 384)  1152        mixed3_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 96)   288         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a (Activation)         (None, 12, 12, 384)  0           mixed3_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 96)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_max (MaxPooling2D)       (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           mixed3_33a[0][0]                 \n",
            "                                                                 activation_42[0][0]              \n",
            "                                                                 mixed3_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c (Activation)         (None, 12, 12, 128)  0           mixed4_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c (Activation)         (None, 12, 12, 128)  0           mixed4_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b (Activation)         (None, 12, 12, 128)  0           mixed4_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c (Activation)         (None, 12, 12, 128)  0           mixed4_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_conv (Conv2D)       (None, 12, 12, 128)  114688      mixed4_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_bn (BatchNormalizat (None, 12, 12, 128)  384         mixed4_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b (Activation)         (None, 12, 12, 128)  0           mixed4_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc (Activation)        (None, 12, 12, 128)  0           mixed4_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_conv (Conv2D)        (None, 12, 12, 192)  172032      mixed4_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_conv (Conv2D)       (None, 12, 12, 192)  172032      mixed4_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed4_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed4_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed4_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a (Activation)         (None, 12, 12, 192)  0           mixed4_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b (Activation)         (None, 12, 12, 192)  0           mixed4_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc (Activation)        (None, 12, 12, 192)  0           mixed4_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11 (Activation)       (None, 12, 12, 192)  0           mixed4_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           mixed4_11a[0][0]                 \n",
            "                                                                 mixed4_71b[0][0]                 \n",
            "                                                                 mixed4_17cc[0][0]                \n",
            "                                                                 mixed4_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c (Activation)         (None, 12, 12, 160)  0           mixed5_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c (Activation)         (None, 12, 12, 160)  0           mixed5_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b (Activation)         (None, 12, 12, 160)  0           mixed5_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c (Activation)         (None, 12, 12, 160)  0           mixed5_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed5_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed5_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b (Activation)         (None, 12, 12, 160)  0           mixed5_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc (Activation)        (None, 12, 12, 160)  0           mixed5_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed5_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed5_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed5_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed5_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed5_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a (Activation)         (None, 12, 12, 192)  0           mixed5_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b (Activation)         (None, 12, 12, 192)  0           mixed5_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc (Activation)        (None, 12, 12, 192)  0           mixed5_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11 (Activation)       (None, 12, 12, 192)  0           mixed5_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           mixed5_11a[0][0]                 \n",
            "                                                                 mixed5_71b[0][0]                 \n",
            "                                                                 mixed5_17cc[0][0]                \n",
            "                                                                 mixed5_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c (Activation)         (None, 12, 12, 160)  0           mixed6_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c (Activation)         (None, 12, 12, 160)  0           mixed6_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b (Activation)         (None, 12, 12, 160)  0           mixed6_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c (Activation)         (None, 12, 12, 160)  0           mixed6_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed6_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed6_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b (Activation)         (None, 12, 12, 160)  0           mixed6_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc (Activation)        (None, 12, 12, 160)  0           mixed6_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed6_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed6_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed6_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed6_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed6_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed6_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed6_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a (Activation)         (None, 12, 12, 192)  0           mixed6_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b (Activation)         (None, 12, 12, 192)  0           mixed6_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc (Activation)        (None, 12, 12, 192)  0           mixed6_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11 (Activation)       (None, 12, 12, 192)  0           mixed6_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           mixed6_11a[0][0]                 \n",
            "                                                                 mixed6_71b[0][0]                 \n",
            "                                                                 mixed6_17cc[0][0]                \n",
            "                                                                 mixed6_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c (Activation)         (None, 12, 12, 192)  0           mixed7_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c (Activation)         (None, 12, 12, 192)  0           mixed7_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b (Activation)         (None, 12, 12, 192)  0           mixed7_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c (Activation)         (None, 12, 12, 192)  0           mixed7_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc_conv (Conv2D)       (None, 12, 12, 192)  258048      mixed7_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed7_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b (Activation)         (None, 12, 12, 192)  0           mixed7_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc (Activation)        (None, 12, 12, 192)  0           mixed7_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc_conv (Conv2D)       (None, 12, 12, 192)  258048      mixed7_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed7_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed7_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed7_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a (Activation)         (None, 12, 12, 192)  0           mixed7_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b (Activation)         (None, 12, 12, 192)  0           mixed7_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc (Activation)        (None, 12, 12, 192)  0           mixed7_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11 (Activation)       (None, 12, 12, 192)  0           mixed7_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           mixed7_11a[0][0]                 \n",
            "                                                                 mixed7_71b[0][0]                 \n",
            "                                                                 mixed7_17cc[0][0]                \n",
            "                                                                 mixed7_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 768)          0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           22301       global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 8,988,619\n",
            "Trainable params: 8,969,803\n",
            "Non-trainable params: 18,816\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_10 (CopyChannels) (None, 224, 224, 1)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_11 (CopyChannels) (None, 224, 224, 2)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 111, 111, 6)  54          copy_channels_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 111, 111, 26) 468         copy_channels_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 111, 111, 6)  18          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 111, 111, 26) 78          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 111, 111, 6)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 111, 111, 26) 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 109, 109, 6)  324         activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 109, 109, 26) 6084        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 109, 109, 6)  18          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 109, 109, 26) 78          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 109, 109, 6)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 109, 109, 26) 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 109, 109, 13) 702         activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 109, 109, 51) 11934       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 109, 109, 13) 39          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 109, 109, 51) 153         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 109, 109, 13) 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 109, 109, 51) 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 54, 54, 13)   0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 54, 54, 51)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d_15[0][0]           \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 54, 54, 80)   240         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 54, 54, 80)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 52, 52, 192)  138240      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 52, 52, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 52, 52, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 25, 25, 192)  0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c (Activation)         (None, 25, 25, 64)   0           mixed1_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_conv (Conv2D)        (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed1_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed1_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed1_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b (Activation)         (None, 25, 25, 48)   0           mixed1_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c (Activation)         (None, 25, 25, 96)   0           mixed1_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg (AveragePooling2D)   (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed1_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed1_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_conv (Conv2D)      (None, 25, 25, 64)   16384       mixed1_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed1_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed1_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a (Activation)         (None, 25, 25, 64)   0           mixed1_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b (Activation)         (None, 25, 25, 64)   0           mixed1_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc (Activation)        (None, 25, 25, 96)   0           mixed1_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11 (Activation)       (None, 25, 25, 64)   0           mixed1_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           mixed1_11a[0][0]                 \n",
            "                                                                 mixed1_55b[0][0]                 \n",
            "                                                                 mixed1_33cc[0][0]                \n",
            "                                                                 mixed1_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c (Activation)         (None, 25, 25, 64)   0           mixed2_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_conv (Conv2D)        (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed2_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed2_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed2_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b (Activation)         (None, 25, 25, 48)   0           mixed2_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c (Activation)         (None, 25, 25, 96)   0           mixed2_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg (AveragePooling2D)   (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed2_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed2_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_conv (Conv2D)      (None, 25, 25, 64)   18432       mixed2_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed2_33bb_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed2_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a (Activation)         (None, 25, 25, 64)   0           mixed2_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b (Activation)         (None, 25, 25, 64)   0           mixed2_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb (Activation)        (None, 25, 25, 96)   0           mixed2_33bb_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11 (Activation)       (None, 25, 25, 64)   0           mixed2_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           mixed2_11a[0][0]                 \n",
            "                                                                 mixed2_55b[0][0]                 \n",
            "                                                                 mixed2_33bb[0][0]                \n",
            "                                                                 mixed2_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed3_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b (Activation)         (None, 25, 25, 64)   0           mixed3_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed3_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed3_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b (Activation)         (None, 25, 25, 96)   0           mixed3_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_conv (Conv2D)        (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 96)   82944       mixed3_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_bn (BatchNormalizati (None, 12, 12, 384)  1152        mixed3_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 96)   288         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a (Activation)         (None, 12, 12, 384)  0           mixed3_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 96)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_max (MaxPooling2D)       (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           mixed3_33a[0][0]                 \n",
            "                                                                 activation_51[0][0]              \n",
            "                                                                 mixed3_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c (Activation)         (None, 12, 12, 128)  0           mixed4_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c (Activation)         (None, 12, 12, 128)  0           mixed4_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b (Activation)         (None, 12, 12, 128)  0           mixed4_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c (Activation)         (None, 12, 12, 128)  0           mixed4_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_conv (Conv2D)       (None, 12, 12, 128)  114688      mixed4_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_bn (BatchNormalizat (None, 12, 12, 128)  384         mixed4_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b (Activation)         (None, 12, 12, 128)  0           mixed4_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc (Activation)        (None, 12, 12, 128)  0           mixed4_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_conv (Conv2D)        (None, 12, 12, 192)  172032      mixed4_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_conv (Conv2D)       (None, 12, 12, 192)  172032      mixed4_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed4_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed4_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed4_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a (Activation)         (None, 12, 12, 192)  0           mixed4_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b (Activation)         (None, 12, 12, 192)  0           mixed4_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc (Activation)        (None, 12, 12, 192)  0           mixed4_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11 (Activation)       (None, 12, 12, 192)  0           mixed4_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           mixed4_11a[0][0]                 \n",
            "                                                                 mixed4_71b[0][0]                 \n",
            "                                                                 mixed4_17cc[0][0]                \n",
            "                                                                 mixed4_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c (Activation)         (None, 12, 12, 160)  0           mixed5_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c (Activation)         (None, 12, 12, 160)  0           mixed5_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b (Activation)         (None, 12, 12, 160)  0           mixed5_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c (Activation)         (None, 12, 12, 160)  0           mixed5_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed5_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed5_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b (Activation)         (None, 12, 12, 160)  0           mixed5_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc (Activation)        (None, 12, 12, 160)  0           mixed5_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed5_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed5_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed5_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed5_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed5_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a (Activation)         (None, 12, 12, 192)  0           mixed5_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b (Activation)         (None, 12, 12, 192)  0           mixed5_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc (Activation)        (None, 12, 12, 192)  0           mixed5_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11 (Activation)       (None, 12, 12, 192)  0           mixed5_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           mixed5_11a[0][0]                 \n",
            "                                                                 mixed5_71b[0][0]                 \n",
            "                                                                 mixed5_17cc[0][0]                \n",
            "                                                                 mixed5_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c (Activation)         (None, 12, 12, 160)  0           mixed6_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c (Activation)         (None, 12, 12, 160)  0           mixed6_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b (Activation)         (None, 12, 12, 160)  0           mixed6_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c (Activation)         (None, 12, 12, 160)  0           mixed6_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed6_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed6_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b (Activation)         (None, 12, 12, 160)  0           mixed6_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc (Activation)        (None, 12, 12, 160)  0           mixed6_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed6_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed6_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed6_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed6_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed6_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed6_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed6_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a (Activation)         (None, 12, 12, 192)  0           mixed6_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b (Activation)         (None, 12, 12, 192)  0           mixed6_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc (Activation)        (None, 12, 12, 192)  0           mixed6_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11 (Activation)       (None, 12, 12, 192)  0           mixed6_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           mixed6_11a[0][0]                 \n",
            "                                                                 mixed6_71b[0][0]                 \n",
            "                                                                 mixed6_17cc[0][0]                \n",
            "                                                                 mixed6_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c (Activation)         (None, 12, 12, 192)  0           mixed7_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c (Activation)         (None, 12, 12, 192)  0           mixed7_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b (Activation)         (None, 12, 12, 192)  0           mixed7_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c (Activation)         (None, 12, 12, 192)  0           mixed7_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc_conv (Conv2D)       (None, 12, 12, 192)  258048      mixed7_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed7_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b (Activation)         (None, 12, 12, 192)  0           mixed7_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc (Activation)        (None, 12, 12, 192)  0           mixed7_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc_conv (Conv2D)       (None, 12, 12, 192)  258048      mixed7_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed7_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed7_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed7_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a (Activation)         (None, 12, 12, 192)  0           mixed7_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b (Activation)         (None, 12, 12, 192)  0           mixed7_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc (Activation)        (None, 12, 12, 192)  0           mixed7_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11 (Activation)       (None, 12, 12, 192)  0           mixed7_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           mixed7_11a[0][0]                 \n",
            "                                                                 mixed7_71b[0][0]                 \n",
            "                                                                 mixed7_17cc[0][0]                \n",
            "                                                                 mixed7_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11b_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11b (Activation)         (None, 12, 12, 192)  0           mixed8_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_17b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed8_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_17b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_17b (Activation)         (None, 12, 12, 192)  0           mixed8_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_71b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed8_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11a (Activation)         (None, 12, 12, 192)  0           mixed8_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_71b (Activation)         (None, 12, 12, 192)  0           mixed8_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33a_conv (Conv2D)        (None, 5, 5, 320)    552960      mixed8_11a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33b_conv (Conv2D)        (None, 5, 5, 192)    331776      mixed8_71b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33a_bn (BatchNormalizati (None, 5, 5, 320)    960         mixed8_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33b_bn (BatchNormalizati (None, 5, 5, 192)    576         mixed8_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33a (Activation)         (None, 5, 5, 320)    0           mixed8_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33b (Activation)         (None, 5, 5, 192)    0           mixed8_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_max (MaxPooling2D)       (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           mixed8_33a[0][0]                 \n",
            "                                                                 mixed8_33b[0][0]                 \n",
            "                                                                 mixed8_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11b_conv (Conv2D)        (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11b_bn (BatchNormalizati (None, 5, 5, 448)    1344        mixed9_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11b (Activation)         (None, 5, 5, 448)    0           mixed9_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11a_conv (Conv2D)        (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_33b_conv (Conv2D)        (None, 5, 5, 384)    1548288     mixed9_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11a_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_33b_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11a (Activation)         (None, 5, 5, 384)    0           mixed9_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_33b (Activation)         (None, 5, 5, 384)    0           mixed9_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13a_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_11a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31a_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_11a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13b_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31b_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg (AveragePooling2D)   (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11_conv (Conv2D)         (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13a_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_13a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31a_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_31a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13b_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_13b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31b_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_31b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg11_conv (Conv2D)      (None, 5, 5, 192)    245760      mixed9_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11_bn (BatchNormalizatio (None, 5, 5, 320)    960         mixed9_11_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13a (Activation)         (None, 5, 5, 384)    0           mixed9_13a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31a (Activation)         (None, 5, 5, 384)    0           mixed9_31a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13b (Activation)         (None, 5, 5, 384)    0           mixed9_13b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31b (Activation)         (None, 5, 5, 384)    0           mixed9_31b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg11_bn (BatchNormaliza (None, 5, 5, 192)    576         mixed9_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11 (Activation)          (None, 5, 5, 320)    0           mixed9_11_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_pa (Concatenate)         (None, 5, 5, 768)    0           mixed9_13a[0][0]                 \n",
            "                                                                 mixed9_31a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_pb (Concatenate)         (None, 5, 5, 768)    0           mixed9_13b[0][0]                 \n",
            "                                                                 mixed9_31b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg11 (Activation)       (None, 5, 5, 192)    0           mixed9_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           mixed9_11[0][0]                  \n",
            "                                                                 mixed9_pa[0][0]                  \n",
            "                                                                 mixed9_pb[0][0]                  \n",
            "                                                                 mixed9_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 2048)         0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           59421       global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 15,773,195\n",
            "Trainable params: 15,745,291\n",
            "Non-trainable params: 27,904\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_12 (CopyChannels) (None, 224, 224, 1)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "copy_channels_13 (CopyChannels) (None, 224, 224, 2)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 111, 111, 6)  54          copy_channels_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 111, 111, 26) 468         copy_channels_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 111, 111, 6)  18          conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 111, 111, 26) 78          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 111, 111, 6)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 111, 111, 26) 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 109, 109, 6)  324         activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 109, 109, 26) 6084        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 109, 109, 6)  18          conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 109, 109, 26) 78          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 109, 109, 6)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 109, 109, 26) 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 109, 109, 13) 702         activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 109, 109, 51) 11934       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 109, 109, 13) 39          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 109, 109, 51) 153         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 109, 109, 13) 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 109, 109, 51) 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 54, 54, 13)   0           activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 54, 54, 51)   0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concat_first_block (Concatenate (None, 54, 54, 64)   0           max_pooling2d_18[0][0]           \n",
            "                                                                 max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 54, 54, 80)   5120        concat_first_block[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 54, 54, 80)   240         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 54, 54, 80)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 52, 52, 192)  138240      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 52, 52, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 52, 52, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 25, 25, 192)  0           activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11c (Activation)         (None, 25, 25, 64)   0           mixed0_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_conv (Conv2D)        (None, 25, 25, 48)   9216        max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed0_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed0_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed0_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11b (Activation)         (None, 25, 25, 48)   0           mixed0_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33c (Activation)         (None, 25, 25, 96)   0           mixed0_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg (AveragePooling2D)   (None, 25, 25, 192)  0           max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_conv (Conv2D)        (None, 25, 25, 64)   12288       max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed0_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed0_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_conv (Conv2D)      (None, 25, 25, 32)   6144        mixed0_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed0_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed0_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11_bn (BatchNormaliza (None, 25, 25, 32)   96          mixed0_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_11a (Activation)         (None, 25, 25, 64)   0           mixed0_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_55b (Activation)         (None, 25, 25, 64)   0           mixed0_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_33cc (Activation)        (None, 25, 25, 96)   0           mixed0_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_avg11 (Activation)       (None, 25, 25, 32)   0           mixed0_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           mixed0_11a[0][0]                 \n",
            "                                                                 mixed0_55b[0][0]                 \n",
            "                                                                 mixed0_33cc[0][0]                \n",
            "                                                                 mixed0_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11c (Activation)         (None, 25, 25, 64)   0           mixed1_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_conv (Conv2D)        (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed1_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed1_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed1_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11b (Activation)         (None, 25, 25, 48)   0           mixed1_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33c (Activation)         (None, 25, 25, 96)   0           mixed1_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg (AveragePooling2D)   (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_conv (Conv2D)        (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed1_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed1_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_conv (Conv2D)      (None, 25, 25, 64)   16384       mixed1_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed1_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed1_33cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed1_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_11a (Activation)         (None, 25, 25, 64)   0           mixed1_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_55b (Activation)         (None, 25, 25, 64)   0           mixed1_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_33cc (Activation)        (None, 25, 25, 96)   0           mixed1_33cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_avg11 (Activation)       (None, 25, 25, 64)   0           mixed1_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           mixed1_11a[0][0]                 \n",
            "                                                                 mixed1_55b[0][0]                 \n",
            "                                                                 mixed1_33cc[0][0]                \n",
            "                                                                 mixed1_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11c (Activation)         (None, 25, 25, 64)   0           mixed2_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_conv (Conv2D)        (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed2_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b_bn (BatchNormalizati (None, 25, 25, 48)   144         mixed2_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed2_33c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11b (Activation)         (None, 25, 25, 48)   0           mixed2_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33c (Activation)         (None, 25, 25, 96)   0           mixed2_33c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg (AveragePooling2D)   (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_conv (Conv2D)        (None, 25, 25, 64)   76800       mixed2_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_conv (Conv2D)       (None, 25, 25, 96)   82944       mixed2_33c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_conv (Conv2D)      (None, 25, 25, 64)   18432       mixed2_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed2_55b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb_bn (BatchNormalizat (None, 25, 25, 96)   288         mixed2_33bb_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11_bn (BatchNormaliza (None, 25, 25, 64)   192         mixed2_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_11a (Activation)         (None, 25, 25, 64)   0           mixed2_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_55b (Activation)         (None, 25, 25, 64)   0           mixed2_55b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_33bb (Activation)        (None, 25, 25, 96)   0           mixed2_33bb_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_avg11 (Activation)       (None, 25, 25, 64)   0           mixed2_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           mixed2_11a[0][0]                 \n",
            "                                                                 mixed2_55b[0][0]                 \n",
            "                                                                 mixed2_33bb[0][0]                \n",
            "                                                                 mixed2_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_conv (Conv2D)        (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b_bn (BatchNormalizati (None, 25, 25, 64)   192         mixed3_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_11b (Activation)         (None, 25, 25, 64)   0           mixed3_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_conv (Conv2D)        (None, 25, 25, 96)   55296       mixed3_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b_bn (BatchNormalizati (None, 25, 25, 96)   288         mixed3_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33b (Activation)         (None, 25, 25, 96)   0           mixed3_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_conv (Conv2D)        (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 96)   82944       mixed3_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a_bn (BatchNormalizati (None, 12, 12, 384)  1152        mixed3_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 96)   288         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_33a (Activation)         (None, 12, 12, 384)  0           mixed3_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 96)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_max (MaxPooling2D)       (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           mixed3_33a[0][0]                 \n",
            "                                                                 activation_60[0][0]              \n",
            "                                                                 mixed3_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11c (Activation)         (None, 12, 12, 128)  0           mixed4_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71c (Activation)         (None, 12, 12, 128)  0           mixed4_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_conv (Conv2D)        (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11b (Activation)         (None, 12, 12, 128)  0           mixed4_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17c (Activation)         (None, 12, 12, 128)  0           mixed4_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_conv (Conv2D)        (None, 12, 12, 128)  114688      mixed4_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_conv (Conv2D)       (None, 12, 12, 128)  114688      mixed4_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b_bn (BatchNormalizati (None, 12, 12, 128)  384         mixed4_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc_bn (BatchNormalizat (None, 12, 12, 128)  384         mixed4_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17b (Activation)         (None, 12, 12, 128)  0           mixed4_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71cc (Activation)        (None, 12, 12, 128)  0           mixed4_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_conv (Conv2D)        (None, 12, 12, 192)  172032      mixed4_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_conv (Conv2D)       (None, 12, 12, 192)  172032      mixed4_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed4_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed4_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed4_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed4_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_11a (Activation)         (None, 12, 12, 192)  0           mixed4_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_71b (Activation)         (None, 12, 12, 192)  0           mixed4_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_17cc (Activation)        (None, 12, 12, 192)  0           mixed4_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_avg11 (Activation)       (None, 12, 12, 192)  0           mixed4_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           mixed4_11a[0][0]                 \n",
            "                                                                 mixed4_71b[0][0]                 \n",
            "                                                                 mixed4_17cc[0][0]                \n",
            "                                                                 mixed4_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11c (Activation)         (None, 12, 12, 160)  0           mixed5_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71c (Activation)         (None, 12, 12, 160)  0           mixed5_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11b (Activation)         (None, 12, 12, 160)  0           mixed5_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17c (Activation)         (None, 12, 12, 160)  0           mixed5_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed5_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed5_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed5_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed5_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17b (Activation)         (None, 12, 12, 160)  0           mixed5_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71cc (Activation)        (None, 12, 12, 160)  0           mixed5_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed5_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed5_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed5_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed5_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed5_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed5_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_11a (Activation)         (None, 12, 12, 192)  0           mixed5_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_71b (Activation)         (None, 12, 12, 192)  0           mixed5_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_17cc (Activation)        (None, 12, 12, 192)  0           mixed5_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_avg11 (Activation)       (None, 12, 12, 192)  0           mixed5_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           mixed5_11a[0][0]                 \n",
            "                                                                 mixed5_71b[0][0]                 \n",
            "                                                                 mixed5_17cc[0][0]                \n",
            "                                                                 mixed5_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11c (Activation)         (None, 12, 12, 160)  0           mixed6_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71c (Activation)         (None, 12, 12, 160)  0           mixed6_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b_conv (Conv2D)        (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11b (Activation)         (None, 12, 12, 160)  0           mixed6_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17c (Activation)         (None, 12, 12, 160)  0           mixed6_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b_conv (Conv2D)        (None, 12, 12, 160)  179200      mixed6_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc_conv (Conv2D)       (None, 12, 12, 160)  179200      mixed6_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b_bn (BatchNormalizati (None, 12, 12, 160)  480         mixed6_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc_bn (BatchNormalizat (None, 12, 12, 160)  480         mixed6_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17b (Activation)         (None, 12, 12, 160)  0           mixed6_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71cc (Activation)        (None, 12, 12, 160)  0           mixed6_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b_conv (Conv2D)        (None, 12, 12, 192)  215040      mixed6_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc_conv (Conv2D)       (None, 12, 12, 192)  215040      mixed6_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed6_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed6_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed6_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed6_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed6_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_11a (Activation)         (None, 12, 12, 192)  0           mixed6_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_71b (Activation)         (None, 12, 12, 192)  0           mixed6_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_17cc (Activation)        (None, 12, 12, 192)  0           mixed6_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_avg11 (Activation)       (None, 12, 12, 192)  0           mixed6_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           mixed6_11a[0][0]                 \n",
            "                                                                 mixed6_71b[0][0]                 \n",
            "                                                                 mixed6_17cc[0][0]                \n",
            "                                                                 mixed6_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11c (Activation)         (None, 12, 12, 192)  0           mixed7_11c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_11c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_71c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71c (Activation)         (None, 12, 12, 192)  0           mixed7_71c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_71c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_17c_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11b (Activation)         (None, 12, 12, 192)  0           mixed7_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17c (Activation)         (None, 12, 12, 192)  0           mixed7_17c_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc_conv (Conv2D)       (None, 12, 12, 192)  258048      mixed7_17c[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed7_71cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17b (Activation)         (None, 12, 12, 192)  0           mixed7_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71cc (Activation)        (None, 12, 12, 192)  0           mixed7_71cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg (AveragePooling2D)   (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed7_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc_conv (Conv2D)       (None, 12, 12, 192)  258048      mixed7_71cc[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11_conv (Conv2D)      (None, 12, 12, 192)  147456      mixed7_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed7_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc_bn (BatchNormalizat (None, 12, 12, 192)  576         mixed7_17cc_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11_bn (BatchNormaliza (None, 12, 12, 192)  576         mixed7_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_11a (Activation)         (None, 12, 12, 192)  0           mixed7_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_71b (Activation)         (None, 12, 12, 192)  0           mixed7_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_17cc (Activation)        (None, 12, 12, 192)  0           mixed7_17cc_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_avg11 (Activation)       (None, 12, 12, 192)  0           mixed7_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           mixed7_11a[0][0]                 \n",
            "                                                                 mixed7_71b[0][0]                 \n",
            "                                                                 mixed7_17cc[0][0]                \n",
            "                                                                 mixed7_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11b_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11b (Activation)         (None, 12, 12, 192)  0           mixed8_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_17b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed8_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_17b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_17b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_17b (Activation)         (None, 12, 12, 192)  0           mixed8_17b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11a_conv (Conv2D)        (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_71b_conv (Conv2D)        (None, 12, 12, 192)  258048      mixed8_17b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11a_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_71b_bn (BatchNormalizati (None, 12, 12, 192)  576         mixed8_71b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_11a (Activation)         (None, 12, 12, 192)  0           mixed8_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_71b (Activation)         (None, 12, 12, 192)  0           mixed8_71b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33a_conv (Conv2D)        (None, 5, 5, 320)    552960      mixed8_11a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33b_conv (Conv2D)        (None, 5, 5, 192)    331776      mixed8_71b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33a_bn (BatchNormalizati (None, 5, 5, 320)    960         mixed8_33a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33b_bn (BatchNormalizati (None, 5, 5, 192)    576         mixed8_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33a (Activation)         (None, 5, 5, 320)    0           mixed8_33a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_33b (Activation)         (None, 5, 5, 192)    0           mixed8_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_max (MaxPooling2D)       (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           mixed8_33a[0][0]                 \n",
            "                                                                 mixed8_33b[0][0]                 \n",
            "                                                                 mixed8_max[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11b_conv (Conv2D)        (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11b_bn (BatchNormalizati (None, 5, 5, 448)    1344        mixed9_11b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11b (Activation)         (None, 5, 5, 448)    0           mixed9_11b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11a_conv (Conv2D)        (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_33b_conv (Conv2D)        (None, 5, 5, 384)    1548288     mixed9_11b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11a_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_11a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_33b_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_33b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11a (Activation)         (None, 5, 5, 384)    0           mixed9_11a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_33b (Activation)         (None, 5, 5, 384)    0           mixed9_33b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13a_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_11a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31a_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_11a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13b_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31b_conv (Conv2D)        (None, 5, 5, 384)    442368      mixed9_33b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg (AveragePooling2D)   (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11_conv (Conv2D)         (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13a_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_13a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31a_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_31a_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13b_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_13b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31b_bn (BatchNormalizati (None, 5, 5, 384)    1152        mixed9_31b_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg11_conv (Conv2D)      (None, 5, 5, 192)    245760      mixed9_avg[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11_bn (BatchNormalizatio (None, 5, 5, 320)    960         mixed9_11_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13a (Activation)         (None, 5, 5, 384)    0           mixed9_13a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31a (Activation)         (None, 5, 5, 384)    0           mixed9_31a_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_13b (Activation)         (None, 5, 5, 384)    0           mixed9_13b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_31b (Activation)         (None, 5, 5, 384)    0           mixed9_31b_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg11_bn (BatchNormaliza (None, 5, 5, 192)    576         mixed9_avg11_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_11 (Activation)          (None, 5, 5, 320)    0           mixed9_11_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_pa (Concatenate)         (None, 5, 5, 768)    0           mixed9_13a[0][0]                 \n",
            "                                                                 mixed9_31a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_pb (Concatenate)         (None, 5, 5, 768)    0           mixed9_13b[0][0]                 \n",
            "                                                                 mixed9_31b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_avg11 (Activation)       (None, 5, 5, 192)    0           mixed9_avg11_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           mixed9_11[0][0]                  \n",
            "                                                                 mixed9_pa[0][0]                  \n",
            "                                                                 mixed9_pb[0][0]                  \n",
            "                                                                 mixed9_avg11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11b_conv (Conv2D)       (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11b_bn (BatchNormalizat (None, 5, 5, 448)    1344        mixed10_11b_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11b (Activation)        (None, 5, 5, 448)    0           mixed10_11b_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11a_conv (Conv2D)       (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_33b_conv (Conv2D)       (None, 5, 5, 384)    1548288     mixed10_11b[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11a_bn (BatchNormalizat (None, 5, 5, 384)    1152        mixed10_11a_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_33b_bn (BatchNormalizat (None, 5, 5, 384)    1152        mixed10_33b_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11a (Activation)        (None, 5, 5, 384)    0           mixed10_11a_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_33b (Activation)        (None, 5, 5, 384)    0           mixed10_33b_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_13a_conv (Conv2D)       (None, 5, 5, 384)    442368      mixed10_11a[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_31a_conv (Conv2D)       (None, 5, 5, 384)    442368      mixed10_11a[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_13b_conv (Conv2D)       (None, 5, 5, 384)    442368      mixed10_33b[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_31b_conv (Conv2D)       (None, 5, 5, 384)    442368      mixed10_33b[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_avg (AveragePooling2D)  (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11_conv (Conv2D)        (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_13a_bn (BatchNormalizat (None, 5, 5, 384)    1152        mixed10_13a_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_31a_bn (BatchNormalizat (None, 5, 5, 384)    1152        mixed10_31a_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_13b_bn (BatchNormalizat (None, 5, 5, 384)    1152        mixed10_13b_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_31b_bn (BatchNormalizat (None, 5, 5, 384)    1152        mixed10_31b_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_avg11_conv (Conv2D)     (None, 5, 5, 192)    393216      mixed10_avg[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11_bn (BatchNormalizati (None, 5, 5, 320)    960         mixed10_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_13a (Activation)        (None, 5, 5, 384)    0           mixed10_13a_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_31a (Activation)        (None, 5, 5, 384)    0           mixed10_31a_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_13b (Activation)        (None, 5, 5, 384)    0           mixed10_13b_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_31b (Activation)        (None, 5, 5, 384)    0           mixed10_31b_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_avg11_bn (BatchNormaliz (None, 5, 5, 192)    576         mixed10_avg11_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_11 (Activation)         (None, 5, 5, 320)    0           mixed10_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_pa (Concatenate)        (None, 5, 5, 768)    0           mixed10_13a[0][0]                \n",
            "                                                                 mixed10_31a[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_pb (Concatenate)        (None, 5, 5, 768)    0           mixed10_13b[0][0]                \n",
            "                                                                 mixed10_31b[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_avg11 (Activation)      (None, 5, 5, 192)    0           mixed10_avg11_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           mixed10_11[0][0]                 \n",
            "                                                                 mixed10_pa[0][0]                 \n",
            "                                                                 mixed10_pb[0][0]                 \n",
            "                                                                 mixed10_avg11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_6 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "preprediction (Dense)           (None, 29)           59421       global_average_pooling2d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Activation)         (None, 29)           0           preprediction[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,853,259\n",
            "Trainable params: 21,818,827\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n"
          ]
        }
      ],
      "source": [
        "work_on_inception_v3(show_model=True, run_fit=False, test_results=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7RjCRzmxhce"
      },
      "source": [
        "# Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edbu3-Y6THos",
        "outputId": "b8c4a7e5-8a1f-4adf-ab77-6c64812125b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 24s 108ms/step - loss: 2.9412 - accuracy: 0.1770 - val_loss: 3.4970 - val_accuracy: 0.0720\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.07202, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 2.5021 - accuracy: 0.2659 - val_loss: 2.9790 - val_accuracy: 0.1508\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.07202 to 0.15079, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 2.3392 - accuracy: 0.3064 - val_loss: 3.9254 - val_accuracy: 0.1260\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.15079\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 2.2031 - accuracy: 0.3396 - val_loss: 2.4025 - val_accuracy: 0.2866\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.15079 to 0.28657, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 2.1247 - accuracy: 0.3589 - val_loss: 2.7625 - val_accuracy: 0.2536\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.28657\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 2.0198 - accuracy: 0.3988 - val_loss: 3.4175 - val_accuracy: 0.1403\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.28657\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.9738 - accuracy: 0.3990 - val_loss: 2.7164 - val_accuracy: 0.2401\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.28657\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.8820 - accuracy: 0.4312 - val_loss: 3.0568 - val_accuracy: 0.2168\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.28657\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.8713 - accuracy: 0.4415 - val_loss: 2.3570 - val_accuracy: 0.3308\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.28657 to 0.33083, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.8308 - accuracy: 0.4350 - val_loss: 2.5746 - val_accuracy: 0.2903\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.33083\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.7532 - accuracy: 0.4615 - val_loss: 2.1227 - val_accuracy: 0.3826\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.33083 to 0.38260, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.7310 - accuracy: 0.4639 - val_loss: 2.8248 - val_accuracy: 0.2933\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.38260\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.6988 - accuracy: 0.4797 - val_loss: 2.6027 - val_accuracy: 0.2978\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.38260\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.6193 - accuracy: 0.4984 - val_loss: 3.5355 - val_accuracy: 0.1838\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.38260\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.5961 - accuracy: 0.5091 - val_loss: 3.0443 - val_accuracy: 0.2978\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.38260\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.5672 - accuracy: 0.5173 - val_loss: 2.9517 - val_accuracy: 0.2978\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.38260\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.5601 - accuracy: 0.5251 - val_loss: 1.9703 - val_accuracy: 0.4014\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.38260 to 0.40135, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.4896 - accuracy: 0.5296 - val_loss: 2.1575 - val_accuracy: 0.3623\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.40135\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.4965 - accuracy: 0.5369 - val_loss: 3.1804 - val_accuracy: 0.2738\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.40135\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.4396 - accuracy: 0.5460 - val_loss: 2.4864 - val_accuracy: 0.3428\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.40135\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.4679 - accuracy: 0.5383 - val_loss: 2.0285 - val_accuracy: 0.4171\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.40135 to 0.41710, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 1.4237 - accuracy: 0.5600 - val_loss: 1.9402 - val_accuracy: 0.4149\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.41710\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.3976 - accuracy: 0.5686 - val_loss: 2.1327 - val_accuracy: 0.3991\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.41710\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.3725 - accuracy: 0.5693 - val_loss: 2.0731 - val_accuracy: 0.4096\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.41710\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.3534 - accuracy: 0.5807 - val_loss: 2.5892 - val_accuracy: 0.3436\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.41710\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.3103 - accuracy: 0.5838 - val_loss: 2.3726 - val_accuracy: 0.3751\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.41710\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 1.3109 - accuracy: 0.5917 - val_loss: 1.6671 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.41710 to 0.49512, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 1.2829 - accuracy: 0.5937 - val_loss: 3.0647 - val_accuracy: 0.3248\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.49512\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.2622 - accuracy: 0.6107 - val_loss: 2.8821 - val_accuracy: 0.3458\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.49512\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.2167 - accuracy: 0.6159 - val_loss: 1.7359 - val_accuracy: 0.4861\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.49512\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.2188 - accuracy: 0.6058 - val_loss: 1.9982 - val_accuracy: 0.4471\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.49512\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 1.2108 - accuracy: 0.6236 - val_loss: 2.1236 - val_accuracy: 0.4051\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.49512\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.1869 - accuracy: 0.6335 - val_loss: 2.8277 - val_accuracy: 0.3503\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.49512\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.1705 - accuracy: 0.6316 - val_loss: 3.0840 - val_accuracy: 0.3166\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.49512\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.1558 - accuracy: 0.6406 - val_loss: 1.6080 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.49512 to 0.51613, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.1114 - accuracy: 0.6537 - val_loss: 2.3785 - val_accuracy: 0.3721\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.51613\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.1217 - accuracy: 0.6396 - val_loss: 1.8435 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.51613\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.0877 - accuracy: 0.6535 - val_loss: 2.1186 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.51613\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.0893 - accuracy: 0.6556 - val_loss: 1.9812 - val_accuracy: 0.4606\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.51613\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.0772 - accuracy: 0.6607 - val_loss: 1.6880 - val_accuracy: 0.5086\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.51613\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.0536 - accuracy: 0.6677 - val_loss: 2.0530 - val_accuracy: 0.4456\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.51613\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.0409 - accuracy: 0.6771 - val_loss: 1.7839 - val_accuracy: 0.4794\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.51613\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 1.0337 - accuracy: 0.6805 - val_loss: 1.6758 - val_accuracy: 0.5079\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.51613\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 1.0262 - accuracy: 0.6776 - val_loss: 1.7980 - val_accuracy: 0.4906\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.51613\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.9937 - accuracy: 0.6823 - val_loss: 2.3770 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.51613\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.9740 - accuracy: 0.6957 - val_loss: 2.0450 - val_accuracy: 0.4576\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.51613\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.9578 - accuracy: 0.6973 - val_loss: 2.3465 - val_accuracy: 0.4074\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.51613\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.9546 - accuracy: 0.6978 - val_loss: 1.7157 - val_accuracy: 0.5101\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.51613\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.9455 - accuracy: 0.7072 - val_loss: 1.4642 - val_accuracy: 0.5664\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.51613 to 0.56639, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.9151 - accuracy: 0.7141 - val_loss: 1.5780 - val_accuracy: 0.5379\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.56639\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.9204 - accuracy: 0.7072 - val_loss: 1.6371 - val_accuracy: 0.5341\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.56639\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 17s 93ms/step - loss: 0.9576 - accuracy: 0.6928 - val_loss: 1.8124 - val_accuracy: 0.4989\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.56639\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.9061 - accuracy: 0.7166 - val_loss: 2.1957 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.56639\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.8640 - accuracy: 0.7276 - val_loss: 2.1343 - val_accuracy: 0.4509\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.56639\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.8434 - accuracy: 0.7336 - val_loss: 1.8602 - val_accuracy: 0.4869\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.56639\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.8397 - accuracy: 0.7314 - val_loss: 1.7486 - val_accuracy: 0.5154\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.56639\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.8630 - accuracy: 0.7245 - val_loss: 1.8210 - val_accuracy: 0.5071\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.56639\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.8187 - accuracy: 0.7417 - val_loss: 1.6096 - val_accuracy: 0.5251\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.56639\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.8138 - accuracy: 0.7454 - val_loss: 1.8665 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.56639\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.8104 - accuracy: 0.7427 - val_loss: 2.2964 - val_accuracy: 0.4344\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.56639\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7914 - accuracy: 0.7612 - val_loss: 2.3951 - val_accuracy: 0.4621\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.56639\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7646 - accuracy: 0.7689 - val_loss: 2.8602 - val_accuracy: 0.4044\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.56639\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.8240 - accuracy: 0.7430 - val_loss: 2.1722 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.56639\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.7860 - accuracy: 0.7544 - val_loss: 1.5523 - val_accuracy: 0.5649\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.56639\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.7583 - accuracy: 0.7587 - val_loss: 2.3812 - val_accuracy: 0.4321\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.56639\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7746 - accuracy: 0.7511 - val_loss: 1.5406 - val_accuracy: 0.5784\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.56639 to 0.57839, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7486 - accuracy: 0.7630 - val_loss: 1.4001 - val_accuracy: 0.6017\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.57839 to 0.60165, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7477 - accuracy: 0.7597 - val_loss: 2.0412 - val_accuracy: 0.4771\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.60165\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7391 - accuracy: 0.7685 - val_loss: 1.6762 - val_accuracy: 0.5416\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.60165\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.7128 - accuracy: 0.7763 - val_loss: 1.5075 - val_accuracy: 0.5694\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.60165\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6866 - accuracy: 0.7912 - val_loss: 1.6023 - val_accuracy: 0.5649\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.60165\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6824 - accuracy: 0.7937 - val_loss: 1.8826 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.60165\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6822 - accuracy: 0.7845 - val_loss: 1.5237 - val_accuracy: 0.5761\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.60165\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6688 - accuracy: 0.7904 - val_loss: 1.3156 - val_accuracy: 0.6234\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.60165 to 0.62341, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6890 - accuracy: 0.7813 - val_loss: 1.3800 - val_accuracy: 0.6047\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.62341\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6578 - accuracy: 0.7897 - val_loss: 1.3669 - val_accuracy: 0.6144\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.62341\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.6924 - accuracy: 0.7814 - val_loss: 1.4824 - val_accuracy: 0.5791\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.62341\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.6351 - accuracy: 0.8033 - val_loss: 2.5178 - val_accuracy: 0.4494\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.62341\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6316 - accuracy: 0.8070 - val_loss: 1.6519 - val_accuracy: 0.5566\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.62341\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.6425 - accuracy: 0.7919 - val_loss: 1.6254 - val_accuracy: 0.5589\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.62341\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.6330 - accuracy: 0.8045 - val_loss: 1.5686 - val_accuracy: 0.5754\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.62341\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6179 - accuracy: 0.8007 - val_loss: 1.8449 - val_accuracy: 0.5356\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.62341\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.5895 - accuracy: 0.8175 - val_loss: 1.3454 - val_accuracy: 0.6144\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.62341\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.6283 - accuracy: 0.8057 - val_loss: 2.2831 - val_accuracy: 0.4854\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.62341\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.6106 - accuracy: 0.8113 - val_loss: 1.4127 - val_accuracy: 0.6054\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.62341\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.5782 - accuracy: 0.8168 - val_loss: 1.4265 - val_accuracy: 0.5979\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.62341\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5672 - accuracy: 0.8238 - val_loss: 1.4881 - val_accuracy: 0.5844\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.62341\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.6038 - accuracy: 0.8093 - val_loss: 1.4866 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.62341\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5838 - accuracy: 0.8185 - val_loss: 1.3807 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.62341\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.5602 - accuracy: 0.8189 - val_loss: 1.5344 - val_accuracy: 0.5844\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.62341\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5523 - accuracy: 0.8322 - val_loss: 1.5711 - val_accuracy: 0.5874\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.62341\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.5656 - accuracy: 0.8241 - val_loss: 1.3452 - val_accuracy: 0.6249\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.62341 to 0.62491, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5638 - accuracy: 0.8195 - val_loss: 1.4384 - val_accuracy: 0.5964\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.62491\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5380 - accuracy: 0.8336 - val_loss: 1.7136 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.62491\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5419 - accuracy: 0.8313 - val_loss: 1.3909 - val_accuracy: 0.6212\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.62491\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.5296 - accuracy: 0.8425 - val_loss: 1.7233 - val_accuracy: 0.5544\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.62491\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.5189 - accuracy: 0.8416 - val_loss: 1.4560 - val_accuracy: 0.6069\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.62491\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5044 - accuracy: 0.8373 - val_loss: 1.2248 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.62491 to 0.65416, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5409 - accuracy: 0.8316 - val_loss: 1.4541 - val_accuracy: 0.6039\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.65416\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.4912 - accuracy: 0.8499 - val_loss: 1.6359 - val_accuracy: 0.5836\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.65416\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4943 - accuracy: 0.8471 - val_loss: 1.2524 - val_accuracy: 0.6587\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.65416 to 0.65866, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.5292 - accuracy: 0.8351 - val_loss: 1.4145 - val_accuracy: 0.6302\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.65866\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4897 - accuracy: 0.8509 - val_loss: 1.2630 - val_accuracy: 0.6549\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.65866\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4629 - accuracy: 0.8514 - val_loss: 1.2306 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.65866 to 0.65941, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4877 - accuracy: 0.8442 - val_loss: 1.5823 - val_accuracy: 0.5896\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.65941\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.4816 - accuracy: 0.8517 - val_loss: 1.3692 - val_accuracy: 0.6354\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.65941\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4610 - accuracy: 0.8575 - val_loss: 1.4966 - val_accuracy: 0.6017\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.65941\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4746 - accuracy: 0.8581 - val_loss: 1.6646 - val_accuracy: 0.5709\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.65941\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4607 - accuracy: 0.8573 - val_loss: 1.5493 - val_accuracy: 0.5821\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.65941\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4591 - accuracy: 0.8584 - val_loss: 1.3925 - val_accuracy: 0.5979\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.65941\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4819 - accuracy: 0.8481 - val_loss: 1.9981 - val_accuracy: 0.5251\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.65941\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4465 - accuracy: 0.8644 - val_loss: 1.5210 - val_accuracy: 0.6009\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.65941\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4452 - accuracy: 0.8631 - val_loss: 1.3539 - val_accuracy: 0.6377\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.65941\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4862 - accuracy: 0.8400 - val_loss: 1.3304 - val_accuracy: 0.6212\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.65941\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4315 - accuracy: 0.8740 - val_loss: 1.8888 - val_accuracy: 0.5416\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.65941\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4513 - accuracy: 0.8590 - val_loss: 1.2176 - val_accuracy: 0.6669\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.65941 to 0.66692, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.4156 - accuracy: 0.8705 - val_loss: 1.4192 - val_accuracy: 0.6219\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.66692\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4166 - accuracy: 0.8694 - val_loss: 1.3644 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.66692\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4278 - accuracy: 0.8731 - val_loss: 1.2674 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.66692\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4470 - accuracy: 0.8590 - val_loss: 1.2136 - val_accuracy: 0.6714\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.66692 to 0.67142, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4310 - accuracy: 0.8687 - val_loss: 1.5166 - val_accuracy: 0.5941\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.67142\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4397 - accuracy: 0.8613 - val_loss: 2.0685 - val_accuracy: 0.5199\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.67142\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4039 - accuracy: 0.8849 - val_loss: 1.1737 - val_accuracy: 0.6819\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.67142 to 0.68192, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.4276 - accuracy: 0.8644 - val_loss: 1.2640 - val_accuracy: 0.6482\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.68192\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.4057 - accuracy: 0.8760 - val_loss: 1.4677 - val_accuracy: 0.6347\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.68192\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4064 - accuracy: 0.8714 - val_loss: 1.4529 - val_accuracy: 0.6234\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.68192\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3984 - accuracy: 0.8824 - val_loss: 1.2103 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.68192\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3989 - accuracy: 0.8731 - val_loss: 1.1767 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.68192\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.4194 - accuracy: 0.8632 - val_loss: 1.1170 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.68192 to 0.68492, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3907 - accuracy: 0.8814 - val_loss: 1.3643 - val_accuracy: 0.6354\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.68492\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3767 - accuracy: 0.8811 - val_loss: 1.1459 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.68492\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3786 - accuracy: 0.8883 - val_loss: 1.2064 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.68492\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.3801 - accuracy: 0.8824 - val_loss: 1.3707 - val_accuracy: 0.6332\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.68492\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.3522 - accuracy: 0.8865 - val_loss: 1.4671 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.68492\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.3594 - accuracy: 0.8951 - val_loss: 1.2096 - val_accuracy: 0.6564\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.68492\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.3537 - accuracy: 0.8954 - val_loss: 1.3124 - val_accuracy: 0.6579\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.68492\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3554 - accuracy: 0.8944 - val_loss: 1.2380 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.68492\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3561 - accuracy: 0.8975 - val_loss: 1.3725 - val_accuracy: 0.6414\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.68492\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3532 - accuracy: 0.8945 - val_loss: 1.1059 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00139: val_accuracy improved from 0.68492 to 0.70218, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3754 - accuracy: 0.8917 - val_loss: 1.2646 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.70218\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3458 - accuracy: 0.8925 - val_loss: 1.2909 - val_accuracy: 0.6467\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.70218\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3566 - accuracy: 0.8893 - val_loss: 1.2091 - val_accuracy: 0.6759\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.70218\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3393 - accuracy: 0.8975 - val_loss: 1.2377 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.70218\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.3274 - accuracy: 0.9026 - val_loss: 1.1735 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.70218\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3417 - accuracy: 0.8945 - val_loss: 1.4401 - val_accuracy: 0.6264\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.70218\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3473 - accuracy: 0.8906 - val_loss: 1.2020 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.70218\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3148 - accuracy: 0.9056 - val_loss: 1.2242 - val_accuracy: 0.6767\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.70218\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3477 - accuracy: 0.8963 - val_loss: 1.1146 - val_accuracy: 0.6894\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.70218\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3493 - accuracy: 0.8919 - val_loss: 1.0732 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.70218\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3214 - accuracy: 0.9054 - val_loss: 1.2387 - val_accuracy: 0.6819\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.70218\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3213 - accuracy: 0.9037 - val_loss: 1.1531 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.70218\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.3295 - accuracy: 0.9005 - val_loss: 1.1413 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.70218\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3144 - accuracy: 0.9053 - val_loss: 1.2384 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.70218\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3257 - accuracy: 0.9050 - val_loss: 1.2774 - val_accuracy: 0.6692\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.70218\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3227 - accuracy: 0.9068 - val_loss: 1.2264 - val_accuracy: 0.6759\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.70218\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3112 - accuracy: 0.9089 - val_loss: 1.2005 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.70218\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3320 - accuracy: 0.9011 - val_loss: 1.2837 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.70218\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.3203 - accuracy: 0.9057 - val_loss: 1.1632 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.70218\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3183 - accuracy: 0.9050 - val_loss: 1.7248 - val_accuracy: 0.6122\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.70218\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3118 - accuracy: 0.9053 - val_loss: 1.1333 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.70218\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2998 - accuracy: 0.9091 - val_loss: 1.1217 - val_accuracy: 0.7074\n",
            "\n",
            "Epoch 00161: val_accuracy improved from 0.70218 to 0.70743, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.3264 - accuracy: 0.8968 - val_loss: 1.1110 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.70743\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3165 - accuracy: 0.9038 - val_loss: 1.1457 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.70743\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2904 - accuracy: 0.9098 - val_loss: 1.1533 - val_accuracy: 0.6954\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.70743\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2993 - accuracy: 0.9163 - val_loss: 1.2692 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.70743\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2906 - accuracy: 0.9107 - val_loss: 1.2254 - val_accuracy: 0.6759\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.70743\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2818 - accuracy: 0.9143 - val_loss: 1.1344 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.70743\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.3068 - accuracy: 0.9104 - val_loss: 1.1561 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.70743\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2936 - accuracy: 0.9148 - val_loss: 1.0965 - val_accuracy: 0.7052\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.70743\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2647 - accuracy: 0.9214 - val_loss: 1.0840 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00170: val_accuracy improved from 0.70743 to 0.71493, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2750 - accuracy: 0.9193 - val_loss: 1.2254 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.71493\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2863 - accuracy: 0.9153 - val_loss: 1.0310 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00172: val_accuracy improved from 0.71493 to 0.72693, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2833 - accuracy: 0.9216 - val_loss: 1.2233 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.72693\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2577 - accuracy: 0.9269 - val_loss: 1.2153 - val_accuracy: 0.6804\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.72693\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2723 - accuracy: 0.9199 - val_loss: 1.1333 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.72693\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2702 - accuracy: 0.9161 - val_loss: 1.2110 - val_accuracy: 0.6819\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.72693\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2924 - accuracy: 0.9102 - val_loss: 1.1695 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.72693\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2697 - accuracy: 0.9219 - val_loss: 1.2263 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.72693\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2674 - accuracy: 0.9176 - val_loss: 1.2252 - val_accuracy: 0.6864\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.72693\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2696 - accuracy: 0.9185 - val_loss: 1.0395 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00180: val_accuracy improved from 0.72693 to 0.73368, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2829 - accuracy: 0.9174 - val_loss: 1.1467 - val_accuracy: 0.7052\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.73368\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2597 - accuracy: 0.9182 - val_loss: 1.2516 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.73368\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2691 - accuracy: 0.9241 - val_loss: 1.3546 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.73368\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2722 - accuracy: 0.9218 - val_loss: 1.1381 - val_accuracy: 0.7037\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.73368\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2545 - accuracy: 0.9270 - val_loss: 1.1114 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.73368\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2677 - accuracy: 0.9184 - val_loss: 1.0735 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.73368\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2480 - accuracy: 0.9305 - val_loss: 1.2836 - val_accuracy: 0.6654\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.73368\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2635 - accuracy: 0.9221 - val_loss: 1.0897 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.73368\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2530 - accuracy: 0.9254 - val_loss: 1.1343 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.73368\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2436 - accuracy: 0.9297 - val_loss: 1.1031 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.73368\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 17s 88ms/step - loss: 0.2593 - accuracy: 0.9296 - val_loss: 1.0632 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.73368\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2544 - accuracy: 0.9212 - val_loss: 1.0315 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.73368\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2424 - accuracy: 0.9351 - val_loss: 1.1027 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.73368\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2367 - accuracy: 0.9393 - val_loss: 1.0648 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.73368\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2447 - accuracy: 0.9286 - val_loss: 1.0888 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.73368\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2410 - accuracy: 0.9330 - val_loss: 1.0834 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.73368\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2521 - accuracy: 0.9270 - val_loss: 1.0540 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.73368\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2420 - accuracy: 0.9269 - val_loss: 1.0895 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.73368\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2395 - accuracy: 0.9355 - val_loss: 1.2081 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.73368\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2429 - accuracy: 0.9300 - val_loss: 1.1514 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.73368\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2489 - accuracy: 0.9301 - val_loss: 1.1022 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.73368\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2293 - accuracy: 0.9330 - val_loss: 1.2042 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.73368\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.2447 - accuracy: 0.9348 - val_loss: 1.1987 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.73368\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.2394 - accuracy: 0.9361 - val_loss: 1.1404 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.73368\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2258 - accuracy: 0.9380 - val_loss: 1.1308 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.73368\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 17s 93ms/step - loss: 0.2188 - accuracy: 0.9403 - val_loss: 1.0688 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.73368\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2293 - accuracy: 0.9364 - val_loss: 1.1274 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.73368\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2183 - accuracy: 0.9394 - val_loss: 1.0997 - val_accuracy: 0.7262\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.73368\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2325 - accuracy: 0.9328 - val_loss: 1.0989 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.73368\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2172 - accuracy: 0.9424 - val_loss: 1.0600 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00210: val_accuracy improved from 0.73368 to 0.73668, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2244 - accuracy: 0.9407 - val_loss: 1.2117 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.73668\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2303 - accuracy: 0.9331 - val_loss: 1.0495 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.73668\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 17s 88ms/step - loss: 0.2424 - accuracy: 0.9353 - val_loss: 1.1713 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.73668\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2110 - accuracy: 0.9414 - val_loss: 1.0851 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.73668\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2046 - accuracy: 0.9442 - val_loss: 1.1282 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.73668\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2333 - accuracy: 0.9351 - val_loss: 1.1180 - val_accuracy: 0.7262\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.73668\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2160 - accuracy: 0.9390 - val_loss: 1.0589 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.73668\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.2097 - accuracy: 0.9445 - val_loss: 1.0385 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.73668\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.2178 - accuracy: 0.9420 - val_loss: 1.0690 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.73668\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2340 - accuracy: 0.9317 - val_loss: 1.0252 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00220: val_accuracy improved from 0.73668 to 0.73818, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2015 - accuracy: 0.9440 - val_loss: 1.0932 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.73818\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2218 - accuracy: 0.9392 - val_loss: 1.1225 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.73818\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2121 - accuracy: 0.9364 - val_loss: 1.0585 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.73818\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.1985 - accuracy: 0.9456 - val_loss: 1.0702 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.73818\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2153 - accuracy: 0.9384 - val_loss: 1.3974 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.73818\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2221 - accuracy: 0.9393 - val_loss: 1.0241 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.73818\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2206 - accuracy: 0.9371 - val_loss: 1.0584 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.73818\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2135 - accuracy: 0.9387 - val_loss: 1.0435 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.73818\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2130 - accuracy: 0.9439 - val_loss: 1.0570 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.73818\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2206 - accuracy: 0.9410 - val_loss: 1.1701 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.73818\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2034 - accuracy: 0.9427 - val_loss: 1.1265 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.73818\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.1879 - accuracy: 0.9529 - val_loss: 1.0497 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.73818\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2104 - accuracy: 0.9435 - val_loss: 1.0761 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.73818\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 17s 89ms/step - loss: 0.2067 - accuracy: 0.9460 - val_loss: 1.0933 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.73818\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.2120 - accuracy: 0.9383 - val_loss: 1.0198 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.73818\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.1989 - accuracy: 0.9484 - val_loss: 1.0676 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.73818\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 17s 91ms/step - loss: 0.1992 - accuracy: 0.9425 - val_loss: 1.0707 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.73818\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.2045 - accuracy: 0.9445 - val_loss: 1.0758 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.73818\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 17s 92ms/step - loss: 0.2028 - accuracy: 0.9415 - val_loss: 1.0314 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00239: val_accuracy improved from 0.73818 to 0.74119, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 17s 90ms/step - loss: 0.1903 - accuracy: 0.9446 - val_loss: 1.0393 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.74119\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 2s 30ms/step - loss: 1.0503 - accuracy: 0.7250\n",
            "loss 1.0503169298171997\n",
            "acc 0.7249860167503357\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 22s 112ms/step - loss: 2.9429 - accuracy: 0.1672 - val_loss: 3.3588 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09827, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 2.5793 - accuracy: 0.2478 - val_loss: 3.2198 - val_accuracy: 0.1275\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09827 to 0.12753, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 2.3062 - accuracy: 0.3151 - val_loss: 3.3259 - val_accuracy: 0.1628\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.12753 to 0.16279, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 2.1666 - accuracy: 0.3416 - val_loss: 3.0063 - val_accuracy: 0.2048\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.16279 to 0.20480, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 2.0731 - accuracy: 0.3843 - val_loss: 2.7526 - val_accuracy: 0.2318\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.20480 to 0.23181, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.9742 - accuracy: 0.4029 - val_loss: 2.5349 - val_accuracy: 0.3001\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.23181 to 0.30008, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 1.9162 - accuracy: 0.4183 - val_loss: 2.5539 - val_accuracy: 0.2708\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.30008\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 20s 106ms/step - loss: 1.8404 - accuracy: 0.4413 - val_loss: 2.5542 - val_accuracy: 0.2738\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.30008\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 20s 106ms/step - loss: 1.7707 - accuracy: 0.4573 - val_loss: 2.6617 - val_accuracy: 0.2926\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.30008\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 20s 106ms/step - loss: 1.7280 - accuracy: 0.4710 - val_loss: 2.9963 - val_accuracy: 0.2251\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.30008\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.6850 - accuracy: 0.4826 - val_loss: 2.8710 - val_accuracy: 0.3008\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.30008 to 0.30083, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.6066 - accuracy: 0.4910 - val_loss: 3.6039 - val_accuracy: 0.2123\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.30083\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.5644 - accuracy: 0.5167 - val_loss: 2.6431 - val_accuracy: 0.3331\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.30083 to 0.33308, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.5541 - accuracy: 0.5116 - val_loss: 2.9428 - val_accuracy: 0.2656\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.33308\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.5061 - accuracy: 0.5266 - val_loss: 3.1744 - val_accuracy: 0.2468\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.33308\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.4701 - accuracy: 0.5414 - val_loss: 2.1225 - val_accuracy: 0.3916\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.33308 to 0.39160, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.3976 - accuracy: 0.5630 - val_loss: 2.1623 - val_accuracy: 0.3691\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.39160\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.3568 - accuracy: 0.5810 - val_loss: 2.5758 - val_accuracy: 0.3668\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.39160\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.3338 - accuracy: 0.5815 - val_loss: 3.1960 - val_accuracy: 0.2791\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.39160\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.3229 - accuracy: 0.5791 - val_loss: 1.9584 - val_accuracy: 0.4359\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.39160 to 0.43586, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 1.3265 - accuracy: 0.5835 - val_loss: 2.9680 - val_accuracy: 0.3481\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.43586\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.2271 - accuracy: 0.6264 - val_loss: 2.3679 - val_accuracy: 0.3646\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.43586\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 1.2566 - accuracy: 0.6092 - val_loss: 2.3463 - val_accuracy: 0.3878\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.43586\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 1.1773 - accuracy: 0.6353 - val_loss: 2.1610 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.43586\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.1750 - accuracy: 0.6323 - val_loss: 2.3869 - val_accuracy: 0.3908\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.43586\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.1657 - accuracy: 0.6322 - val_loss: 1.8480 - val_accuracy: 0.4479\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.43586 to 0.44786, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.1255 - accuracy: 0.6487 - val_loss: 3.4697 - val_accuracy: 0.3046\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.44786\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.1161 - accuracy: 0.6553 - val_loss: 2.8787 - val_accuracy: 0.3503\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.44786\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 1.0473 - accuracy: 0.6643 - val_loss: 2.8705 - val_accuracy: 0.3263\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.44786\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.0641 - accuracy: 0.6656 - val_loss: 1.7161 - val_accuracy: 0.5184\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.44786 to 0.51838, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 1.0242 - accuracy: 0.6683 - val_loss: 3.0259 - val_accuracy: 0.3286\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.51838\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.9738 - accuracy: 0.6859 - val_loss: 2.4363 - val_accuracy: 0.4149\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.51838\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.9777 - accuracy: 0.6929 - val_loss: 2.2980 - val_accuracy: 0.3961\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.51838\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.9484 - accuracy: 0.6965 - val_loss: 3.5056 - val_accuracy: 0.3383\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.51838\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.9311 - accuracy: 0.7005 - val_loss: 1.7003 - val_accuracy: 0.5086\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.51838\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.9347 - accuracy: 0.7044 - val_loss: 3.0971 - val_accuracy: 0.3173\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.51838\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.8693 - accuracy: 0.7252 - val_loss: 2.7508 - val_accuracy: 0.3263\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.51838\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.8826 - accuracy: 0.7141 - val_loss: 3.3841 - val_accuracy: 0.3436\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.51838\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.9030 - accuracy: 0.7074 - val_loss: 1.6633 - val_accuracy: 0.5341\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.51838 to 0.53413, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.8800 - accuracy: 0.7200 - val_loss: 2.2205 - val_accuracy: 0.4224\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.53413\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.8588 - accuracy: 0.7233 - val_loss: 1.7920 - val_accuracy: 0.5304\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.53413\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.8145 - accuracy: 0.7489 - val_loss: 1.8579 - val_accuracy: 0.4854\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.53413\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.7996 - accuracy: 0.7442 - val_loss: 1.5543 - val_accuracy: 0.5566\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.53413 to 0.55664, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.7645 - accuracy: 0.7558 - val_loss: 1.7008 - val_accuracy: 0.5274\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.55664\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.7633 - accuracy: 0.7607 - val_loss: 1.7651 - val_accuracy: 0.5011\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.55664\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.7534 - accuracy: 0.7566 - val_loss: 1.9978 - val_accuracy: 0.4846\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.55664\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.7263 - accuracy: 0.7701 - val_loss: 1.8537 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.55664\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.7484 - accuracy: 0.7594 - val_loss: 1.9687 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.55664\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.6862 - accuracy: 0.7862 - val_loss: 2.0946 - val_accuracy: 0.4644\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.55664\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6893 - accuracy: 0.7798 - val_loss: 1.3567 - val_accuracy: 0.6137\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.55664 to 0.61365, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6668 - accuracy: 0.7813 - val_loss: 2.7662 - val_accuracy: 0.4261\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.61365\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6544 - accuracy: 0.7954 - val_loss: 1.8997 - val_accuracy: 0.4869\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.61365\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.6388 - accuracy: 0.7986 - val_loss: 1.8146 - val_accuracy: 0.5214\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.61365\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6405 - accuracy: 0.7836 - val_loss: 1.7897 - val_accuracy: 0.5086\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.61365\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.6056 - accuracy: 0.8087 - val_loss: 2.7492 - val_accuracy: 0.4374\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.61365\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6110 - accuracy: 0.8134 - val_loss: 1.4920 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.61365\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6004 - accuracy: 0.8086 - val_loss: 2.0273 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.61365\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.6065 - accuracy: 0.8002 - val_loss: 1.7774 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.61365\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.5876 - accuracy: 0.8152 - val_loss: 2.8937 - val_accuracy: 0.4036\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.61365\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.5249 - accuracy: 0.8407 - val_loss: 1.6451 - val_accuracy: 0.5731\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.61365\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.5542 - accuracy: 0.8221 - val_loss: 1.5611 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.61365\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.5902 - accuracy: 0.8164 - val_loss: 2.4478 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.61365\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.5294 - accuracy: 0.8303 - val_loss: 1.9019 - val_accuracy: 0.5289\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.61365\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.5480 - accuracy: 0.8254 - val_loss: 1.4087 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.61365\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.5220 - accuracy: 0.8343 - val_loss: 1.3214 - val_accuracy: 0.6467\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.61365 to 0.64666, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.5198 - accuracy: 0.8394 - val_loss: 1.6124 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.64666\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.4650 - accuracy: 0.8574 - val_loss: 1.9084 - val_accuracy: 0.5386\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.64666\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.5176 - accuracy: 0.8338 - val_loss: 1.3707 - val_accuracy: 0.6272\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.64666\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.4400 - accuracy: 0.8671 - val_loss: 1.4314 - val_accuracy: 0.6309\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.64666\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.4482 - accuracy: 0.8586 - val_loss: 1.4116 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.64666\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.4719 - accuracy: 0.8518 - val_loss: 1.8001 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.64666\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.4458 - accuracy: 0.8545 - val_loss: 1.4373 - val_accuracy: 0.6392\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.64666\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.4430 - accuracy: 0.8546 - val_loss: 1.2321 - val_accuracy: 0.6534\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.64666 to 0.65341, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.4191 - accuracy: 0.8693 - val_loss: 1.3569 - val_accuracy: 0.6407\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.65341\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.4227 - accuracy: 0.8637 - val_loss: 2.5994 - val_accuracy: 0.4734\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.65341\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.4356 - accuracy: 0.8639 - val_loss: 1.4746 - val_accuracy: 0.6212\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.65341\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.4033 - accuracy: 0.8694 - val_loss: 1.5258 - val_accuracy: 0.5971\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.65341\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.3893 - accuracy: 0.8794 - val_loss: 1.2969 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.65341 to 0.67217, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.4035 - accuracy: 0.8702 - val_loss: 1.4318 - val_accuracy: 0.6302\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.67217\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.4198 - accuracy: 0.8652 - val_loss: 1.3684 - val_accuracy: 0.6272\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.67217\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.3633 - accuracy: 0.8833 - val_loss: 1.3963 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.67217\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3657 - accuracy: 0.8878 - val_loss: 1.5709 - val_accuracy: 0.6062\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.67217\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3880 - accuracy: 0.8767 - val_loss: 1.3778 - val_accuracy: 0.6519\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.67217\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.3578 - accuracy: 0.8913 - val_loss: 2.1084 - val_accuracy: 0.5056\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.67217\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3767 - accuracy: 0.8818 - val_loss: 1.3239 - val_accuracy: 0.6557\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.67217\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.3557 - accuracy: 0.8881 - val_loss: 1.2869 - val_accuracy: 0.6662\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.67217\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.3504 - accuracy: 0.8916 - val_loss: 1.2802 - val_accuracy: 0.6759\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.67217 to 0.67592, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3263 - accuracy: 0.9042 - val_loss: 2.5981 - val_accuracy: 0.4666\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.67592\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3592 - accuracy: 0.8835 - val_loss: 1.9252 - val_accuracy: 0.5536\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.67592\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3074 - accuracy: 0.9108 - val_loss: 1.6211 - val_accuracy: 0.6152\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.67592\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.3479 - accuracy: 0.8928 - val_loss: 1.6499 - val_accuracy: 0.5904\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.67592\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.3167 - accuracy: 0.9003 - val_loss: 1.5391 - val_accuracy: 0.6107\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.67592\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3114 - accuracy: 0.9069 - val_loss: 1.5899 - val_accuracy: 0.6257\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.67592\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2988 - accuracy: 0.9069 - val_loss: 1.6866 - val_accuracy: 0.5836\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.67592\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2982 - accuracy: 0.9018 - val_loss: 1.7869 - val_accuracy: 0.6159\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.67592\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2934 - accuracy: 0.9097 - val_loss: 1.3533 - val_accuracy: 0.6737\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.67592\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.3238 - accuracy: 0.9016 - val_loss: 1.3754 - val_accuracy: 0.6587\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.67592\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2988 - accuracy: 0.9115 - val_loss: 1.6645 - val_accuracy: 0.6069\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.67592\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2938 - accuracy: 0.9067 - val_loss: 1.4021 - val_accuracy: 0.6572\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.67592\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2668 - accuracy: 0.9177 - val_loss: 1.9157 - val_accuracy: 0.5799\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.67592\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2693 - accuracy: 0.9195 - val_loss: 1.4055 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.67592\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2699 - accuracy: 0.9165 - val_loss: 1.2957 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.67592 to 0.67742, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2650 - accuracy: 0.9191 - val_loss: 1.2811 - val_accuracy: 0.6827\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.67742 to 0.68267, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2647 - accuracy: 0.9236 - val_loss: 1.6096 - val_accuracy: 0.6264\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.68267\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2693 - accuracy: 0.9149 - val_loss: 1.5053 - val_accuracy: 0.6377\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.68267\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.2661 - accuracy: 0.9158 - val_loss: 1.5399 - val_accuracy: 0.6242\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.68267\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.2568 - accuracy: 0.9271 - val_loss: 1.2809 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.68267 to 0.68867, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2470 - accuracy: 0.9260 - val_loss: 1.3988 - val_accuracy: 0.6392\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.68867\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2533 - accuracy: 0.9209 - val_loss: 1.2757 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.68867\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2414 - accuracy: 0.9257 - val_loss: 1.1558 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.68867 to 0.69392, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.2433 - accuracy: 0.9231 - val_loss: 1.2467 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.69392 to 0.69917, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.2286 - accuracy: 0.9324 - val_loss: 1.5804 - val_accuracy: 0.6122\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.69917\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2427 - accuracy: 0.9291 - val_loss: 1.2244 - val_accuracy: 0.6969\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.69917\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2336 - accuracy: 0.9371 - val_loss: 1.3613 - val_accuracy: 0.6714\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.69917\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2135 - accuracy: 0.9418 - val_loss: 1.1780 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.69917\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.2212 - accuracy: 0.9377 - val_loss: 1.3796 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.69917\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.2270 - accuracy: 0.9342 - val_loss: 2.0641 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.69917\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2042 - accuracy: 0.9403 - val_loss: 1.2837 - val_accuracy: 0.6842\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.69917\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2091 - accuracy: 0.9433 - val_loss: 1.2309 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.69917 to 0.70218, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2131 - accuracy: 0.9368 - val_loss: 2.0187 - val_accuracy: 0.5769\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.70218\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.2116 - accuracy: 0.9368 - val_loss: 1.3479 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.70218\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1995 - accuracy: 0.9475 - val_loss: 1.6580 - val_accuracy: 0.6309\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.70218\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.2054 - accuracy: 0.9386 - val_loss: 1.1153 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.70218 to 0.71493, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1973 - accuracy: 0.9473 - val_loss: 1.3017 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.71493\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.1840 - accuracy: 0.9539 - val_loss: 1.2609 - val_accuracy: 0.6789\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.71493\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1923 - accuracy: 0.9449 - val_loss: 1.1671 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.71493\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1864 - accuracy: 0.9463 - val_loss: 1.4723 - val_accuracy: 0.6512\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.71493\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1951 - accuracy: 0.9444 - val_loss: 1.3592 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.71493\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1922 - accuracy: 0.9417 - val_loss: 1.1515 - val_accuracy: 0.7112\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.71493\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1976 - accuracy: 0.9428 - val_loss: 1.2935 - val_accuracy: 0.6879\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.71493\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1831 - accuracy: 0.9460 - val_loss: 1.9074 - val_accuracy: 0.5896\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.71493\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1848 - accuracy: 0.9463 - val_loss: 1.5693 - val_accuracy: 0.6204\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.71493\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1818 - accuracy: 0.9469 - val_loss: 1.2969 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.71493\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1796 - accuracy: 0.9438 - val_loss: 1.1915 - val_accuracy: 0.7187\n",
            "\n",
            "Epoch 00134: val_accuracy improved from 0.71493 to 0.71868, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1921 - accuracy: 0.9427 - val_loss: 1.3944 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.71868\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1859 - accuracy: 0.9458 - val_loss: 1.2216 - val_accuracy: 0.7059\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.71868\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1692 - accuracy: 0.9521 - val_loss: 1.2220 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.71868\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1568 - accuracy: 0.9582 - val_loss: 1.1894 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.71868\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1688 - accuracy: 0.9558 - val_loss: 1.1760 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00139: val_accuracy improved from 0.71868 to 0.72843, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.1571 - accuracy: 0.9568 - val_loss: 1.2625 - val_accuracy: 0.6969\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.72843\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.1560 - accuracy: 0.9574 - val_loss: 1.2725 - val_accuracy: 0.6894\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.72843\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1809 - accuracy: 0.9497 - val_loss: 1.2554 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.72843\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1790 - accuracy: 0.9500 - val_loss: 1.1494 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.72843\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1482 - accuracy: 0.9572 - val_loss: 1.1737 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.72843 to 0.73143, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1545 - accuracy: 0.9581 - val_loss: 1.1642 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.73143\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1406 - accuracy: 0.9632 - val_loss: 1.2492 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.73143\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1554 - accuracy: 0.9550 - val_loss: 1.2507 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.73143\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1430 - accuracy: 0.9618 - val_loss: 1.1475 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.73143\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1447 - accuracy: 0.9605 - val_loss: 1.1099 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00149: val_accuracy improved from 0.73143 to 0.73218, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1535 - accuracy: 0.9550 - val_loss: 1.2385 - val_accuracy: 0.7187\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.73218\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1447 - accuracy: 0.9604 - val_loss: 1.1116 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.73218 to 0.73818, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1396 - accuracy: 0.9642 - val_loss: 1.1701 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00152: val_accuracy improved from 0.73818 to 0.74119, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1554 - accuracy: 0.9576 - val_loss: 1.2446 - val_accuracy: 0.7082\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.74119\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1511 - accuracy: 0.9533 - val_loss: 1.2545 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.74119\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1419 - accuracy: 0.9605 - val_loss: 1.1415 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.74119\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1418 - accuracy: 0.9613 - val_loss: 1.1517 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.74119\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1388 - accuracy: 0.9627 - val_loss: 1.1822 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.74119\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1356 - accuracy: 0.9621 - val_loss: 1.1053 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.74119\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1359 - accuracy: 0.9663 - val_loss: 1.0863 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.74119\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1320 - accuracy: 0.9642 - val_loss: 1.1199 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.74119\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1225 - accuracy: 0.9662 - val_loss: 1.0801 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00161: val_accuracy improved from 0.74119 to 0.74269, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1293 - accuracy: 0.9676 - val_loss: 1.0917 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.74269\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1321 - accuracy: 0.9629 - val_loss: 1.1656 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.74269\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1299 - accuracy: 0.9689 - val_loss: 1.1468 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.74269\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1065 - accuracy: 0.9738 - val_loss: 1.1410 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.74269\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1203 - accuracy: 0.9647 - val_loss: 1.1842 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.74269\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1301 - accuracy: 0.9628 - val_loss: 1.1497 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.74269\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1293 - accuracy: 0.9644 - val_loss: 1.1616 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.74269\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1227 - accuracy: 0.9699 - val_loss: 1.1362 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.74269\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.1282 - accuracy: 0.9670 - val_loss: 1.1703 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.74269\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.1227 - accuracy: 0.9690 - val_loss: 1.1965 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.74269\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.1407 - accuracy: 0.9600 - val_loss: 1.1004 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.74269\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1067 - accuracy: 0.9722 - val_loss: 1.1328 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.74269\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.1213 - accuracy: 0.9658 - val_loss: 1.1842 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.74269\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1238 - accuracy: 0.9653 - val_loss: 1.1737 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.74269\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1238 - accuracy: 0.9671 - val_loss: 1.1142 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.74269\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1130 - accuracy: 0.9730 - val_loss: 1.1708 - val_accuracy: 0.7374\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.74269\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1130 - accuracy: 0.9684 - val_loss: 1.0781 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.74269 to 0.74419, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1075 - accuracy: 0.9710 - val_loss: 1.1590 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.74419\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1168 - accuracy: 0.9687 - val_loss: 1.0940 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.74419\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1038 - accuracy: 0.9745 - val_loss: 1.1041 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.74419\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1104 - accuracy: 0.9713 - val_loss: 1.2004 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.74419\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1084 - accuracy: 0.9711 - val_loss: 1.1285 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.74419\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1204 - accuracy: 0.9659 - val_loss: 1.0811 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00184: val_accuracy improved from 0.74419 to 0.75469, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1095 - accuracy: 0.9707 - val_loss: 1.0843 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.75469\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1042 - accuracy: 0.9729 - val_loss: 1.1013 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.75469\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.1203 - accuracy: 0.9675 - val_loss: 1.1298 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.75469\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 19s 105ms/step - loss: 0.1011 - accuracy: 0.9702 - val_loss: 1.1043 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.75469\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1070 - accuracy: 0.9717 - val_loss: 1.1089 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.75469\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.1074 - accuracy: 0.9721 - val_loss: 1.1198 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.75469\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0943 - accuracy: 0.9780 - val_loss: 1.1288 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.75469\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1051 - accuracy: 0.9750 - val_loss: 1.0764 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.75469\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1025 - accuracy: 0.9761 - val_loss: 1.0939 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.75469\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1033 - accuracy: 0.9743 - val_loss: 1.1177 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.75469\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0979 - accuracy: 0.9739 - val_loss: 1.1698 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.75469\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0908 - accuracy: 0.9751 - val_loss: 1.0746 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00196: val_accuracy improved from 0.75469 to 0.76069, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.0932 - accuracy: 0.9766 - val_loss: 1.1539 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.76069\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.1089 - accuracy: 0.9704 - val_loss: 1.1157 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.76069\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0968 - accuracy: 0.9773 - val_loss: 1.1006 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.76069\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1117 - accuracy: 0.9703 - val_loss: 1.0924 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.76069\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0963 - accuracy: 0.9761 - val_loss: 1.0557 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.76069\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0994 - accuracy: 0.9756 - val_loss: 1.1206 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.76069\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1022 - accuracy: 0.9729 - val_loss: 1.1354 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.76069\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.1052 - accuracy: 0.9711 - val_loss: 1.1064 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.76069\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 19s 101ms/step - loss: 0.0933 - accuracy: 0.9764 - val_loss: 1.0377 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00205: val_accuracy improved from 0.76069 to 0.76294, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0882 - accuracy: 0.9800 - val_loss: 1.1033 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.76294\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0909 - accuracy: 0.9773 - val_loss: 1.1261 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.76294\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0959 - accuracy: 0.9771 - val_loss: 1.0928 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.76294\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0885 - accuracy: 0.9770 - val_loss: 1.1229 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.76294\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0923 - accuracy: 0.9744 - val_loss: 1.0785 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.76294\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0809 - accuracy: 0.9821 - val_loss: 1.0788 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.76294\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0855 - accuracy: 0.9818 - val_loss: 1.0721 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.76294\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0897 - accuracy: 0.9774 - val_loss: 1.0895 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.76294\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0736 - accuracy: 0.9844 - val_loss: 1.1599 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.76294\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0896 - accuracy: 0.9787 - val_loss: 1.0897 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.76294\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.0880 - accuracy: 0.9789 - val_loss: 1.0803 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00216: val_accuracy improved from 0.76294 to 0.76519, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.0906 - accuracy: 0.9773 - val_loss: 1.0966 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00217: val_accuracy improved from 0.76519 to 0.76594, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.0822 - accuracy: 0.9799 - val_loss: 1.0829 - val_accuracy: 0.7569\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.76594\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 20s 105ms/step - loss: 0.0867 - accuracy: 0.9779 - val_loss: 1.0420 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.76594\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.0899 - accuracy: 0.9778 - val_loss: 1.0399 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.76594\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0863 - accuracy: 0.9783 - val_loss: 1.0554 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.76594\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0818 - accuracy: 0.9805 - val_loss: 1.0552 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.76594\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0813 - accuracy: 0.9803 - val_loss: 1.0705 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.76594\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0795 - accuracy: 0.9809 - val_loss: 1.0652 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.76594\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0840 - accuracy: 0.9781 - val_loss: 1.0798 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.76594\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0809 - accuracy: 0.9789 - val_loss: 1.0820 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.76594\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0754 - accuracy: 0.9822 - val_loss: 1.1504 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.76594\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0780 - accuracy: 0.9812 - val_loss: 1.0793 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.76594\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0883 - accuracy: 0.9753 - val_loss: 1.0764 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00229: val_accuracy improved from 0.76594 to 0.76669, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0803 - accuracy: 0.9771 - val_loss: 1.0592 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.76669\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0781 - accuracy: 0.9822 - val_loss: 1.0559 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00231: val_accuracy improved from 0.76669 to 0.77194, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.0871 - accuracy: 0.9779 - val_loss: 1.0177 - val_accuracy: 0.7727\n",
            "\n",
            "Epoch 00232: val_accuracy improved from 0.77194 to 0.77269, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0678 - accuracy: 0.9854 - val_loss: 1.0623 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.77269\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.0722 - accuracy: 0.9823 - val_loss: 1.0406 - val_accuracy: 0.7682\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.77269\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0739 - accuracy: 0.9837 - val_loss: 1.0721 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.77269\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 19s 103ms/step - loss: 0.0842 - accuracy: 0.9793 - val_loss: 1.0372 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.77269\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 19s 104ms/step - loss: 0.0838 - accuracy: 0.9839 - val_loss: 1.0320 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.77269\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0794 - accuracy: 0.9816 - val_loss: 1.0885 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.77269\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0809 - accuracy: 0.9791 - val_loss: 1.0332 - val_accuracy: 0.7682\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.77269\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 19s 102ms/step - loss: 0.0844 - accuracy: 0.9790 - val_loss: 1.0455 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.77269\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 2s 26ms/step - loss: 1.0398 - accuracy: 0.7697\n",
            "loss 1.0397576093673706\n",
            "acc 0.76970374584198\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 27s 138ms/step - loss: 3.1364 - accuracy: 0.1539 - val_loss: 3.6689 - val_accuracy: 0.0825\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.08252, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 2.6274 - accuracy: 0.2447 - val_loss: 3.6335 - val_accuracy: 0.1373\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.08252 to 0.13728, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 2.4178 - accuracy: 0.2900 - val_loss: 3.1458 - val_accuracy: 0.1860\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.13728 to 0.18605, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 2.2973 - accuracy: 0.3200 - val_loss: 2.6736 - val_accuracy: 0.2483\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.18605 to 0.24831, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 2.1486 - accuracy: 0.3462 - val_loss: 3.1702 - val_accuracy: 0.2071\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.24831\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 2.0853 - accuracy: 0.3747 - val_loss: 2.3653 - val_accuracy: 0.3173\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.24831 to 0.31733, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 1.9681 - accuracy: 0.4094 - val_loss: 2.3829 - val_accuracy: 0.3481\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.31733 to 0.34809, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 24s 133ms/step - loss: 1.9122 - accuracy: 0.4188 - val_loss: 2.6544 - val_accuracy: 0.2491\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.34809\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.8129 - accuracy: 0.4452 - val_loss: 2.2223 - val_accuracy: 0.3586\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.34809 to 0.35859, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.7601 - accuracy: 0.4582 - val_loss: 2.8086 - val_accuracy: 0.2521\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.35859\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.7413 - accuracy: 0.4660 - val_loss: 2.1141 - val_accuracy: 0.3833\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.35859 to 0.38335, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 1.6609 - accuracy: 0.4781 - val_loss: 2.3436 - val_accuracy: 0.3811\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.38335\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.6721 - accuracy: 0.4727 - val_loss: 2.3986 - val_accuracy: 0.3631\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.38335\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.5691 - accuracy: 0.5132 - val_loss: 2.1750 - val_accuracy: 0.3713\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.38335\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.5154 - accuracy: 0.5341 - val_loss: 2.2423 - val_accuracy: 0.3578\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.38335\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.4742 - accuracy: 0.5405 - val_loss: 2.3635 - val_accuracy: 0.3886\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.38335 to 0.38860, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.4434 - accuracy: 0.5489 - val_loss: 2.2571 - val_accuracy: 0.3751\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.38860\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 1.3774 - accuracy: 0.5659 - val_loss: 4.2261 - val_accuracy: 0.2116\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.38860\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 1.3348 - accuracy: 0.5871 - val_loss: 2.4273 - val_accuracy: 0.3526\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.38860\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 1.3069 - accuracy: 0.5961 - val_loss: 2.0147 - val_accuracy: 0.4224\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.38860 to 0.42236, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.2259 - accuracy: 0.6095 - val_loss: 2.3767 - val_accuracy: 0.3826\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.42236\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.1709 - accuracy: 0.6414 - val_loss: 1.9045 - val_accuracy: 0.4756\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.42236 to 0.47562, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.1827 - accuracy: 0.6224 - val_loss: 2.5621 - val_accuracy: 0.3451\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.47562\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.1244 - accuracy: 0.6493 - val_loss: 2.2578 - val_accuracy: 0.3938\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.47562\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.0757 - accuracy: 0.6602 - val_loss: 1.8154 - val_accuracy: 0.5026\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.47562 to 0.50263, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.0704 - accuracy: 0.6691 - val_loss: 2.8920 - val_accuracy: 0.3241\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.50263\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 1.0540 - accuracy: 0.6641 - val_loss: 1.9160 - val_accuracy: 0.4741\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.50263\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 1.0494 - accuracy: 0.6685 - val_loss: 2.0065 - val_accuracy: 0.4554\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.50263\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 1.0030 - accuracy: 0.6775 - val_loss: 2.3528 - val_accuracy: 0.3766\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.50263\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.9177 - accuracy: 0.7103 - val_loss: 2.2172 - val_accuracy: 0.4359\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.50263\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.9227 - accuracy: 0.7007 - val_loss: 2.0418 - val_accuracy: 0.4809\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.50263\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.9278 - accuracy: 0.6982 - val_loss: 2.5395 - val_accuracy: 0.3856\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.50263\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.8898 - accuracy: 0.7084 - val_loss: 2.2988 - val_accuracy: 0.4351\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.50263\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.8581 - accuracy: 0.7293 - val_loss: 2.2895 - val_accuracy: 0.4254\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.50263\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.7916 - accuracy: 0.7524 - val_loss: 2.1607 - val_accuracy: 0.4779\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.50263\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.8095 - accuracy: 0.7370 - val_loss: 1.9606 - val_accuracy: 0.5094\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.50263 to 0.50938, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.7559 - accuracy: 0.7473 - val_loss: 1.8256 - val_accuracy: 0.4854\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.50938\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.7747 - accuracy: 0.7492 - val_loss: 2.4923 - val_accuracy: 0.4584\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.50938\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.6748 - accuracy: 0.7834 - val_loss: 2.2002 - val_accuracy: 0.4831\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.50938\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.7066 - accuracy: 0.7687 - val_loss: 2.1926 - val_accuracy: 0.4801\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.50938\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.7340 - accuracy: 0.7579 - val_loss: 1.9058 - val_accuracy: 0.5214\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.50938 to 0.52138, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.6738 - accuracy: 0.7799 - val_loss: 2.0980 - val_accuracy: 0.4989\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.52138\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.6205 - accuracy: 0.8018 - val_loss: 1.8682 - val_accuracy: 0.5334\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.52138 to 0.53338, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.6551 - accuracy: 0.7882 - val_loss: 1.5802 - val_accuracy: 0.5746\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.53338 to 0.57464, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.6153 - accuracy: 0.8036 - val_loss: 1.8452 - val_accuracy: 0.5386\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.57464\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.5938 - accuracy: 0.8006 - val_loss: 2.3488 - val_accuracy: 0.4674\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.57464\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.5430 - accuracy: 0.8247 - val_loss: 1.7592 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.57464 to 0.58065, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.5687 - accuracy: 0.8142 - val_loss: 2.4381 - val_accuracy: 0.4876\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.58065\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.5522 - accuracy: 0.8120 - val_loss: 1.5947 - val_accuracy: 0.5896\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.58065 to 0.58965, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.5239 - accuracy: 0.8296 - val_loss: 1.6296 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.58965 to 0.61665, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.5281 - accuracy: 0.8297 - val_loss: 2.5445 - val_accuracy: 0.4681\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.61665\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.4986 - accuracy: 0.8400 - val_loss: 1.6239 - val_accuracy: 0.6137\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.61665\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.4468 - accuracy: 0.8532 - val_loss: 1.4967 - val_accuracy: 0.6234\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.61665 to 0.62341, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.4825 - accuracy: 0.8416 - val_loss: 1.5343 - val_accuracy: 0.6242\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.62341 to 0.62416, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.4294 - accuracy: 0.8555 - val_loss: 1.5404 - val_accuracy: 0.6069\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.62416\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.3928 - accuracy: 0.8699 - val_loss: 1.9906 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.62416\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.3783 - accuracy: 0.8767 - val_loss: 1.5862 - val_accuracy: 0.6107\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.62416\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.4244 - accuracy: 0.8577 - val_loss: 1.6213 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.62416\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.4222 - accuracy: 0.8615 - val_loss: 1.8833 - val_accuracy: 0.5731\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.62416\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.3805 - accuracy: 0.8783 - val_loss: 1.6422 - val_accuracy: 0.5904\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.62416\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.3809 - accuracy: 0.8768 - val_loss: 1.7099 - val_accuracy: 0.5889\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.62416\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.3949 - accuracy: 0.8715 - val_loss: 1.5284 - val_accuracy: 0.6437\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.62416 to 0.64366, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.3627 - accuracy: 0.8882 - val_loss: 1.5364 - val_accuracy: 0.6302\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.64366\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.3623 - accuracy: 0.8862 - val_loss: 1.7171 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.64366\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.3277 - accuracy: 0.8997 - val_loss: 2.0242 - val_accuracy: 0.5746\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.64366\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.3291 - accuracy: 0.8972 - val_loss: 1.7943 - val_accuracy: 0.5964\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.64366\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.3391 - accuracy: 0.8927 - val_loss: 1.6899 - val_accuracy: 0.6137\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.64366\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.2978 - accuracy: 0.9071 - val_loss: 1.6328 - val_accuracy: 0.6227\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.64366\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.2708 - accuracy: 0.9135 - val_loss: 1.7757 - val_accuracy: 0.6032\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.64366\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.2759 - accuracy: 0.9142 - val_loss: 1.9951 - val_accuracy: 0.5679\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.64366\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.3165 - accuracy: 0.8927 - val_loss: 1.4888 - val_accuracy: 0.6557\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.64366 to 0.65566, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.2748 - accuracy: 0.9107 - val_loss: 1.6231 - val_accuracy: 0.6324\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.65566\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.2959 - accuracy: 0.9070 - val_loss: 1.4458 - val_accuracy: 0.6639\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.65566 to 0.66392, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.2694 - accuracy: 0.9100 - val_loss: 1.8192 - val_accuracy: 0.6107\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.66392\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.2593 - accuracy: 0.9199 - val_loss: 1.3671 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.66392 to 0.69317, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.2296 - accuracy: 0.9263 - val_loss: 1.4234 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.69317\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.2384 - accuracy: 0.9293 - val_loss: 1.3804 - val_accuracy: 0.6737\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.69317\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.2369 - accuracy: 0.9282 - val_loss: 1.2665 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.69317 to 0.69917, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.2131 - accuracy: 0.9327 - val_loss: 1.5500 - val_accuracy: 0.6489\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.69917\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.2289 - accuracy: 0.9291 - val_loss: 1.4328 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.69917\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.2392 - accuracy: 0.9232 - val_loss: 1.3633 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.69917\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.2016 - accuracy: 0.9429 - val_loss: 1.3898 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.69917\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.2252 - accuracy: 0.9247 - val_loss: 1.4267 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.69917\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.1945 - accuracy: 0.9384 - val_loss: 1.5081 - val_accuracy: 0.6512\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.69917\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.2197 - accuracy: 0.9290 - val_loss: 1.4002 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.69917\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.1805 - accuracy: 0.9443 - val_loss: 1.6301 - val_accuracy: 0.6587\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.69917\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.2208 - accuracy: 0.9318 - val_loss: 1.3052 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.69917\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1854 - accuracy: 0.9410 - val_loss: 1.4061 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.69917\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1814 - accuracy: 0.9421 - val_loss: 1.4338 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.69917\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.1833 - accuracy: 0.9406 - val_loss: 1.5306 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.69917\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1764 - accuracy: 0.9408 - val_loss: 1.5606 - val_accuracy: 0.6647\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.69917\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.1746 - accuracy: 0.9493 - val_loss: 1.3412 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.69917\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.1662 - accuracy: 0.9517 - val_loss: 1.4164 - val_accuracy: 0.6857\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.69917\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 25s 135ms/step - loss: 0.1437 - accuracy: 0.9562 - val_loss: 1.3187 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.69917 to 0.70668, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.1351 - accuracy: 0.9619 - val_loss: 1.5277 - val_accuracy: 0.6789\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.70668\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1531 - accuracy: 0.9537 - val_loss: 1.4739 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.70668\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1366 - accuracy: 0.9604 - val_loss: 1.3903 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.70668\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1404 - accuracy: 0.9617 - val_loss: 1.3680 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.70668\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1441 - accuracy: 0.9589 - val_loss: 1.5105 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.70668\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1567 - accuracy: 0.9488 - val_loss: 1.4986 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.70668\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1392 - accuracy: 0.9598 - val_loss: 1.5704 - val_accuracy: 0.6632\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.70668\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1383 - accuracy: 0.9579 - val_loss: 1.3643 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.70668\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.1346 - accuracy: 0.9550 - val_loss: 1.2824 - val_accuracy: 0.7239\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.70668 to 0.72393, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.1231 - accuracy: 0.9652 - val_loss: 1.4566 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.72393\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.1275 - accuracy: 0.9600 - val_loss: 1.3481 - val_accuracy: 0.7037\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.72393\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.1284 - accuracy: 0.9613 - val_loss: 1.4872 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.72393\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.1232 - accuracy: 0.9651 - val_loss: 1.4512 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.72393\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1300 - accuracy: 0.9604 - val_loss: 1.4709 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.72393\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1156 - accuracy: 0.9647 - val_loss: 1.3823 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.72393\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1345 - accuracy: 0.9567 - val_loss: 1.3696 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.72393\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1002 - accuracy: 0.9704 - val_loss: 1.2229 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.72393 to 0.74044, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1062 - accuracy: 0.9685 - val_loss: 1.6704 - val_accuracy: 0.6662\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.74044\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.1067 - accuracy: 0.9716 - val_loss: 1.4547 - val_accuracy: 0.6894\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.74044\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.1167 - accuracy: 0.9642 - val_loss: 1.3036 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.74044\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0919 - accuracy: 0.9754 - val_loss: 1.3525 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.74044\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.1231 - accuracy: 0.9623 - val_loss: 1.4812 - val_accuracy: 0.7059\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.74044\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0955 - accuracy: 0.9717 - val_loss: 1.4940 - val_accuracy: 0.6894\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.74044\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0963 - accuracy: 0.9711 - val_loss: 1.3509 - val_accuracy: 0.7172\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.74044\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.1117 - accuracy: 0.9676 - val_loss: 1.2790 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.74044\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0891 - accuracy: 0.9756 - val_loss: 1.4410 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.74044\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0899 - accuracy: 0.9766 - val_loss: 1.2676 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.74044\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0868 - accuracy: 0.9770 - val_loss: 1.4826 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.74044\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0923 - accuracy: 0.9711 - val_loss: 1.3014 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.74044\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0821 - accuracy: 0.9759 - val_loss: 1.3415 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.74044\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0818 - accuracy: 0.9782 - val_loss: 1.2515 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.74044 to 0.75319, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0857 - accuracy: 0.9751 - val_loss: 1.2976 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.75319\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0908 - accuracy: 0.9744 - val_loss: 1.3079 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.75319\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0848 - accuracy: 0.9760 - val_loss: 1.4922 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.75319\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 1.2794 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.75319\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0765 - accuracy: 0.9794 - val_loss: 1.3603 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.75319\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0747 - accuracy: 0.9815 - val_loss: 1.2701 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.75319\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0840 - accuracy: 0.9739 - val_loss: 1.2895 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.75319\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0886 - accuracy: 0.9732 - val_loss: 1.2117 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.75319\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0781 - accuracy: 0.9805 - val_loss: 1.2331 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.75319\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0818 - accuracy: 0.9777 - val_loss: 1.2810 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.75319\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0806 - accuracy: 0.9734 - val_loss: 1.2388 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.75319\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0771 - accuracy: 0.9765 - val_loss: 1.1954 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.75319 to 0.75394, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0703 - accuracy: 0.9797 - val_loss: 1.2829 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.75394\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0900 - accuracy: 0.9719 - val_loss: 1.2172 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.75394\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0717 - accuracy: 0.9808 - val_loss: 1.2820 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.75394\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0824 - accuracy: 0.9759 - val_loss: 1.3482 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.75394\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0657 - accuracy: 0.9799 - val_loss: 1.3118 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.75394\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 25s 136ms/step - loss: 0.0751 - accuracy: 0.9786 - val_loss: 1.1866 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.75394\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0811 - accuracy: 0.9753 - val_loss: 1.2985 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.75394\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0688 - accuracy: 0.9815 - val_loss: 1.2963 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.75394\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 1.2504 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.75394\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0746 - accuracy: 0.9802 - val_loss: 1.3238 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.75394\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0563 - accuracy: 0.9859 - val_loss: 1.4244 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.75394\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0635 - accuracy: 0.9838 - val_loss: 1.2719 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.75394\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0623 - accuracy: 0.9834 - val_loss: 1.3473 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.75394\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0595 - accuracy: 0.9834 - val_loss: 1.3869 - val_accuracy: 0.7112\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.75394\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0636 - accuracy: 0.9802 - val_loss: 1.2849 - val_accuracy: 0.7397\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.75394\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0630 - accuracy: 0.9843 - val_loss: 1.2291 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.75394\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0616 - accuracy: 0.9845 - val_loss: 1.3590 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.75394\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0695 - accuracy: 0.9813 - val_loss: 1.2632 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.75394\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 25s 135ms/step - loss: 0.0567 - accuracy: 0.9844 - val_loss: 1.2539 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.75394\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0557 - accuracy: 0.9814 - val_loss: 1.2980 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.75394\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0590 - accuracy: 0.9817 - val_loss: 1.2664 - val_accuracy: 0.7374\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.75394\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 1.2120 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00159: val_accuracy improved from 0.75394 to 0.75469, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0574 - accuracy: 0.9852 - val_loss: 1.2533 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.75469\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0529 - accuracy: 0.9849 - val_loss: 1.2952 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.75469\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0493 - accuracy: 0.9880 - val_loss: 1.2539 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.75469\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0571 - accuracy: 0.9838 - val_loss: 1.2347 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.75469\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0552 - accuracy: 0.9863 - val_loss: 1.2271 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.75469\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0535 - accuracy: 0.9861 - val_loss: 1.2301 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.75469\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0480 - accuracy: 0.9872 - val_loss: 1.2469 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00166: val_accuracy improved from 0.75469 to 0.75544, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 1.2662 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.75544\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 25s 135ms/step - loss: 0.0570 - accuracy: 0.9858 - val_loss: 1.2945 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.75544\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0439 - accuracy: 0.9906 - val_loss: 1.2483 - val_accuracy: 0.7569\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.75544 to 0.75694, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 1.2552 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.75694\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 1.2182 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.75694\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0576 - accuracy: 0.9853 - val_loss: 1.2477 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.75694\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0405 - accuracy: 0.9911 - val_loss: 1.2802 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.75694\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 1.2622 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.75694\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0472 - accuracy: 0.9859 - val_loss: 1.2659 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.75694\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0399 - accuracy: 0.9905 - val_loss: 1.2218 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.75694\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 1.1990 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.75694\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0549 - accuracy: 0.9852 - val_loss: 1.2071 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.75694 to 0.75994, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0436 - accuracy: 0.9901 - val_loss: 1.3447 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.75994\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 1.2022 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.75994\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0533 - accuracy: 0.9842 - val_loss: 1.2332 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.75994\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0417 - accuracy: 0.9910 - val_loss: 1.2329 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.75994\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0425 - accuracy: 0.9883 - val_loss: 1.1877 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00183: val_accuracy improved from 0.75994 to 0.76969, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0462 - accuracy: 0.9868 - val_loss: 1.2814 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.76969\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0366 - accuracy: 0.9910 - val_loss: 1.2710 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.76969\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0421 - accuracy: 0.9890 - val_loss: 1.2590 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.76969\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0407 - accuracy: 0.9880 - val_loss: 1.2228 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.76969\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0420 - accuracy: 0.9898 - val_loss: 1.2212 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.76969\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0478 - accuracy: 0.9870 - val_loss: 1.2431 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.76969\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0386 - accuracy: 0.9904 - val_loss: 1.2077 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.76969\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0373 - accuracy: 0.9921 - val_loss: 1.2472 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.76969\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0378 - accuracy: 0.9906 - val_loss: 1.3099 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.76969\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 1.2729 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.76969\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0424 - accuracy: 0.9879 - val_loss: 1.1938 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.76969\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0432 - accuracy: 0.9894 - val_loss: 1.3062 - val_accuracy: 0.7464\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.76969\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0334 - accuracy: 0.9921 - val_loss: 1.2169 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.76969\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 24s 133ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 1.2271 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.76969\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 1.2381 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.76969\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 1.2054 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.76969\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0382 - accuracy: 0.9918 - val_loss: 1.1598 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.76969\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0379 - accuracy: 0.9919 - val_loss: 1.2648 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.76969\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0375 - accuracy: 0.9911 - val_loss: 1.2421 - val_accuracy: 0.7569\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.76969\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 1.1836 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.76969\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 1.2188 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.76969\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 25s 135ms/step - loss: 0.0425 - accuracy: 0.9896 - val_loss: 1.1867 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.76969\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0348 - accuracy: 0.9925 - val_loss: 1.1883 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.76969\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0370 - accuracy: 0.9914 - val_loss: 1.1986 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.76969\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0439 - accuracy: 0.9879 - val_loss: 1.2187 - val_accuracy: 0.7569\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.76969\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 1.2023 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.76969\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 1.1998 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.76969\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 1.1902 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.76969\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 1.1943 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.76969\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0386 - accuracy: 0.9891 - val_loss: 1.1708 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.76969\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 1.1968 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.76969\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 1.1779 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.76969\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 1.1907 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.76969\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 25s 134ms/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 1.2044 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.76969\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0293 - accuracy: 0.9929 - val_loss: 1.2101 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.76969\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0314 - accuracy: 0.9929 - val_loss: 1.2099 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.76969\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0358 - accuracy: 0.9907 - val_loss: 1.2183 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.76969\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 1.1765 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00221: val_accuracy improved from 0.76969 to 0.77119, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0253 - accuracy: 0.9949 - val_loss: 1.2050 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.77119\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0284 - accuracy: 0.9930 - val_loss: 1.2071 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.77119\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0311 - accuracy: 0.9928 - val_loss: 1.2075 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00224: val_accuracy improved from 0.77119 to 0.77194, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0378 - accuracy: 0.9889 - val_loss: 1.2016 - val_accuracy: 0.7622\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.77194\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0260 - accuracy: 0.9935 - val_loss: 1.2117 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.77194\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 1.2458 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.77194\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0347 - accuracy: 0.9903 - val_loss: 1.2222 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.77194\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0352 - accuracy: 0.9930 - val_loss: 1.2383 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.77194\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 25s 135ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 1.2241 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.77194\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 1.2105 - val_accuracy: 0.7622\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.77194\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 1.1990 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.77194\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 24s 130ms/step - loss: 0.0386 - accuracy: 0.9928 - val_loss: 1.1921 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.77194\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 24s 129ms/step - loss: 0.0272 - accuracy: 0.9950 - val_loss: 1.1961 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.77194\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 24s 131ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 1.2059 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.77194\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 1.2153 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.77194\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 1.2002 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.77194\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 25s 133ms/step - loss: 0.0349 - accuracy: 0.9916 - val_loss: 1.2023 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.77194\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0252 - accuracy: 0.9941 - val_loss: 1.2316 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.77194\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 24s 132ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 1.2202 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.77194\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 2s 35ms/step - loss: 1.2672 - accuracy: 0.7468\n",
            "loss 1.267235279083252\n",
            "acc 0.7467859387397766\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 37s 182ms/step - loss: 3.0653 - accuracy: 0.1559 - val_loss: 3.5072 - val_accuracy: 0.0668\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.06677, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 2.6405 - accuracy: 0.2314 - val_loss: 3.3312 - val_accuracy: 0.1155\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.06677 to 0.11553, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 2.4101 - accuracy: 0.2957 - val_loss: 2.7640 - val_accuracy: 0.2446\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.11553 to 0.24456, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 2.2699 - accuracy: 0.3219 - val_loss: 2.4377 - val_accuracy: 0.3211\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.24456 to 0.32108, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 2.0929 - accuracy: 0.3684 - val_loss: 2.7595 - val_accuracy: 0.2498\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.32108\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 1.9645 - accuracy: 0.4015 - val_loss: 2.4526 - val_accuracy: 0.2941\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.32108\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 1.8824 - accuracy: 0.4218 - val_loss: 2.6441 - val_accuracy: 0.2896\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.32108\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 1.8114 - accuracy: 0.4295 - val_loss: 2.4789 - val_accuracy: 0.3158\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.32108\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 1.7255 - accuracy: 0.4523 - val_loss: 2.6219 - val_accuracy: 0.2851\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.32108\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 1.6481 - accuracy: 0.4819 - val_loss: 2.1778 - val_accuracy: 0.3638\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.32108 to 0.36384, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 1.5750 - accuracy: 0.5081 - val_loss: 2.0682 - val_accuracy: 0.4074\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.36384 to 0.40735, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 1.5180 - accuracy: 0.5215 - val_loss: 2.0245 - val_accuracy: 0.4254\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.40735 to 0.42536, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 1.4787 - accuracy: 0.5322 - val_loss: 2.2576 - val_accuracy: 0.3706\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.42536\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 1.4361 - accuracy: 0.5411 - val_loss: 2.2210 - val_accuracy: 0.3878\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.42536\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 1.3380 - accuracy: 0.5715 - val_loss: 1.9699 - val_accuracy: 0.4336\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.42536 to 0.43361, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 1.3198 - accuracy: 0.5853 - val_loss: 3.1495 - val_accuracy: 0.2626\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.43361\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 1.2483 - accuracy: 0.6036 - val_loss: 1.9342 - val_accuracy: 0.4374\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.43361 to 0.43736, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 1.2432 - accuracy: 0.5970 - val_loss: 1.7128 - val_accuracy: 0.4959\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.43736 to 0.49587, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 1.1895 - accuracy: 0.6165 - val_loss: 1.8054 - val_accuracy: 0.4726\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.49587\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 1.1751 - accuracy: 0.6223 - val_loss: 1.7087 - val_accuracy: 0.5191\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.49587 to 0.51913, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 1.1150 - accuracy: 0.6382 - val_loss: 2.0234 - val_accuracy: 0.4471\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.51913\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 1.0656 - accuracy: 0.6513 - val_loss: 1.8401 - val_accuracy: 0.4794\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.51913\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 30s 166ms/step - loss: 0.9943 - accuracy: 0.6755 - val_loss: 1.6365 - val_accuracy: 0.5386\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.51913 to 0.53863, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 30s 165ms/step - loss: 0.9886 - accuracy: 0.6930 - val_loss: 2.4690 - val_accuracy: 0.4096\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.53863\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 30s 165ms/step - loss: 0.9223 - accuracy: 0.7008 - val_loss: 2.2517 - val_accuracy: 0.4464\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.53863\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.9284 - accuracy: 0.6995 - val_loss: 1.5889 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.53863 to 0.53938, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.8812 - accuracy: 0.7153 - val_loss: 2.0522 - val_accuracy: 0.4906\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.53938\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.8538 - accuracy: 0.7232 - val_loss: 1.9285 - val_accuracy: 0.4816\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.53938\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.8307 - accuracy: 0.7288 - val_loss: 2.1805 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.53938\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 32s 175ms/step - loss: 0.7703 - accuracy: 0.7461 - val_loss: 1.8417 - val_accuracy: 0.5019\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.53938\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.7288 - accuracy: 0.7651 - val_loss: 2.1393 - val_accuracy: 0.4636\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.53938\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.7527 - accuracy: 0.7483 - val_loss: 1.6905 - val_accuracy: 0.5454\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.53938 to 0.54539, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.7199 - accuracy: 0.7555 - val_loss: 1.8217 - val_accuracy: 0.5004\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.54539\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.6381 - accuracy: 0.7942 - val_loss: 1.9026 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.54539\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.6954 - accuracy: 0.7710 - val_loss: 2.0404 - val_accuracy: 0.4959\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.54539\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.6287 - accuracy: 0.7956 - val_loss: 1.6047 - val_accuracy: 0.5649\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.54539 to 0.56489, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.6198 - accuracy: 0.7862 - val_loss: 1.9051 - val_accuracy: 0.5386\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.56489\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.5480 - accuracy: 0.8175 - val_loss: 1.6601 - val_accuracy: 0.5664\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.56489 to 0.56639, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.5951 - accuracy: 0.7952 - val_loss: 1.6234 - val_accuracy: 0.5754\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.56639 to 0.57539, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.5538 - accuracy: 0.8169 - val_loss: 1.8717 - val_accuracy: 0.5536\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.57539\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.5082 - accuracy: 0.8269 - val_loss: 1.9060 - val_accuracy: 0.5289\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.57539\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.4796 - accuracy: 0.8406 - val_loss: 1.6757 - val_accuracy: 0.5836\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.57539 to 0.58365, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.5292 - accuracy: 0.8188 - val_loss: 1.5740 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.58365 to 0.59115, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.4392 - accuracy: 0.8599 - val_loss: 1.4045 - val_accuracy: 0.6497\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.59115 to 0.64966, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.4434 - accuracy: 0.8507 - val_loss: 1.4892 - val_accuracy: 0.6264\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.64966\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.4212 - accuracy: 0.8659 - val_loss: 1.8008 - val_accuracy: 0.5776\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.64966\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.4225 - accuracy: 0.8568 - val_loss: 1.7312 - val_accuracy: 0.5799\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.64966\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.4092 - accuracy: 0.8563 - val_loss: 1.5327 - val_accuracy: 0.6302\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.64966\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.3796 - accuracy: 0.8756 - val_loss: 1.4544 - val_accuracy: 0.6459\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.64966\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.3700 - accuracy: 0.8750 - val_loss: 1.6918 - val_accuracy: 0.6077\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.64966\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.3852 - accuracy: 0.8709 - val_loss: 1.8795 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.64966\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.3608 - accuracy: 0.8820 - val_loss: 1.3625 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.64966 to 0.66242, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.3506 - accuracy: 0.8790 - val_loss: 1.8332 - val_accuracy: 0.5934\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.66242\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.3034 - accuracy: 0.8977 - val_loss: 1.5562 - val_accuracy: 0.6399\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.66242\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.3205 - accuracy: 0.8916 - val_loss: 1.3338 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.66242 to 0.67517, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.2748 - accuracy: 0.9108 - val_loss: 1.3931 - val_accuracy: 0.6519\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.67517\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.2681 - accuracy: 0.9144 - val_loss: 1.5754 - val_accuracy: 0.6272\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.67517\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.2512 - accuracy: 0.9142 - val_loss: 1.6181 - val_accuracy: 0.6332\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.67517\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.2568 - accuracy: 0.9156 - val_loss: 1.3998 - val_accuracy: 0.6767\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.67517 to 0.67667, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.2778 - accuracy: 0.9090 - val_loss: 1.8046 - val_accuracy: 0.5941\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.67667\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.2922 - accuracy: 0.9042 - val_loss: 1.7230 - val_accuracy: 0.6107\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.67667\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 0.2342 - accuracy: 0.9244 - val_loss: 1.8020 - val_accuracy: 0.6069\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.67667\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.2245 - accuracy: 0.9242 - val_loss: 1.8039 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.67667\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.2421 - accuracy: 0.9204 - val_loss: 1.3544 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.67667 to 0.67967, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.2187 - accuracy: 0.9296 - val_loss: 1.5217 - val_accuracy: 0.6452\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.67967\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.2285 - accuracy: 0.9282 - val_loss: 1.6228 - val_accuracy: 0.6609\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.67967\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.2061 - accuracy: 0.9326 - val_loss: 1.7887 - val_accuracy: 0.6144\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.67967\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.1800 - accuracy: 0.9419 - val_loss: 1.4921 - val_accuracy: 0.6677\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.67967\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.1855 - accuracy: 0.9387 - val_loss: 1.5812 - val_accuracy: 0.6452\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.67967\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.1778 - accuracy: 0.9487 - val_loss: 1.6710 - val_accuracy: 0.6452\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.67967\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.1888 - accuracy: 0.9393 - val_loss: 1.5025 - val_accuracy: 0.6759\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.67967\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.1704 - accuracy: 0.9463 - val_loss: 1.4418 - val_accuracy: 0.6654\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.67967\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.1590 - accuracy: 0.9519 - val_loss: 1.5226 - val_accuracy: 0.6669\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.67967\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.1481 - accuracy: 0.9529 - val_loss: 1.4005 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.67967 to 0.69017, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.1397 - accuracy: 0.9577 - val_loss: 1.5276 - val_accuracy: 0.6692\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.69017\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.1654 - accuracy: 0.9415 - val_loss: 1.5405 - val_accuracy: 0.6647\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.69017\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.1353 - accuracy: 0.9575 - val_loss: 1.2706 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.69017 to 0.71268, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 1.5404 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.71268\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.1355 - accuracy: 0.9570 - val_loss: 1.5489 - val_accuracy: 0.6504\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.71268\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.1524 - accuracy: 0.9542 - val_loss: 1.3569 - val_accuracy: 0.7082\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.71268\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.1270 - accuracy: 0.9577 - val_loss: 1.3132 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.71268 to 0.71568, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.1412 - accuracy: 0.9535 - val_loss: 1.5126 - val_accuracy: 0.6819\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.71568\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.1157 - accuracy: 0.9620 - val_loss: 1.4171 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.71568\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.1258 - accuracy: 0.9620 - val_loss: 1.3679 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.71568\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.1242 - accuracy: 0.9598 - val_loss: 1.3139 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.71568 to 0.72243, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.1126 - accuracy: 0.9627 - val_loss: 1.2538 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.72243 to 0.72693, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.1103 - accuracy: 0.9653 - val_loss: 1.5920 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.72693\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.1322 - accuracy: 0.9582 - val_loss: 1.3130 - val_accuracy: 0.7239\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.72693\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0975 - accuracy: 0.9694 - val_loss: 1.2909 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.72693\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0994 - accuracy: 0.9725 - val_loss: 1.4593 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.72693\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.1142 - accuracy: 0.9680 - val_loss: 1.2385 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.72693 to 0.72768, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0847 - accuracy: 0.9707 - val_loss: 1.4113 - val_accuracy: 0.6954\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.72768\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0922 - accuracy: 0.9737 - val_loss: 1.2506 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.72768 to 0.74344, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0858 - accuracy: 0.9727 - val_loss: 1.3958 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.74344\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 1.3146 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.74344\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0796 - accuracy: 0.9774 - val_loss: 1.2964 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.74344\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0845 - accuracy: 0.9743 - val_loss: 1.2901 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.74344\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0837 - accuracy: 0.9730 - val_loss: 1.2730 - val_accuracy: 0.7359\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.74344\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0859 - accuracy: 0.9748 - val_loss: 1.2324 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.74344\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0664 - accuracy: 0.9797 - val_loss: 1.2619 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.74344\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0720 - accuracy: 0.9766 - val_loss: 1.5392 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.74344\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0698 - accuracy: 0.9792 - val_loss: 1.3778 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.74344\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0717 - accuracy: 0.9779 - val_loss: 1.3193 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.74344\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0699 - accuracy: 0.9782 - val_loss: 1.2548 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.74344\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0655 - accuracy: 0.9787 - val_loss: 1.3356 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.74344\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 32s 174ms/step - loss: 0.0591 - accuracy: 0.9842 - val_loss: 1.3439 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.74344\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 32s 174ms/step - loss: 0.0728 - accuracy: 0.9776 - val_loss: 1.3851 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.74344\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0748 - accuracy: 0.9774 - val_loss: 1.3554 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.74344\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 1.4500 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.74344\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0675 - accuracy: 0.9804 - val_loss: 1.4043 - val_accuracy: 0.7082\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.74344\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0616 - accuracy: 0.9783 - val_loss: 1.2455 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.74344\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0613 - accuracy: 0.9807 - val_loss: 1.3545 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.74344\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0730 - accuracy: 0.9767 - val_loss: 1.2948 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.74344\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 1.3258 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.74344\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 1.3608 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.74344\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 32s 175ms/step - loss: 0.0608 - accuracy: 0.9793 - val_loss: 1.2597 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.74344\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 1.4684 - val_accuracy: 0.7187\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.74344\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0577 - accuracy: 0.9805 - val_loss: 1.3197 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.74344\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0552 - accuracy: 0.9809 - val_loss: 1.2654 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.74344 to 0.75169, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0479 - accuracy: 0.9843 - val_loss: 1.2782 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.75169\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0457 - accuracy: 0.9868 - val_loss: 1.2348 - val_accuracy: 0.7464\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.75169\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 1.1622 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.75169 to 0.76669, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0572 - accuracy: 0.9840 - val_loss: 1.2515 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.76669\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0384 - accuracy: 0.9902 - val_loss: 1.1716 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.76669\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 1.2268 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.76669\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 32s 174ms/step - loss: 0.0520 - accuracy: 0.9849 - val_loss: 1.2617 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.76669\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 1.2388 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.76669\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 1.2254 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.76669\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0492 - accuracy: 0.9834 - val_loss: 1.1802 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.76669\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 1.2228 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.76669\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0413 - accuracy: 0.9885 - val_loss: 1.3660 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.76669\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0441 - accuracy: 0.9871 - val_loss: 1.2529 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.76669\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0370 - accuracy: 0.9916 - val_loss: 1.2461 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.76669\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0435 - accuracy: 0.9874 - val_loss: 1.2545 - val_accuracy: 0.7622\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.76669\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 1.1910 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.76669\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0443 - accuracy: 0.9851 - val_loss: 1.2347 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.76669\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0485 - accuracy: 0.9857 - val_loss: 1.2978 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.76669\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 1.3014 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.76669\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 1.1650 - val_accuracy: 0.7674\n",
            "\n",
            "Epoch 00139: val_accuracy improved from 0.76669 to 0.76744, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0397 - accuracy: 0.9885 - val_loss: 1.1981 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.76744 to 0.77044, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0363 - accuracy: 0.9892 - val_loss: 1.3361 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.77044\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0361 - accuracy: 0.9881 - val_loss: 1.1709 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.77044\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0294 - accuracy: 0.9925 - val_loss: 1.2433 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.77044\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 1.2365 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.77044\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 32s 175ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 1.2198 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.77044\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 1.2473 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.77044\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 1.2109 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.77044\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 1.2512 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.77044\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: 1.2330 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.77044\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0332 - accuracy: 0.9922 - val_loss: 1.2190 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.77044\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 1.2591 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.77044\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 1.2478 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.77044\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 1.2423 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.77044\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 1.1977 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.77044\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0268 - accuracy: 0.9935 - val_loss: 1.1942 - val_accuracy: 0.7727\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.77044 to 0.77269, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 1.1928 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.77269\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 1.2236 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.77269\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0666 - accuracy: 0.9832 - val_loss: 1.2182 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.77269\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 1.2198 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.77269\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 1.2096 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.77269\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 1.1926 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.77269\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 1.2076 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.77269\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0275 - accuracy: 0.9930 - val_loss: 1.2317 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.77269\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 32s 175ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 1.2202 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.77269\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 1.1853 - val_accuracy: 0.7674\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.77269\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 1.2291 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.77269\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0258 - accuracy: 0.9930 - val_loss: 1.2079 - val_accuracy: 0.7682\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.77269\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 1.2619 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.77269\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 1.1901 - val_accuracy: 0.7772\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.77269 to 0.77719, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 1.2368 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.77719\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 1.1972 - val_accuracy: 0.7742\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.77719\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 1.1714 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.77719\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 1.1929 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.77719\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 1.2189 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.77719\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 1.1937 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.77719\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 31s 166ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 1.2292 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.77719\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 1.1729 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.77719\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 1.2259 - val_accuracy: 0.7622\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.77719\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 1.2591 - val_accuracy: 0.7629\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.77719\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 1.2524 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.77719\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 1.2245 - val_accuracy: 0.7674\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.77719\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 31s 174ms/step - loss: 0.0545 - accuracy: 0.9866 - val_loss: 1.1828 - val_accuracy: 0.7809\n",
            "\n",
            "Epoch 00182: val_accuracy improved from 0.77719 to 0.78095, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0259 - accuracy: 0.9902 - val_loss: 1.1863 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.78095\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 1.2093 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.78095\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 1.1825 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.78095\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 1.1632 - val_accuracy: 0.7674\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.78095\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 1.1870 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.78095\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 1.2121 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.78095\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.1862 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.78095\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 1.1852 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.78095\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 1.1626 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.78095\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 32s 174ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 1.1683 - val_accuracy: 0.7764\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.78095\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 32s 175ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.1534 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.78095\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 1.2062 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.78095\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 1.1645 - val_accuracy: 0.7824\n",
            "\n",
            "Epoch 00195: val_accuracy improved from 0.78095 to 0.78245, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 1.1958 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.78245\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 1.1904 - val_accuracy: 0.7802\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.78245\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 1.1971 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.78245\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 1.1700 - val_accuracy: 0.7787\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.78245\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 1.1761 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.78245\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 1.1917 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.78245\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 1.1849 - val_accuracy: 0.7674\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.78245\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 1.1779 - val_accuracy: 0.7794\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.78245\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 1.1916 - val_accuracy: 0.7742\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.78245\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 1.1819 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.78245\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 1.1764 - val_accuracy: 0.7787\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.78245\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 1.1874 - val_accuracy: 0.7839\n",
            "\n",
            "Epoch 00207: val_accuracy improved from 0.78245 to 0.78395, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 1.1930 - val_accuracy: 0.7727\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.78395\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 1.1601 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.78395\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 1.1790 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.78395\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 1.1810 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.78395\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 1.1970 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.78395\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 1.1881 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.78395\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 1.1978 - val_accuracy: 0.7742\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.78395\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 1.1783 - val_accuracy: 0.7779\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.78395\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 1.1750 - val_accuracy: 0.7877\n",
            "\n",
            "Epoch 00216: val_accuracy improved from 0.78395 to 0.78770, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 1.1980 - val_accuracy: 0.7764\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.78770\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 31s 172ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 1.1709 - val_accuracy: 0.7794\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.78770\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 1.1656 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.78770\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 32s 172ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 1.1960 - val_accuracy: 0.7749\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.78770\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 32s 174ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 1.2183 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.78770\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 32s 174ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 1.1586 - val_accuracy: 0.7839\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.78770\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 1.1897 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.78770\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 31s 167ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 1.2059 - val_accuracy: 0.7854\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.78770\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 31s 168ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.1560 - val_accuracy: 0.7839\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.78770\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 1.1900 - val_accuracy: 0.7869\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.78770\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 1.1536 - val_accuracy: 0.7847\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.78770\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 1.1549 - val_accuracy: 0.7832\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.78770\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 32s 171ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 1.1752 - val_accuracy: 0.7839\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.78770\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 1.1775 - val_accuracy: 0.7802\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.78770\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 32s 175ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 1.1543 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.78770\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 1.1631 - val_accuracy: 0.7854\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.78770\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 1.1805 - val_accuracy: 0.7787\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.78770\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 1.1814 - val_accuracy: 0.7764\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.78770\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 1.1884 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.78770\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 1.1704 - val_accuracy: 0.7809\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.78770\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 31s 169ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 1.1714 - val_accuracy: 0.7832\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.78770\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 31s 170ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 1.1958 - val_accuracy: 0.7772\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.78770\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 31s 171ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 1.2056 - val_accuracy: 0.7779\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.78770\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 32s 173ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 1.1767 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.78770\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 1.2597 - accuracy: 0.7708\n",
            "loss 1.2596752643585205\n",
            "acc 0.7708216905593872\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 46s 228ms/step - loss: 3.2063 - accuracy: 0.1145 - val_loss: 3.3777 - val_accuracy: 0.0953\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09527, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 2.7977 - accuracy: 0.1898 - val_loss: 3.4450 - val_accuracy: 0.1013\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09527 to 0.10128, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 2.5543 - accuracy: 0.2600 - val_loss: 3.4887 - val_accuracy: 0.1523\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10128 to 0.15229, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 2.4409 - accuracy: 0.2823 - val_loss: 3.5482 - val_accuracy: 0.1185\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.15229\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 2.3175 - accuracy: 0.3091 - val_loss: 3.3001 - val_accuracy: 0.1815\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.15229 to 0.18155, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 2.1820 - accuracy: 0.3340 - val_loss: 3.4661 - val_accuracy: 0.1253\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.18155\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 2.1315 - accuracy: 0.3497 - val_loss: 3.5744 - val_accuracy: 0.1388\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.18155\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 1.9903 - accuracy: 0.3787 - val_loss: 2.5172 - val_accuracy: 0.2941\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.18155 to 0.29407, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 1.9043 - accuracy: 0.4216 - val_loss: 2.9481 - val_accuracy: 0.1943\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.29407\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 1.8069 - accuracy: 0.4448 - val_loss: 2.4814 - val_accuracy: 0.2813\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.29407\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 1.7651 - accuracy: 0.4406 - val_loss: 2.1750 - val_accuracy: 0.3691\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.29407 to 0.36909, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 1.7072 - accuracy: 0.4669 - val_loss: 2.0287 - val_accuracy: 0.3923\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.36909 to 0.39235, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 1.6332 - accuracy: 0.4788 - val_loss: 2.4092 - val_accuracy: 0.3398\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.39235\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 1.5285 - accuracy: 0.5261 - val_loss: 2.3118 - val_accuracy: 0.3646\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.39235\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 40s 218ms/step - loss: 1.5314 - accuracy: 0.5117 - val_loss: 1.9722 - val_accuracy: 0.4269\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.39235 to 0.42686, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 1.4630 - accuracy: 0.5314 - val_loss: 1.8687 - val_accuracy: 0.4509\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.42686 to 0.45086, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 1.3286 - accuracy: 0.5773 - val_loss: 2.1975 - val_accuracy: 0.3863\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.45086\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 1.3581 - accuracy: 0.5693 - val_loss: 2.7810 - val_accuracy: 0.3053\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.45086\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 1.3471 - accuracy: 0.5603 - val_loss: 2.2030 - val_accuracy: 0.3841\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.45086\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 1.2639 - accuracy: 0.5825 - val_loss: 1.9293 - val_accuracy: 0.4614\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.45086 to 0.46137, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 1.1721 - accuracy: 0.6203 - val_loss: 2.2368 - val_accuracy: 0.4111\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.46137\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 1.2364 - accuracy: 0.6032 - val_loss: 1.8236 - val_accuracy: 0.4696\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.46137 to 0.46962, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 40s 219ms/step - loss: 1.1312 - accuracy: 0.6377 - val_loss: 1.8973 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.46962\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 1.0632 - accuracy: 0.6504 - val_loss: 1.8890 - val_accuracy: 0.4846\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.46962 to 0.48462, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 1.0492 - accuracy: 0.6625 - val_loss: 1.9062 - val_accuracy: 0.4614\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.48462\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 1.0238 - accuracy: 0.6658 - val_loss: 1.7578 - val_accuracy: 0.5229\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.48462 to 0.52288, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.9937 - accuracy: 0.6781 - val_loss: 2.0909 - val_accuracy: 0.4351\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.52288\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.9643 - accuracy: 0.6901 - val_loss: 2.5334 - val_accuracy: 0.3691\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.52288\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.9697 - accuracy: 0.6885 - val_loss: 1.9800 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.52288\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 40s 219ms/step - loss: 0.8929 - accuracy: 0.7058 - val_loss: 1.9629 - val_accuracy: 0.4854\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.52288\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.8401 - accuracy: 0.7280 - val_loss: 2.6089 - val_accuracy: 0.3796\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.52288\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.8585 - accuracy: 0.7177 - val_loss: 2.0866 - val_accuracy: 0.4561\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.52288\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.8226 - accuracy: 0.7314 - val_loss: 2.0739 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.52288\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.7558 - accuracy: 0.7512 - val_loss: 1.7926 - val_accuracy: 0.5086\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.52288\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.7609 - accuracy: 0.7449 - val_loss: 1.7863 - val_accuracy: 0.5341\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.52288 to 0.53413, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.7487 - accuracy: 0.7487 - val_loss: 1.7858 - val_accuracy: 0.5499\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.53413 to 0.54989, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 40s 216ms/step - loss: 0.6898 - accuracy: 0.7585 - val_loss: 1.6203 - val_accuracy: 0.5746\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.54989 to 0.57464, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 40s 218ms/step - loss: 0.6361 - accuracy: 0.7931 - val_loss: 1.8869 - val_accuracy: 0.5304\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.57464\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.6642 - accuracy: 0.7860 - val_loss: 1.9763 - val_accuracy: 0.5199\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.57464\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.6470 - accuracy: 0.7837 - val_loss: 1.7993 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.57464\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.5970 - accuracy: 0.8008 - val_loss: 1.5120 - val_accuracy: 0.6204\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.57464 to 0.62041, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.6056 - accuracy: 0.7952 - val_loss: 1.5653 - val_accuracy: 0.6024\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.62041\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.5574 - accuracy: 0.8149 - val_loss: 1.8933 - val_accuracy: 0.5446\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.62041\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.5268 - accuracy: 0.8268 - val_loss: 1.6876 - val_accuracy: 0.5649\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.62041\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 40s 218ms/step - loss: 0.5291 - accuracy: 0.8227 - val_loss: 1.9312 - val_accuracy: 0.5521\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.62041\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.5607 - accuracy: 0.8142 - val_loss: 1.8616 - val_accuracy: 0.5491\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.62041\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.5217 - accuracy: 0.8195 - val_loss: 1.9817 - val_accuracy: 0.5281\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.62041\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.4676 - accuracy: 0.8497 - val_loss: 1.6225 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.62041\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.4532 - accuracy: 0.8500 - val_loss: 1.7389 - val_accuracy: 0.5994\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.62041\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.3970 - accuracy: 0.8713 - val_loss: 1.7779 - val_accuracy: 0.5949\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.62041\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.3957 - accuracy: 0.8634 - val_loss: 1.4867 - val_accuracy: 0.6414\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.62041 to 0.64141, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.3811 - accuracy: 0.8712 - val_loss: 1.7718 - val_accuracy: 0.6032\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.64141\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 40s 220ms/step - loss: 0.3870 - accuracy: 0.8718 - val_loss: 1.6786 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.64141\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.3584 - accuracy: 0.8775 - val_loss: 1.7790 - val_accuracy: 0.5994\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.64141\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.3545 - accuracy: 0.8812 - val_loss: 1.7230 - val_accuracy: 0.5866\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.64141\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.3541 - accuracy: 0.8816 - val_loss: 1.5839 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.64141\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.3315 - accuracy: 0.8909 - val_loss: 1.7643 - val_accuracy: 0.6092\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.64141\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.3675 - accuracy: 0.8745 - val_loss: 1.5783 - val_accuracy: 0.6452\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.64141 to 0.64516, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.3149 - accuracy: 0.8953 - val_loss: 1.7109 - val_accuracy: 0.6114\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.64516\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 40s 217ms/step - loss: 0.3008 - accuracy: 0.8965 - val_loss: 1.8437 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.64516\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 40s 216ms/step - loss: 0.2814 - accuracy: 0.9066 - val_loss: 1.5971 - val_accuracy: 0.6369\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.64516\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.2786 - accuracy: 0.9040 - val_loss: 1.4254 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.64516 to 0.66992, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.2708 - accuracy: 0.9121 - val_loss: 1.8410 - val_accuracy: 0.6152\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.66992\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.3047 - accuracy: 0.8948 - val_loss: 1.6907 - val_accuracy: 0.6219\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.66992\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.2319 - accuracy: 0.9271 - val_loss: 1.4238 - val_accuracy: 0.6767\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.66992 to 0.67667, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.2649 - accuracy: 0.9097 - val_loss: 1.6968 - val_accuracy: 0.6354\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.67667\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.2391 - accuracy: 0.9183 - val_loss: 1.8652 - val_accuracy: 0.5964\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.67667\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 40s 220ms/step - loss: 0.2308 - accuracy: 0.9272 - val_loss: 1.7460 - val_accuracy: 0.6482\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.67667\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.2006 - accuracy: 0.9337 - val_loss: 1.5747 - val_accuracy: 0.6677\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.67667\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.2221 - accuracy: 0.9319 - val_loss: 1.5071 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.67667\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.2361 - accuracy: 0.9252 - val_loss: 1.5255 - val_accuracy: 0.6842\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.67667 to 0.68417, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.2086 - accuracy: 0.9297 - val_loss: 1.6841 - val_accuracy: 0.6384\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.68417\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.1745 - accuracy: 0.9455 - val_loss: 1.6245 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.68417\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.1868 - accuracy: 0.9423 - val_loss: 1.5598 - val_accuracy: 0.6654\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.68417\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 40s 217ms/step - loss: 0.1728 - accuracy: 0.9436 - val_loss: 1.9197 - val_accuracy: 0.5896\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.68417\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 40s 218ms/step - loss: 0.1957 - accuracy: 0.9350 - val_loss: 1.5111 - val_accuracy: 0.6564\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.68417\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.2054 - accuracy: 0.9362 - val_loss: 1.5378 - val_accuracy: 0.6587\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.68417\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.1616 - accuracy: 0.9481 - val_loss: 1.5846 - val_accuracy: 0.6557\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.68417\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.1396 - accuracy: 0.9505 - val_loss: 1.7382 - val_accuracy: 0.6272\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.68417\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.1848 - accuracy: 0.9391 - val_loss: 1.8083 - val_accuracy: 0.6212\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.68417\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.1673 - accuracy: 0.9448 - val_loss: 1.5444 - val_accuracy: 0.6692\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.68417\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.1518 - accuracy: 0.9520 - val_loss: 1.4722 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.68417\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 40s 217ms/step - loss: 0.1363 - accuracy: 0.9536 - val_loss: 1.5063 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.68417\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.1563 - accuracy: 0.9477 - val_loss: 1.6639 - val_accuracy: 0.6369\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.68417\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.1447 - accuracy: 0.9519 - val_loss: 1.5109 - val_accuracy: 0.6662\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.68417\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.1263 - accuracy: 0.9613 - val_loss: 1.4268 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.68417 to 0.69317, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.1415 - accuracy: 0.9514 - val_loss: 1.4589 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.69317 to 0.69467, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.1410 - accuracy: 0.9551 - val_loss: 1.6880 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.69467\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.1225 - accuracy: 0.9620 - val_loss: 1.5524 - val_accuracy: 0.6864\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.69467\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.1098 - accuracy: 0.9650 - val_loss: 1.5390 - val_accuracy: 0.6804\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.69467\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 40s 219ms/step - loss: 0.1278 - accuracy: 0.9561 - val_loss: 1.5857 - val_accuracy: 0.6759\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.69467\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.1379 - accuracy: 0.9550 - val_loss: 1.4974 - val_accuracy: 0.6819\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.69467\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.1142 - accuracy: 0.9608 - val_loss: 1.7231 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.69467\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.1336 - accuracy: 0.9603 - val_loss: 1.5393 - val_accuracy: 0.6767\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.69467\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.1091 - accuracy: 0.9646 - val_loss: 1.3722 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.69467 to 0.71568, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.1282 - accuracy: 0.9596 - val_loss: 1.4122 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.71568\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0964 - accuracy: 0.9687 - val_loss: 1.4114 - val_accuracy: 0.7059\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.71568\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.1060 - accuracy: 0.9659 - val_loss: 1.4923 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.71568\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 1.5282 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.71568\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0923 - accuracy: 0.9711 - val_loss: 1.4386 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.71568\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0904 - accuracy: 0.9743 - val_loss: 1.4490 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.71568\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0839 - accuracy: 0.9738 - val_loss: 1.3929 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.71568 to 0.71643, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0807 - accuracy: 0.9726 - val_loss: 1.4740 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.71643\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0904 - accuracy: 0.9677 - val_loss: 1.5778 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.71643\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0822 - accuracy: 0.9733 - val_loss: 1.5100 - val_accuracy: 0.7104\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.71643\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.0929 - accuracy: 0.9710 - val_loss: 1.5128 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.71643\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0825 - accuracy: 0.9741 - val_loss: 1.5557 - val_accuracy: 0.6932\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.71643\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0869 - accuracy: 0.9711 - val_loss: 1.5080 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.71643\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 39s 209ms/step - loss: 0.0787 - accuracy: 0.9784 - val_loss: 1.5651 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.71643\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0611 - accuracy: 0.9822 - val_loss: 1.4317 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.71643\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 1.5148 - val_accuracy: 0.7082\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.71643\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0759 - accuracy: 0.9748 - val_loss: 1.4471 - val_accuracy: 0.7104\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.71643\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0647 - accuracy: 0.9816 - val_loss: 1.6240 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.71643\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 40s 217ms/step - loss: 0.0632 - accuracy: 0.9811 - val_loss: 1.4282 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.71643 to 0.72543, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0768 - accuracy: 0.9719 - val_loss: 1.4331 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.72543\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0671 - accuracy: 0.9796 - val_loss: 1.4627 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.72543 to 0.72693, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0635 - accuracy: 0.9770 - val_loss: 1.3725 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.72693 to 0.72918, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0664 - accuracy: 0.9791 - val_loss: 1.3657 - val_accuracy: 0.7374\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.72918 to 0.73743, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0756 - accuracy: 0.9722 - val_loss: 1.5261 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.73743\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0538 - accuracy: 0.9818 - val_loss: 1.4319 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.73743\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 1.3944 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.73743\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 1.4661 - val_accuracy: 0.7172\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.73743\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0795 - accuracy: 0.9754 - val_loss: 1.7224 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.73743\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0645 - accuracy: 0.9814 - val_loss: 1.4488 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.73743\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0627 - accuracy: 0.9794 - val_loss: 1.4683 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.73743\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0524 - accuracy: 0.9822 - val_loss: 1.3270 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.73743\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 1.4062 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.73743\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 1.4286 - val_accuracy: 0.7194\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.73743\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 40s 215ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 1.4157 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.73743\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 1.5194 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.73743\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0509 - accuracy: 0.9860 - val_loss: 1.4900 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.73743\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 1.4471 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.73743\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 1.4705 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.73743\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0544 - accuracy: 0.9788 - val_loss: 1.4039 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.73743\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 1.4536 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.73743\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0421 - accuracy: 0.9884 - val_loss: 1.5052 - val_accuracy: 0.7194\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.73743\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 40s 216ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 1.4277 - val_accuracy: 0.7397\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.73743 to 0.73968, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 1.3985 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.73968\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0364 - accuracy: 0.9883 - val_loss: 1.3684 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.73968\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0423 - accuracy: 0.9849 - val_loss: 1.3897 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.73968\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 1.2959 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.73968 to 0.74719, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0452 - accuracy: 0.9857 - val_loss: 1.3176 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.74719\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 1.3018 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.74719\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0393 - accuracy: 0.9888 - val_loss: 1.3975 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.74719\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 1.3188 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00145: val_accuracy improved from 0.74719 to 0.75244, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 39s 209ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 1.3141 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.75244\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0415 - accuracy: 0.9884 - val_loss: 1.2991 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.75244\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 1.3135 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.75244\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 1.3930 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.75244\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 1.4186 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.75244\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0432 - accuracy: 0.9846 - val_loss: 1.4308 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.75244\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0423 - accuracy: 0.9855 - val_loss: 1.3563 - val_accuracy: 0.7464\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.75244\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 1.4101 - val_accuracy: 0.7359\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.75244\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 1.3219 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.75244\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 1.3521 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.75244\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 1.4118 - val_accuracy: 0.7329\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.75244\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 1.6621 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.75244\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0370 - accuracy: 0.9870 - val_loss: 1.3968 - val_accuracy: 0.7359\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.75244\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0399 - accuracy: 0.9868 - val_loss: 1.3670 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.75244\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 1.3901 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.75244\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 1.3903 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.75244\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0316 - accuracy: 0.9913 - val_loss: 1.4367 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.75244\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 1.3675 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.75244\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0349 - accuracy: 0.9878 - val_loss: 1.3297 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00164: val_accuracy improved from 0.75244 to 0.75619, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 1.4070 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.75619\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0391 - accuracy: 0.9887 - val_loss: 1.4038 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.75619\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0269 - accuracy: 0.9899 - val_loss: 1.4583 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.75619\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 1.3409 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.75619\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 1.3271 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.75619\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 1.3206 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.75619\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 1.3410 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.75619\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 1.3314 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.75619\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 1.2817 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00173: val_accuracy improved from 0.75619 to 0.75994, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0283 - accuracy: 0.9928 - val_loss: 1.3219 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.75994\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 1.3500 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.75994\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0250 - accuracy: 0.9903 - val_loss: 1.3322 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.75994\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 1.3185 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.75994\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 1.3242 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.75994\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 1.3050 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00179: val_accuracy improved from 0.75994 to 0.77119, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 1.3282 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.77119\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 1.3577 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.77119\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 39s 215ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 1.3040 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.77119\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 40s 216ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 1.3021 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.77119\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 1.3079 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.77119\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 1.4296 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.77119\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 1.3251 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.77119\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 38s 207ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 1.2814 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.77119\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 38s 207ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 1.3370 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.77119\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 1.3283 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.77119\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 38s 207ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 1.3064 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.77119\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 38s 206ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 1.3526 - val_accuracy: 0.7569\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.77119\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 38s 207ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 1.3426 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.77119\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 38s 207ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 1.3714 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.77119\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 38s 207ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 1.3526 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.77119\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 1.3281 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.77119\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 1.3430 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.77119\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 1.3520 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.77119\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 1.3147 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.77119\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.3288 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.77119\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 1.3779 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.77119\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 1.3177 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.77119\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 1.3755 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.77119\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 1.3383 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.77119\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 1.3071 - val_accuracy: 0.7674\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.77119\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 1.3387 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.77119\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 1.3210 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.77119\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 1.3705 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.77119\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 1.3241 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.77119\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 1.3388 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.77119\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 1.3672 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.77119\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0165 - accuracy: 0.9931 - val_loss: 1.3418 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.77119\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 1.3191 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.77119\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 1.3191 - val_accuracy: 0.7659\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.77119\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 1.3290 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.77119\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 1.3566 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.77119\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 1.3435 - val_accuracy: 0.7524\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.77119\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 1.3257 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.77119\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 1.3150 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.77119\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0177 - accuracy: 0.9929 - val_loss: 1.3304 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.77119\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 1.3452 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.77119\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 1.3607 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.77119\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 1.3230 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.77119\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 1.3355 - val_accuracy: 0.7614\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.77119\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0166 - accuracy: 0.9932 - val_loss: 1.3385 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.77119\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 1.3283 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.77119\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 1.3289 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.77119\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 1.3542 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.77119\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 39s 210ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 1.3408 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.77119\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 39s 212ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 1.3465 - val_accuracy: 0.7622\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.77119\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 1.3454 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.77119\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 38s 210ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 1.3231 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.77119\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 1.3524 - val_accuracy: 0.7637\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.77119\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 1.3470 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.77119\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 1.3543 - val_accuracy: 0.7569\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.77119\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 1.3381 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.77119\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 39s 211ms/step - loss: 0.0181 - accuracy: 0.9931 - val_loss: 1.3523 - val_accuracy: 0.7652\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.77119\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 39s 213ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 1.3281 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.77119\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 39s 214ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 1.3172 - val_accuracy: 0.7577\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.77119\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 38s 209ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.3314 - val_accuracy: 0.7584\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.77119\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 38s 208ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 1.3519 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.77119\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 4s 56ms/step - loss: 1.4152 - accuracy: 0.7390\n",
            "loss 1.4152165651321411\n",
            "acc 0.738960325717926\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 50s 245ms/step - loss: 3.3500 - accuracy: 0.1214 - val_loss: 3.0399 - val_accuracy: 0.1373\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.13728, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 2.8806 - accuracy: 0.1889 - val_loss: 2.8916 - val_accuracy: 0.1898\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.13728 to 0.18980, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 2.6687 - accuracy: 0.2294 - val_loss: 2.9410 - val_accuracy: 0.1995\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.18980 to 0.19955, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 2.5694 - accuracy: 0.2464 - val_loss: 2.8543 - val_accuracy: 0.2131\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.19955 to 0.21305, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 2.4483 - accuracy: 0.2768 - val_loss: 2.4602 - val_accuracy: 0.2888\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.21305 to 0.28882, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 2.2538 - accuracy: 0.3253 - val_loss: 2.3627 - val_accuracy: 0.3046\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.28882 to 0.30458, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 2.1902 - accuracy: 0.3359 - val_loss: 2.4922 - val_accuracy: 0.2971\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.30458\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 2.1220 - accuracy: 0.3623 - val_loss: 3.4730 - val_accuracy: 0.1868\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.30458\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 1.9973 - accuracy: 0.3891 - val_loss: 2.9857 - val_accuracy: 0.2071\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.30458\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 2.0157 - accuracy: 0.3763 - val_loss: 2.6651 - val_accuracy: 0.2738\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.30458\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 45s 244ms/step - loss: 1.9155 - accuracy: 0.4095 - val_loss: 2.1906 - val_accuracy: 0.3398\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.30458 to 0.33983, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.8192 - accuracy: 0.4324 - val_loss: 2.7323 - val_accuracy: 0.3736\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.33983 to 0.37359, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.7844 - accuracy: 0.4403 - val_loss: 2.2758 - val_accuracy: 0.3376\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.37359\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 1.6766 - accuracy: 0.4719 - val_loss: 2.2998 - val_accuracy: 0.3421\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.37359\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.6446 - accuracy: 0.4742 - val_loss: 2.3814 - val_accuracy: 0.3578\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.37359\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 1.5951 - accuracy: 0.4918 - val_loss: 2.3518 - val_accuracy: 0.3856\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.37359 to 0.38560, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 44s 237ms/step - loss: 1.5731 - accuracy: 0.5149 - val_loss: 2.5895 - val_accuracy: 0.2978\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.38560\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 1.5406 - accuracy: 0.5132 - val_loss: 1.8979 - val_accuracy: 0.4501\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.38560 to 0.45011, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.4519 - accuracy: 0.5460 - val_loss: 2.8159 - val_accuracy: 0.3398\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.45011\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 1.4589 - accuracy: 0.5369 - val_loss: 2.4301 - val_accuracy: 0.3196\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.45011\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.3720 - accuracy: 0.5616 - val_loss: 1.7630 - val_accuracy: 0.4824\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.45011 to 0.48237, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 1.3379 - accuracy: 0.5750 - val_loss: 1.9497 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.48237\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 1.3391 - accuracy: 0.5647 - val_loss: 1.8133 - val_accuracy: 0.4629\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.48237\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 1.2545 - accuracy: 0.6017 - val_loss: 1.7762 - val_accuracy: 0.4981\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.48237 to 0.49812, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.1982 - accuracy: 0.6223 - val_loss: 2.1198 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.49812\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 1.2536 - accuracy: 0.6069 - val_loss: 1.9723 - val_accuracy: 0.4674\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.49812\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 1.1361 - accuracy: 0.6419 - val_loss: 2.0389 - val_accuracy: 0.4584\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.49812\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 1.1099 - accuracy: 0.6378 - val_loss: 1.9696 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.49812\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 1.0702 - accuracy: 0.6466 - val_loss: 1.6567 - val_accuracy: 0.5154\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.49812 to 0.51538, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 1.0528 - accuracy: 0.6483 - val_loss: 2.1685 - val_accuracy: 0.4381\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.51538\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 1.0259 - accuracy: 0.6725 - val_loss: 3.0134 - val_accuracy: 0.3916\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.51538\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.9859 - accuracy: 0.6829 - val_loss: 1.5624 - val_accuracy: 0.5461\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.51538 to 0.54614, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.9592 - accuracy: 0.6903 - val_loss: 1.8292 - val_accuracy: 0.4914\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.54614\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.8827 - accuracy: 0.7162 - val_loss: 2.3147 - val_accuracy: 0.4831\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.54614\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.8815 - accuracy: 0.7111 - val_loss: 1.7829 - val_accuracy: 0.4914\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.54614\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.8505 - accuracy: 0.7180 - val_loss: 1.6397 - val_accuracy: 0.5521\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.54614 to 0.55214, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 42s 231ms/step - loss: 0.8575 - accuracy: 0.7132 - val_loss: 1.6533 - val_accuracy: 0.5709\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.55214 to 0.57089, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 42s 231ms/step - loss: 0.8260 - accuracy: 0.7235 - val_loss: 1.7466 - val_accuracy: 0.5409\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.57089\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.7620 - accuracy: 0.7494 - val_loss: 2.0880 - val_accuracy: 0.4801\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.57089\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.7531 - accuracy: 0.7475 - val_loss: 2.4755 - val_accuracy: 0.4921\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.57089\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.7476 - accuracy: 0.7462 - val_loss: 1.7006 - val_accuracy: 0.5686\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.57089\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.6772 - accuracy: 0.7702 - val_loss: 1.6772 - val_accuracy: 0.5686\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.57089\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.6676 - accuracy: 0.7850 - val_loss: 1.7023 - val_accuracy: 0.5746\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.57089 to 0.57464, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.6315 - accuracy: 0.7891 - val_loss: 1.9644 - val_accuracy: 0.4906\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.57464\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.6304 - accuracy: 0.7858 - val_loss: 1.6507 - val_accuracy: 0.5686\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.57464\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.5994 - accuracy: 0.8040 - val_loss: 1.7516 - val_accuracy: 0.5589\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.57464\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.5977 - accuracy: 0.8052 - val_loss: 1.8967 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.57464\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.5774 - accuracy: 0.8060 - val_loss: 1.6675 - val_accuracy: 0.5971\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.57464 to 0.59715, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.5749 - accuracy: 0.8062 - val_loss: 1.6017 - val_accuracy: 0.6107\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.59715 to 0.61065, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.5460 - accuracy: 0.8152 - val_loss: 1.6303 - val_accuracy: 0.5829\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.61065\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 44s 242ms/step - loss: 0.5254 - accuracy: 0.8185 - val_loss: 1.8851 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.61065\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.5189 - accuracy: 0.8320 - val_loss: 1.7479 - val_accuracy: 0.5949\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.61065\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.5060 - accuracy: 0.8336 - val_loss: 1.9801 - val_accuracy: 0.5349\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.61065\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.4647 - accuracy: 0.8458 - val_loss: 1.8331 - val_accuracy: 0.5664\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.61065\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.5083 - accuracy: 0.8248 - val_loss: 1.6168 - val_accuracy: 0.6159\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.61065 to 0.61590, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.4375 - accuracy: 0.8451 - val_loss: 1.9744 - val_accuracy: 0.5596\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.61590\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.4388 - accuracy: 0.8516 - val_loss: 1.5837 - val_accuracy: 0.6264\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.61590 to 0.62641, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.3965 - accuracy: 0.8611 - val_loss: 1.8898 - val_accuracy: 0.5671\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.62641\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.4443 - accuracy: 0.8482 - val_loss: 1.5554 - val_accuracy: 0.6392\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.62641 to 0.63916, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.3932 - accuracy: 0.8660 - val_loss: 1.8363 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.63916\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.4074 - accuracy: 0.8609 - val_loss: 1.6017 - val_accuracy: 0.6152\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.63916\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.3422 - accuracy: 0.8783 - val_loss: 1.7164 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.63916\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.3563 - accuracy: 0.8864 - val_loss: 1.7370 - val_accuracy: 0.6212\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.63916\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.3426 - accuracy: 0.8819 - val_loss: 2.1105 - val_accuracy: 0.5236\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.63916\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.3174 - accuracy: 0.8957 - val_loss: 1.6567 - val_accuracy: 0.6377\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.63916\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.3451 - accuracy: 0.8787 - val_loss: 1.6544 - val_accuracy: 0.6272\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.63916\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.2838 - accuracy: 0.9021 - val_loss: 1.9896 - val_accuracy: 0.5881\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.63916\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2916 - accuracy: 0.8986 - val_loss: 2.1218 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.63916\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.3063 - accuracy: 0.8949 - val_loss: 1.7889 - val_accuracy: 0.6174\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.63916\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.2916 - accuracy: 0.9007 - val_loss: 1.8625 - val_accuracy: 0.6047\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.63916\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.2722 - accuracy: 0.9070 - val_loss: 2.1673 - val_accuracy: 0.5491\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.63916\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 44s 242ms/step - loss: 0.2982 - accuracy: 0.9036 - val_loss: 1.6171 - val_accuracy: 0.6504\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.63916 to 0.65041, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2851 - accuracy: 0.9044 - val_loss: 1.6948 - val_accuracy: 0.6414\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.65041\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.2936 - accuracy: 0.8973 - val_loss: 1.8493 - val_accuracy: 0.5956\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.65041\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.2283 - accuracy: 0.9236 - val_loss: 1.7223 - val_accuracy: 0.6339\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.65041\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2484 - accuracy: 0.9187 - val_loss: 1.6315 - val_accuracy: 0.6587\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.65041 to 0.65866, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.2161 - accuracy: 0.9299 - val_loss: 1.7965 - val_accuracy: 0.6317\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.65866\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2464 - accuracy: 0.9161 - val_loss: 1.8385 - val_accuracy: 0.6324\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.65866\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2345 - accuracy: 0.9138 - val_loss: 1.5493 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.65866 to 0.66242, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2007 - accuracy: 0.9362 - val_loss: 1.7376 - val_accuracy: 0.6452\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.66242\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.2266 - accuracy: 0.9182 - val_loss: 2.2713 - val_accuracy: 0.5521\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.66242\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.1957 - accuracy: 0.9327 - val_loss: 1.7643 - val_accuracy: 0.6444\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.66242\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1998 - accuracy: 0.9352 - val_loss: 1.8575 - val_accuracy: 0.6407\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.66242\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.2050 - accuracy: 0.9301 - val_loss: 1.8051 - val_accuracy: 0.6459\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.66242\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1606 - accuracy: 0.9455 - val_loss: 1.6882 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.66242 to 0.67517, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.1827 - accuracy: 0.9408 - val_loss: 1.7270 - val_accuracy: 0.6579\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.67517\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.1993 - accuracy: 0.9351 - val_loss: 1.7064 - val_accuracy: 0.6369\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.67517\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1468 - accuracy: 0.9497 - val_loss: 1.6796 - val_accuracy: 0.6647\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.67517\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.1545 - accuracy: 0.9489 - val_loss: 1.9213 - val_accuracy: 0.6444\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.67517\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1956 - accuracy: 0.9347 - val_loss: 1.6569 - val_accuracy: 0.6437\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.67517\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.1435 - accuracy: 0.9508 - val_loss: 1.5583 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.67517 to 0.69993, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.1943 - accuracy: 0.9319 - val_loss: 1.7252 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.69993\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.1386 - accuracy: 0.9527 - val_loss: 1.6776 - val_accuracy: 0.6654\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.69993\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.1346 - accuracy: 0.9566 - val_loss: 1.5781 - val_accuracy: 0.6804\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.69993\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.1430 - accuracy: 0.9523 - val_loss: 1.7046 - val_accuracy: 0.6669\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.69993\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1456 - accuracy: 0.9503 - val_loss: 2.0645 - val_accuracy: 0.6302\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.69993\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.1346 - accuracy: 0.9542 - val_loss: 1.6666 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.69993\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.1478 - accuracy: 0.9505 - val_loss: 1.5127 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.69993 to 0.70443, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.1350 - accuracy: 0.9557 - val_loss: 1.8018 - val_accuracy: 0.6609\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.70443\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.1338 - accuracy: 0.9548 - val_loss: 1.7635 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.70443\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1533 - accuracy: 0.9513 - val_loss: 1.5741 - val_accuracy: 0.6857\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.70443\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.1206 - accuracy: 0.9601 - val_loss: 1.8473 - val_accuracy: 0.6384\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.70443\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.1070 - accuracy: 0.9665 - val_loss: 1.7107 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.70443\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1330 - accuracy: 0.9533 - val_loss: 1.8825 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.70443\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.1095 - accuracy: 0.9645 - val_loss: 1.9980 - val_accuracy: 0.6444\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.70443\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.1426 - accuracy: 0.9502 - val_loss: 1.6567 - val_accuracy: 0.6864\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.70443\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.1027 - accuracy: 0.9686 - val_loss: 1.5528 - val_accuracy: 0.6917\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.70443\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.1006 - accuracy: 0.9655 - val_loss: 1.5520 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.70443\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0950 - accuracy: 0.9675 - val_loss: 1.7975 - val_accuracy: 0.6639\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.70443\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1108 - accuracy: 0.9644 - val_loss: 1.7199 - val_accuracy: 0.6737\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.70443\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0983 - accuracy: 0.9670 - val_loss: 1.5926 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.70443\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.1033 - accuracy: 0.9615 - val_loss: 1.6607 - val_accuracy: 0.7037\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.70443\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0844 - accuracy: 0.9753 - val_loss: 1.5503 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.70443 to 0.70893, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0733 - accuracy: 0.9734 - val_loss: 1.8547 - val_accuracy: 0.6437\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.70893\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0857 - accuracy: 0.9692 - val_loss: 1.5494 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.70893 to 0.71493, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.1004 - accuracy: 0.9671 - val_loss: 1.6392 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.71493\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0834 - accuracy: 0.9695 - val_loss: 1.6202 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.71493\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0760 - accuracy: 0.9733 - val_loss: 1.7272 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.71493\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0738 - accuracy: 0.9773 - val_loss: 1.7860 - val_accuracy: 0.6789\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.71493\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0826 - accuracy: 0.9694 - val_loss: 1.5052 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.71493 to 0.72543, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0792 - accuracy: 0.9757 - val_loss: 1.5325 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.72543\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0934 - accuracy: 0.9696 - val_loss: 1.5441 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.72543\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0756 - accuracy: 0.9745 - val_loss: 1.5564 - val_accuracy: 0.7104\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.72543\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0639 - accuracy: 0.9805 - val_loss: 1.6193 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.72543\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 1.5528 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.72543\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0701 - accuracy: 0.9794 - val_loss: 1.6891 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.72543\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0821 - accuracy: 0.9752 - val_loss: 1.5156 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.72543 to 0.72993, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 1.8318 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.72993\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0940 - accuracy: 0.9714 - val_loss: 1.5775 - val_accuracy: 0.7262\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.72993\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 1.5984 - val_accuracy: 0.7187\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.72993\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0697 - accuracy: 0.9749 - val_loss: 1.6050 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.72993\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.0688 - accuracy: 0.9782 - val_loss: 1.5166 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.72993\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0587 - accuracy: 0.9804 - val_loss: 1.5184 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00133: val_accuracy improved from 0.72993 to 0.73818, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0704 - accuracy: 0.9764 - val_loss: 1.6358 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.73818\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 1.5169 - val_accuracy: 0.7194\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.73818\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0574 - accuracy: 0.9816 - val_loss: 1.5645 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.73818\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 1.6396 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.73818\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0583 - accuracy: 0.9803 - val_loss: 1.6059 - val_accuracy: 0.7187\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.73818\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0653 - accuracy: 0.9776 - val_loss: 1.5431 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.73818\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 1.5235 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.73818\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 45s 243ms/step - loss: 0.0577 - accuracy: 0.9843 - val_loss: 1.5655 - val_accuracy: 0.7239\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.73818\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0487 - accuracy: 0.9816 - val_loss: 1.6097 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.73818\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 1.5685 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.73818\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0468 - accuracy: 0.9868 - val_loss: 1.6236 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.73818\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0395 - accuracy: 0.9863 - val_loss: 1.5430 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.73818\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.0455 - accuracy: 0.9873 - val_loss: 1.5483 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.73818\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0476 - accuracy: 0.9845 - val_loss: 1.6379 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.73818\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.0486 - accuracy: 0.9863 - val_loss: 1.4887 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00148: val_accuracy improved from 0.73818 to 0.74044, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 1.5620 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.74044\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 1.7190 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.74044\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 1.7248 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.74044\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 1.6019 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.74044\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 1.5948 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.74044\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 1.6042 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.74044\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.0521 - accuracy: 0.9819 - val_loss: 1.5506 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.74044 to 0.74269, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0461 - accuracy: 0.9869 - val_loss: 1.6528 - val_accuracy: 0.7254\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.74269\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 1.6068 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.74269\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 1.7336 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.74269\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 43s 240ms/step - loss: 0.0668 - accuracy: 0.9808 - val_loss: 1.5876 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.74269\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0367 - accuracy: 0.9871 - val_loss: 1.6408 - val_accuracy: 0.7247\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.74269\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 1.6760 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.74269\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 1.7937 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.74269\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 1.7726 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.74269\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0423 - accuracy: 0.9841 - val_loss: 1.6243 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.74269\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 1.6526 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.74269\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 1.5799 - val_accuracy: 0.7397\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.74269\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 1.5578 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00167: val_accuracy improved from 0.74269 to 0.74344, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 1.6605 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.74344\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0379 - accuracy: 0.9886 - val_loss: 1.5118 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.74344 to 0.74419, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 1.5880 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.74419\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 1.5140 - val_accuracy: 0.7464\n",
            "\n",
            "Epoch 00171: val_accuracy improved from 0.74419 to 0.74644, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 42s 231ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 1.5910 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.74644\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 1.5644 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.74644\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 1.6314 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.74644\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.0316 - accuracy: 0.9885 - val_loss: 1.6036 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.74644\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 1.5878 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.74644\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 1.5642 - val_accuracy: 0.7397\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.74644\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 1.5953 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.74644\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 1.6312 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.74644\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 1.5722 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.74644\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 1.5165 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.74644\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 1.5966 - val_accuracy: 0.7382\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.74644\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 44s 241ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 1.6047 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.74644\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 1.6145 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.74644\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 1.6198 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.74644\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 1.5904 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.74644\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0267 - accuracy: 0.9895 - val_loss: 1.6112 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.74644\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0247 - accuracy: 0.9908 - val_loss: 1.6268 - val_accuracy: 0.7374\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.74644\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 1.6411 - val_accuracy: 0.7322\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.74644\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 44s 242ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 1.6076 - val_accuracy: 0.7262\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.74644\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 1.5259 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.74644\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 1.5839 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.74644\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 1.5362 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00193: val_accuracy improved from 0.74644 to 0.74794, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 1.5482 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.74794\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 1.5133 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00195: val_accuracy improved from 0.74794 to 0.74869, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 1.5354 - val_accuracy: 0.7434\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.74869\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 1.5538 - val_accuracy: 0.7509\n",
            "\n",
            "Epoch 00197: val_accuracy improved from 0.74869 to 0.75094, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 1.5721 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.75094\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 1.6189 - val_accuracy: 0.7359\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.75094\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 1.5584 - val_accuracy: 0.7457\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.75094\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 1.5462 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.75094\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 1.6400 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.75094\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 1.5681 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.75094\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 1.6016 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.75094\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 1.5650 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.75094\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 1.6091 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.75094\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 1.5255 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00207: val_accuracy improved from 0.75094 to 0.75619, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 1.5565 - val_accuracy: 0.7464\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.75619\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 1.5700 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.75619\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 1.5704 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.75619\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 1.5356 - val_accuracy: 0.7554\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.75619\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 1.5732 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.75619\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 1.5834 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.75619\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 1.5762 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.75619\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 1.6239 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.75619\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 42s 232ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 1.5669 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.75619\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 1.5423 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.75619\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 1.5299 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.75619\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 43s 232ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 1.5471 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.75619\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 1.5710 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.75619\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 1.5411 - val_accuracy: 0.7517\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.75619\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 1.5872 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.75619\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 1.5532 - val_accuracy: 0.7479\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.75619\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 1.5625 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.75619\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 1.5639 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.75619\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 1.5507 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.75619\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0170 - accuracy: 0.9927 - val_loss: 1.5681 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.75619\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 1.6184 - val_accuracy: 0.7337\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.75619\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 43s 235ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 1.5812 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.75619\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 43s 237ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 1.5925 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.75619\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 1.5435 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.75619\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 44s 240ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.5466 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.75619\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 1.5395 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.75619\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 1.5559 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.75619\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 43s 233ms/step - loss: 0.0222 - accuracy: 0.9912 - val_loss: 1.5540 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.75619\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 1.5555 - val_accuracy: 0.7472\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.75619\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 43s 236ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 1.5358 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.75619\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 44s 238ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 1.5442 - val_accuracy: 0.7494\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.75619\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 44s 239ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 1.5444 - val_accuracy: 0.7487\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.75619\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 43s 234ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 1.5578 - val_accuracy: 0.7449\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.75619\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 5s 66ms/step - loss: 1.7025 - accuracy: 0.7384\n",
            "loss 1.702492594718933\n",
            "acc 0.7384013533592224\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Running: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "Epoch 1/240\n",
            "181/181 [==============================] - 53s 261ms/step - loss: 3.3913 - accuracy: 0.1151 - val_loss: 10.7344 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11703, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 2/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 2.9456 - accuracy: 0.1656 - val_loss: 2.8275 - val_accuracy: 0.1845\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.11703 to 0.18455, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 3/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 2.7899 - accuracy: 0.2037 - val_loss: 2.7042 - val_accuracy: 0.2153\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.18455 to 0.21530, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 4/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 2.6290 - accuracy: 0.2382 - val_loss: 2.6355 - val_accuracy: 0.2476\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.21530 to 0.24756, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 5/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 2.5247 - accuracy: 0.2559 - val_loss: 2.5676 - val_accuracy: 0.2431\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.24756\n",
            "Epoch 6/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 2.4612 - accuracy: 0.2737 - val_loss: 3.8075 - val_accuracy: 0.2311\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.24756\n",
            "Epoch 7/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 2.3946 - accuracy: 0.2832 - val_loss: 2.5240 - val_accuracy: 0.3031\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.24756 to 0.30308, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 8/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 2.2569 - accuracy: 0.3233 - val_loss: 2.6148 - val_accuracy: 0.2401\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.30308\n",
            "Epoch 9/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 2.3127 - accuracy: 0.3106 - val_loss: 3.0439 - val_accuracy: 0.2206\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.30308\n",
            "Epoch 10/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 2.1822 - accuracy: 0.3391 - val_loss: 2.5867 - val_accuracy: 0.2588\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.30308\n",
            "Epoch 11/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 2.0867 - accuracy: 0.3618 - val_loss: 2.5487 - val_accuracy: 0.2791\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.30308\n",
            "Epoch 12/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 2.0383 - accuracy: 0.3654 - val_loss: 2.4316 - val_accuracy: 0.3211\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.30308 to 0.32108, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 13/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 1.9871 - accuracy: 0.3948 - val_loss: 2.7762 - val_accuracy: 0.2221\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.32108\n",
            "Epoch 14/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 1.8665 - accuracy: 0.4229 - val_loss: 2.6948 - val_accuracy: 0.2813\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.32108\n",
            "Epoch 15/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 1.8358 - accuracy: 0.4312 - val_loss: 2.5065 - val_accuracy: 0.3083\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.32108\n",
            "Epoch 16/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 1.8207 - accuracy: 0.4299 - val_loss: 2.3883 - val_accuracy: 0.3338\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.32108 to 0.33383, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 17/240\n",
            "181/181 [==============================] - 45s 244ms/step - loss: 1.6990 - accuracy: 0.4667 - val_loss: 2.0804 - val_accuracy: 0.4081\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.33383 to 0.40810, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 18/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 1.7349 - accuracy: 0.4534 - val_loss: 2.0663 - val_accuracy: 0.4156\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.40810 to 0.41560, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 19/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 1.6230 - accuracy: 0.4791 - val_loss: 1.9756 - val_accuracy: 0.4321\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.41560 to 0.43211, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 20/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 1.6193 - accuracy: 0.4873 - val_loss: 1.9958 - val_accuracy: 0.4284\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.43211\n",
            "Epoch 21/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 1.5591 - accuracy: 0.5084 - val_loss: 2.4247 - val_accuracy: 0.3331\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.43211\n",
            "Epoch 22/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 1.5304 - accuracy: 0.5158 - val_loss: 2.2223 - val_accuracy: 0.4044\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.43211\n",
            "Epoch 23/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 1.4695 - accuracy: 0.5388 - val_loss: 2.0151 - val_accuracy: 0.4224\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.43211\n",
            "Epoch 24/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 1.4205 - accuracy: 0.5402 - val_loss: 1.8797 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.43211 to 0.45686, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 25/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 1.4174 - accuracy: 0.5468 - val_loss: 2.3967 - val_accuracy: 0.3121\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.45686\n",
            "Epoch 26/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 1.4086 - accuracy: 0.5448 - val_loss: 2.0600 - val_accuracy: 0.4126\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.45686\n",
            "Epoch 27/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 1.3434 - accuracy: 0.5613 - val_loss: 1.7842 - val_accuracy: 0.4726\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.45686 to 0.47262, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 28/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 1.2754 - accuracy: 0.5855 - val_loss: 1.6864 - val_accuracy: 0.4959\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.47262 to 0.49587, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 29/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 1.2868 - accuracy: 0.5887 - val_loss: 2.0091 - val_accuracy: 0.4509\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.49587\n",
            "Epoch 30/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 1.2252 - accuracy: 0.6068 - val_loss: 1.9760 - val_accuracy: 0.4591\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.49587\n",
            "Epoch 31/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 1.1955 - accuracy: 0.6138 - val_loss: 2.3296 - val_accuracy: 0.4284\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.49587\n",
            "Epoch 32/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 1.1567 - accuracy: 0.6193 - val_loss: 1.9850 - val_accuracy: 0.4659\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.49587\n",
            "Epoch 33/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 1.0827 - accuracy: 0.6457 - val_loss: 1.8811 - val_accuracy: 0.4914\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.49587\n",
            "Epoch 34/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 1.0911 - accuracy: 0.6499 - val_loss: 2.0551 - val_accuracy: 0.5034\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.49587 to 0.50338, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 35/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 1.0672 - accuracy: 0.6581 - val_loss: 1.8041 - val_accuracy: 0.5071\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.50338 to 0.50713, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 36/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 1.0258 - accuracy: 0.6540 - val_loss: 2.0785 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.50713\n",
            "Epoch 37/240\n",
            "181/181 [==============================] - 46s 254ms/step - loss: 1.0559 - accuracy: 0.6437 - val_loss: 1.8453 - val_accuracy: 0.4944\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.50713\n",
            "Epoch 38/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.9809 - accuracy: 0.6736 - val_loss: 1.6320 - val_accuracy: 0.5304\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.50713 to 0.53038, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 39/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.9386 - accuracy: 0.6871 - val_loss: 1.9312 - val_accuracy: 0.5011\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.53038\n",
            "Epoch 40/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.9433 - accuracy: 0.6959 - val_loss: 1.6488 - val_accuracy: 0.5356\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.53038 to 0.53563, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 41/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.8582 - accuracy: 0.7093 - val_loss: 2.0479 - val_accuracy: 0.4891\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.53563\n",
            "Epoch 42/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.8159 - accuracy: 0.7311 - val_loss: 1.8895 - val_accuracy: 0.5176\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.53563\n",
            "Epoch 43/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.8753 - accuracy: 0.7139 - val_loss: 1.6787 - val_accuracy: 0.5529\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.53563 to 0.55289, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 44/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 0.8130 - accuracy: 0.7315 - val_loss: 1.8600 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.55289\n",
            "Epoch 45/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.7311 - accuracy: 0.7620 - val_loss: 1.9294 - val_accuracy: 0.5439\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.55289\n",
            "Epoch 46/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.7684 - accuracy: 0.7429 - val_loss: 1.7055 - val_accuracy: 0.5851\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.55289 to 0.58515, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 47/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.7016 - accuracy: 0.7670 - val_loss: 1.6213 - val_accuracy: 0.5896\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.58515 to 0.58965, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 48/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.7156 - accuracy: 0.7567 - val_loss: 2.1468 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.58965\n",
            "Epoch 49/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.7018 - accuracy: 0.7763 - val_loss: 1.9360 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.58965\n",
            "Epoch 50/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.7090 - accuracy: 0.7607 - val_loss: 1.7556 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.58965\n",
            "Epoch 51/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.6622 - accuracy: 0.7754 - val_loss: 1.8105 - val_accuracy: 0.5521\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.58965\n",
            "Epoch 52/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 0.6640 - accuracy: 0.7748 - val_loss: 2.2105 - val_accuracy: 0.5416\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.58965\n",
            "Epoch 53/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.6114 - accuracy: 0.7935 - val_loss: 1.9290 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.58965\n",
            "Epoch 54/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.6122 - accuracy: 0.8029 - val_loss: 1.7843 - val_accuracy: 0.5521\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.58965\n",
            "Epoch 55/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.5631 - accuracy: 0.8074 - val_loss: 1.8352 - val_accuracy: 0.5431\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.58965\n",
            "Epoch 56/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.5487 - accuracy: 0.8109 - val_loss: 2.1821 - val_accuracy: 0.5071\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.58965\n",
            "Epoch 57/240\n",
            "181/181 [==============================] - 47s 256ms/step - loss: 0.5549 - accuracy: 0.8089 - val_loss: 1.7269 - val_accuracy: 0.5521\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.58965\n",
            "Epoch 58/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.5142 - accuracy: 0.8244 - val_loss: 1.6934 - val_accuracy: 0.5851\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.58965\n",
            "Epoch 59/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.5384 - accuracy: 0.8163 - val_loss: 2.0386 - val_accuracy: 0.5461\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.58965\n",
            "Epoch 60/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.4429 - accuracy: 0.8515 - val_loss: 1.7489 - val_accuracy: 0.5844\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.58965\n",
            "Epoch 61/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.4629 - accuracy: 0.8489 - val_loss: 1.7503 - val_accuracy: 0.5859\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.58965\n",
            "Epoch 62/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.4930 - accuracy: 0.8332 - val_loss: 1.7035 - val_accuracy: 0.6039\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.58965 to 0.60390, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 63/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.4264 - accuracy: 0.8577 - val_loss: 1.7614 - val_accuracy: 0.5956\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.60390\n",
            "Epoch 64/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.4464 - accuracy: 0.8476 - val_loss: 1.7533 - val_accuracy: 0.5889\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.60390\n",
            "Epoch 65/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.4183 - accuracy: 0.8605 - val_loss: 1.8629 - val_accuracy: 0.5694\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.60390\n",
            "Epoch 66/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.4020 - accuracy: 0.8633 - val_loss: 1.9205 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.60390\n",
            "Epoch 67/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.3814 - accuracy: 0.8692 - val_loss: 1.8116 - val_accuracy: 0.5836\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.60390\n",
            "Epoch 68/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.3891 - accuracy: 0.8657 - val_loss: 1.6921 - val_accuracy: 0.6309\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.60390 to 0.63091, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 69/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.3346 - accuracy: 0.8908 - val_loss: 1.8393 - val_accuracy: 0.5761\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.63091\n",
            "Epoch 70/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.3747 - accuracy: 0.8596 - val_loss: 1.7063 - val_accuracy: 0.5979\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.63091\n",
            "Epoch 71/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.3650 - accuracy: 0.8840 - val_loss: 1.6930 - val_accuracy: 0.6197\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.63091\n",
            "Epoch 72/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.3084 - accuracy: 0.8971 - val_loss: 1.6276 - val_accuracy: 0.6332\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.63091 to 0.63316, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 73/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.3199 - accuracy: 0.8850 - val_loss: 2.1613 - val_accuracy: 0.5529\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.63316\n",
            "Epoch 74/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.3263 - accuracy: 0.8893 - val_loss: 1.8680 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.63316\n",
            "Epoch 75/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.2809 - accuracy: 0.9109 - val_loss: 1.9297 - val_accuracy: 0.5851\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.63316\n",
            "Epoch 76/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.2755 - accuracy: 0.9019 - val_loss: 2.1935 - val_accuracy: 0.5889\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.63316\n",
            "Epoch 77/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.3274 - accuracy: 0.8888 - val_loss: 1.8908 - val_accuracy: 0.6144\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.63316\n",
            "Epoch 78/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.2743 - accuracy: 0.9126 - val_loss: 1.8668 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.63316\n",
            "Epoch 79/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.2404 - accuracy: 0.9178 - val_loss: 1.8790 - val_accuracy: 0.6122\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.63316\n",
            "Epoch 80/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.2585 - accuracy: 0.9177 - val_loss: 1.5825 - val_accuracy: 0.6497\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.63316 to 0.64966, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 81/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.2735 - accuracy: 0.9092 - val_loss: 1.8231 - val_accuracy: 0.6017\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.64966\n",
            "Epoch 82/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.2499 - accuracy: 0.9109 - val_loss: 1.7432 - val_accuracy: 0.6399\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.64966\n",
            "Epoch 83/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.2304 - accuracy: 0.9194 - val_loss: 1.8891 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.64966\n",
            "Epoch 84/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.2220 - accuracy: 0.9259 - val_loss: 1.7817 - val_accuracy: 0.6294\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.64966\n",
            "Epoch 85/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.2543 - accuracy: 0.9117 - val_loss: 1.8395 - val_accuracy: 0.6279\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.64966\n",
            "Epoch 86/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.2668 - accuracy: 0.9158 - val_loss: 1.7857 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.64966\n",
            "Epoch 87/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.2249 - accuracy: 0.9245 - val_loss: 1.9087 - val_accuracy: 0.6309\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.64966\n",
            "Epoch 88/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.1859 - accuracy: 0.9403 - val_loss: 1.8805 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.64966\n",
            "Epoch 89/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.2181 - accuracy: 0.9281 - val_loss: 1.8846 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.64966 to 0.65266, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 90/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.2156 - accuracy: 0.9267 - val_loss: 1.7045 - val_accuracy: 0.6572\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.65266 to 0.65716, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 91/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.2020 - accuracy: 0.9301 - val_loss: 1.8442 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.65716\n",
            "Epoch 92/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1815 - accuracy: 0.9361 - val_loss: 1.7647 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.65716\n",
            "Epoch 93/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1775 - accuracy: 0.9369 - val_loss: 1.8047 - val_accuracy: 0.6332\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.65716\n",
            "Epoch 94/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.1514 - accuracy: 0.9502 - val_loss: 1.7341 - val_accuracy: 0.6602\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.65716 to 0.66017, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 95/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.1517 - accuracy: 0.9514 - val_loss: 1.8539 - val_accuracy: 0.6279\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.66017\n",
            "Epoch 96/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.1735 - accuracy: 0.9438 - val_loss: 1.7897 - val_accuracy: 0.6362\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.66017\n",
            "Epoch 97/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.1624 - accuracy: 0.9440 - val_loss: 1.7983 - val_accuracy: 0.6519\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.66017\n",
            "Epoch 98/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.1587 - accuracy: 0.9533 - val_loss: 1.8096 - val_accuracy: 0.6294\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.66017\n",
            "Epoch 99/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.1908 - accuracy: 0.9371 - val_loss: 1.7423 - val_accuracy: 0.6519\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.66017\n",
            "Epoch 100/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.1521 - accuracy: 0.9478 - val_loss: 1.6701 - val_accuracy: 0.6662\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.66017 to 0.66617, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 101/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.1622 - accuracy: 0.9462 - val_loss: 1.8890 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.66617\n",
            "Epoch 102/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.1503 - accuracy: 0.9511 - val_loss: 1.8890 - val_accuracy: 0.6377\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.66617\n",
            "Epoch 103/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.1555 - accuracy: 0.9482 - val_loss: 1.6589 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.66617 to 0.67067, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 104/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.1302 - accuracy: 0.9559 - val_loss: 1.8124 - val_accuracy: 0.6557\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.67067\n",
            "Epoch 105/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.1351 - accuracy: 0.9555 - val_loss: 1.8722 - val_accuracy: 0.6392\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.67067\n",
            "Epoch 106/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1290 - accuracy: 0.9556 - val_loss: 1.6902 - val_accuracy: 0.6557\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.67067\n",
            "Epoch 107/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.1276 - accuracy: 0.9595 - val_loss: 1.6376 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.67067 to 0.67217, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 108/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.1324 - accuracy: 0.9531 - val_loss: 1.6678 - val_accuracy: 0.6647\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.67217\n",
            "Epoch 109/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.1131 - accuracy: 0.9611 - val_loss: 1.6765 - val_accuracy: 0.6714\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.67217\n",
            "Epoch 110/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.1289 - accuracy: 0.9610 - val_loss: 1.7665 - val_accuracy: 0.6654\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.67217\n",
            "Epoch 111/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1178 - accuracy: 0.9607 - val_loss: 1.7038 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.67217\n",
            "Epoch 112/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1050 - accuracy: 0.9655 - val_loss: 1.6490 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.67217 to 0.67967, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 113/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1051 - accuracy: 0.9655 - val_loss: 1.5703 - val_accuracy: 0.6969\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.67967 to 0.69692, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 114/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.1421 - accuracy: 0.9542 - val_loss: 1.6834 - val_accuracy: 0.6609\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.69692\n",
            "Epoch 115/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.1089 - accuracy: 0.9619 - val_loss: 1.6607 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.69692\n",
            "Epoch 116/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.1258 - accuracy: 0.9622 - val_loss: 1.7864 - val_accuracy: 0.6579\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.69692\n",
            "Epoch 117/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.1096 - accuracy: 0.9631 - val_loss: 1.5328 - val_accuracy: 0.6954\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.69692\n",
            "Epoch 118/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0908 - accuracy: 0.9688 - val_loss: 1.6823 - val_accuracy: 0.6639\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.69692\n",
            "Epoch 119/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.1038 - accuracy: 0.9649 - val_loss: 1.6491 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.69692\n",
            "Epoch 120/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.1015 - accuracy: 0.9648 - val_loss: 1.7014 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.69692\n",
            "Epoch 121/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 0.0858 - accuracy: 0.9698 - val_loss: 1.7355 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.69692\n",
            "Epoch 122/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 0.1231 - accuracy: 0.9568 - val_loss: 1.5756 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.69692 to 0.70443, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 123/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0846 - accuracy: 0.9703 - val_loss: 1.6689 - val_accuracy: 0.6767\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.70443\n",
            "Epoch 124/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 1.7349 - val_accuracy: 0.6789\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.70443\n",
            "Epoch 125/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 0.0883 - accuracy: 0.9673 - val_loss: 1.7515 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.70443\n",
            "Epoch 126/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0841 - accuracy: 0.9711 - val_loss: 1.6884 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.70443\n",
            "Epoch 127/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0966 - accuracy: 0.9684 - val_loss: 1.6872 - val_accuracy: 0.6917\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.70443\n",
            "Epoch 128/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.0912 - accuracy: 0.9718 - val_loss: 1.5832 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.70443\n",
            "Epoch 129/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0869 - accuracy: 0.9694 - val_loss: 1.6682 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.70443\n",
            "Epoch 130/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.0818 - accuracy: 0.9749 - val_loss: 1.7229 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.70443\n",
            "Epoch 131/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.1063 - accuracy: 0.9645 - val_loss: 1.7366 - val_accuracy: 0.6707\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.70443\n",
            "Epoch 132/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0694 - accuracy: 0.9783 - val_loss: 1.5881 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.70443\n",
            "Epoch 133/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.1000 - accuracy: 0.9656 - val_loss: 2.0267 - val_accuracy: 0.6422\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.70443\n",
            "Epoch 134/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0838 - accuracy: 0.9727 - val_loss: 1.7221 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.70443\n",
            "Epoch 135/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0822 - accuracy: 0.9730 - val_loss: 1.6632 - val_accuracy: 0.6969\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.70443\n",
            "Epoch 136/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0812 - accuracy: 0.9731 - val_loss: 1.6774 - val_accuracy: 0.6744\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.70443\n",
            "Epoch 137/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0496 - accuracy: 0.9830 - val_loss: 1.6784 - val_accuracy: 0.6804\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.70443\n",
            "Epoch 138/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 1.6314 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.70443\n",
            "Epoch 139/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0798 - accuracy: 0.9731 - val_loss: 1.7272 - val_accuracy: 0.6827\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.70443\n",
            "Epoch 140/240\n",
            "181/181 [==============================] - 46s 248ms/step - loss: 0.0809 - accuracy: 0.9745 - val_loss: 1.7469 - val_accuracy: 0.6714\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.70443\n",
            "Epoch 141/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0658 - accuracy: 0.9796 - val_loss: 1.6510 - val_accuracy: 0.6857\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.70443\n",
            "Epoch 142/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0727 - accuracy: 0.9776 - val_loss: 1.7120 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.70443\n",
            "Epoch 143/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.0741 - accuracy: 0.9753 - val_loss: 1.6797 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.70443\n",
            "Epoch 144/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0551 - accuracy: 0.9830 - val_loss: 1.5874 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.70443\n",
            "Epoch 145/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 1.5803 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.70443\n",
            "Epoch 146/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 1.5798 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.70443 to 0.71343, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 147/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0629 - accuracy: 0.9792 - val_loss: 1.6057 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.71343\n",
            "Epoch 148/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0523 - accuracy: 0.9805 - val_loss: 1.6460 - val_accuracy: 0.6969\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.71343\n",
            "Epoch 149/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 1.6992 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.71343\n",
            "Epoch 150/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 1.6376 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.71343\n",
            "Epoch 151/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 1.6639 - val_accuracy: 0.7104\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.71343\n",
            "Epoch 152/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0587 - accuracy: 0.9794 - val_loss: 1.6218 - val_accuracy: 0.7059\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.71343\n",
            "Epoch 153/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 1.7254 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.71343\n",
            "Epoch 154/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 1.7092 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.71343\n",
            "Epoch 155/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0463 - accuracy: 0.9861 - val_loss: 1.6195 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.71343\n",
            "Epoch 156/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0547 - accuracy: 0.9805 - val_loss: 1.7362 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.71343\n",
            "Epoch 157/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0564 - accuracy: 0.9834 - val_loss: 1.5684 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00157: val_accuracy improved from 0.71343 to 0.71418, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 158/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0499 - accuracy: 0.9857 - val_loss: 1.6748 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.71418\n",
            "Epoch 159/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 1.6260 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.71418\n",
            "Epoch 160/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 1.7216 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.71418\n",
            "Epoch 161/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0463 - accuracy: 0.9866 - val_loss: 1.7120 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.71418\n",
            "Epoch 162/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 1.6966 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.71418\n",
            "Epoch 163/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 1.6760 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.71418\n",
            "Epoch 164/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0420 - accuracy: 0.9878 - val_loss: 1.7287 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.71418\n",
            "Epoch 165/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 1.6803 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.71418\n",
            "Epoch 166/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 1.7440 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.71418\n",
            "Epoch 167/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0449 - accuracy: 0.9836 - val_loss: 1.7638 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.71418\n",
            "Epoch 168/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 1.6860 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.71418\n",
            "Epoch 169/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 1.6615 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.71418 to 0.71793, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 170/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0521 - accuracy: 0.9837 - val_loss: 1.6583 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.71793\n",
            "Epoch 171/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 1.6170 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00171: val_accuracy improved from 0.71793 to 0.72168, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 172/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 1.7107 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.72168\n",
            "Epoch 173/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0400 - accuracy: 0.9842 - val_loss: 1.7060 - val_accuracy: 0.7059\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.72168\n",
            "Epoch 174/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0421 - accuracy: 0.9850 - val_loss: 1.8521 - val_accuracy: 0.7037\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.72168\n",
            "Epoch 175/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.0416 - accuracy: 0.9868 - val_loss: 1.7701 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.72168\n",
            "Epoch 176/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 1.7139 - val_accuracy: 0.6954\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.72168\n",
            "Epoch 177/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 1.7007 - val_accuracy: 0.7074\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.72168\n",
            "Epoch 178/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 1.6555 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.72168\n",
            "Epoch 179/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 1.6239 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.72168\n",
            "Epoch 180/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 1.7573 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.72168\n",
            "Epoch 181/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 1.7332 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.72168\n",
            "Epoch 182/240\n",
            "181/181 [==============================] - 46s 257ms/step - loss: 0.0541 - accuracy: 0.9809 - val_loss: 1.6999 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00182: val_accuracy improved from 0.72168 to 0.72243, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 183/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 1.7257 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.72243\n",
            "Epoch 184/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0300 - accuracy: 0.9880 - val_loss: 1.7592 - val_accuracy: 0.7082\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.72243\n",
            "Epoch 185/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 1.6908 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.72243\n",
            "Epoch 186/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0378 - accuracy: 0.9871 - val_loss: 1.6881 - val_accuracy: 0.7052\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.72243\n",
            "Epoch 187/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 1.6956 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.72243\n",
            "Epoch 188/240\n",
            "181/181 [==============================] - 47s 256ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 1.6767 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.72243\n",
            "Epoch 189/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0343 - accuracy: 0.9870 - val_loss: 1.7539 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.72243\n",
            "Epoch 190/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 1.7037 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.72243\n",
            "Epoch 191/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 1.7020 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.72243\n",
            "Epoch 192/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 1.8278 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.72243\n",
            "Epoch 193/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.0288 - accuracy: 0.9897 - val_loss: 1.7956 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.72243\n",
            "Epoch 194/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 1.7448 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.72243\n",
            "Epoch 195/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 1.6639 - val_accuracy: 0.7149\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.72243\n",
            "Epoch 196/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0441 - accuracy: 0.9880 - val_loss: 1.8372 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.72243\n",
            "Epoch 197/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 1.6600 - val_accuracy: 0.7239\n",
            "\n",
            "Epoch 00197: val_accuracy improved from 0.72243 to 0.72393, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 198/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 1.7371 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.72393\n",
            "Epoch 199/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 1.7691 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.72393\n",
            "Epoch 200/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 1.7736 - val_accuracy: 0.7037\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.72393\n",
            "Epoch 201/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 1.6861 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.72393\n",
            "Epoch 202/240\n",
            "181/181 [==============================] - 45s 245ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 1.6307 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.72393\n",
            "Epoch 203/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 1.6671 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.72393\n",
            "Epoch 204/240\n",
            "181/181 [==============================] - 45s 246ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 1.6984 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.72393\n",
            "Epoch 205/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0313 - accuracy: 0.9868 - val_loss: 1.6333 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.72393\n",
            "Epoch 206/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0275 - accuracy: 0.9899 - val_loss: 1.7350 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.72393\n",
            "Epoch 207/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 1.7278 - val_accuracy: 0.7112\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.72393\n",
            "Epoch 208/240\n",
            "181/181 [==============================] - 46s 254ms/step - loss: 0.0373 - accuracy: 0.9861 - val_loss: 1.7548 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.72393\n",
            "Epoch 209/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 1.6370 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.72393\n",
            "Epoch 210/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 1.6427 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.72393\n",
            "Epoch 211/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0265 - accuracy: 0.9895 - val_loss: 1.7202 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.72393\n",
            "Epoch 212/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 1.6823 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.72393\n",
            "Epoch 213/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 1.7238 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.72393\n",
            "Epoch 214/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 1.8042 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.72393\n",
            "Epoch 215/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 1.7468 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.72393\n",
            "Epoch 216/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 1.6788 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.72393\n",
            "Epoch 217/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 1.7092 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.72393\n",
            "Epoch 218/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 1.7093 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.72393\n",
            "Epoch 219/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 1.7049 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.72393\n",
            "Epoch 220/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 1.7237 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.72393\n",
            "Epoch 221/240\n",
            "181/181 [==============================] - 47s 254ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 1.7174 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.72393\n",
            "Epoch 222/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 1.6658 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.72393\n",
            "Epoch 223/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 1.7287 - val_accuracy: 0.7262\n",
            "\n",
            "Epoch 00223: val_accuracy improved from 0.72393 to 0.72618, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 224/240\n",
            "181/181 [==============================] - 45s 248ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 1.6818 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.72618\n",
            "Epoch 225/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 1.6527 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.72618\n",
            "Epoch 226/240\n",
            "181/181 [==============================] - 46s 251ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 1.6431 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.72618\n",
            "Epoch 227/240\n",
            "181/181 [==============================] - 46s 254ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 1.6925 - val_accuracy: 0.7194\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.72618\n",
            "Epoch 228/240\n",
            "181/181 [==============================] - 46s 252ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 1.6324 - val_accuracy: 0.7142\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.72618\n",
            "Epoch 229/240\n",
            "181/181 [==============================] - 45s 251ms/step - loss: 0.0566 - accuracy: 0.9851 - val_loss: 1.6783 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00229: val_accuracy improved from 0.72618 to 0.72843, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 230/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0304 - accuracy: 0.9894 - val_loss: 1.6773 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.72843\n",
            "Epoch 231/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 1.6967 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.72843\n",
            "Epoch 232/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 1.6681 - val_accuracy: 0.7232\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.72843\n",
            "Epoch 233/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 1.6380 - val_accuracy: 0.7299\n",
            "\n",
            "Epoch 00233: val_accuracy improved from 0.72843 to 0.72993, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 234/240\n",
            "181/181 [==============================] - 47s 255ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 1.6406 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.72993\n",
            "Epoch 235/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 1.6510 - val_accuracy: 0.7314\n",
            "\n",
            "Epoch 00235: val_accuracy improved from 0.72993 to 0.73143, saving model to JP27B17-InceptionV3-CroppedPlantDoc-0.2-best_result.hdf5\n",
            "Epoch 236/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 1.6583 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.73143\n",
            "Epoch 237/240\n",
            "181/181 [==============================] - 45s 247ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.7360 - val_accuracy: 0.7209\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.73143\n",
            "Epoch 238/240\n",
            "181/181 [==============================] - 46s 249ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 1.6945 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.73143\n",
            "Epoch 239/240\n",
            "181/181 [==============================] - 46s 250ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 1.6955 - val_accuracy: 0.7172\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.73143\n",
            "Epoch 240/240\n",
            "181/181 [==============================] - 46s 253ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 1.6610 - val_accuracy: 0.7269\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.73143\n",
            "Best Model Results: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n",
            "56/56 [==============================] - 5s 72ms/step - loss: 1.6826 - accuracy: 0.7423\n",
            "loss 1.6825616359710693\n",
            "acc 0.7423141598701477\n",
            "Finished: JP27B17-InceptionV3-CroppedPlantDoc-0.2\n"
          ]
        }
      ],
      "source": [
        "work_on_inception_v3(show_model=False, run_fit=True, test_results=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsHFKBo2NxP-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of JP27B17 - PAPER - InceptionV3WithCroppedPlantDoc_240Epochs_Size224.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}